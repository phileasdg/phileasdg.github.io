{
    "version": "https://jsonfeed.org/version/1",
    "title": "Phileas Dazeley-Gaist",
    "description": "",
    "home_page_url": "https://phileasdg.github.io",
    "feed_url": "https://phileasdg.github.io/feed.json",
    "user_comment": "",
    "author": {
        "name": "Phileas Dazeley-Gaist"
    },
    "items": [
        {
            "id": "https://phileasdg.github.io/computational-plant-ecology-interactive-spatial-network-analysis-of-a-college-garden/",
            "url": "https://phileasdg.github.io/computational-plant-ecology-interactive-spatial-network-analysis-of-a-college-garden/",
            "title": "Computational Plant Ecology: Interactive Spatial Network Analysis of a College Garden",
            "summary": "Note: This post was originally a short technical article I shared on&hellip;",
            "content_html": "<p><strong>Note:</strong> This post was originally a short technical article I shared on the Wolfram Community forums. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3535315\">here</a>. </p><h2 id=\"introduction\">Introduction</h2>\n<p>About a year ago, a student at College of the Atlantic reached out to me for advice on a capstone project. She was interested in using Wolfram Language to make an interactive map of the college’s Sunken Garden, and exhibiting it as a kind of art installation. To help get her get started, I traced a <a href=\"https://www.coa.edu/live/files/841-appendix-1-sunken-garden-brochure-pdf\">map of the garden</a> using the image Coordinates tool in a Wolfram Notebook and made two data representations of the garden: a point cloud of plant locations by species and a network of the garden’s paths.</p><p>Although her project ended up taking a different direction, the idea stuck with me. After stumbling upon the files recently I was inspired to see if I could build the representations I had made into a fully interactive map. Over the weekend, I dusted off this old notebook and got to work figuring out:</p><ol>\n<li><p>What interesting things can be said about the garden data?</p></li>\n<li><p>What kind of interactions and interfaces to the data would feel compelling to a general audience interested in the Sunken Garden.</p></li>\n<li><p>How to package and deploy this experience as a website.</p></li>\n</ol>\n<p>This post is a short reflection on that process, and how I used Wolfram to prototype and design the final website, which you can visit <a href=\"https://phileasdg.github.io/coa-sunken-garden/\">here</a>, or read along to discover bit by bit.</p><h2 id=\"sketching-a-digital-garden\">Sketching a digital garden</h2>\n<p>The first step was to import a copy of the <a href=\"https://www.coa.edu/live/files/841-appendix-1-sunken-garden-brochure-pdf\">map from the brochure</a>:</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/49/0ockt0ex1876r.png\" alt=\"\" width=\"200\" height=\"undefined\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/0ockt0ex1876r-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0ockt0ex1876r-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0ockt0ex1876r-md.png 768w\"></figure><p>I traced the map image twice: once for plant label coordinates, and once for a rough sample of points along the garden path using the image Coordinates tool described in <a href=\"https://reference.wolfram.com/language/workflow/GetCoordinatesFromAnImage.html\">this tutorial</a> (and I later found <a href=\"https://mathematica.stackexchange.com/questions/214497/making-a-graph-or-network-interactively-over-an-image\">this one too</a>). It was a surprisingly meditative experience. I grouped points corresponding to the same species together, and constructed a network representation of the garden path based on my path point sample. I was left with a dataset of plant positions, and a path network.</p><p>Here’s a preview of the plant positions data:</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/1mp0w9zxnu82m.png\" alt=\"\" width=\"250\" height=\"undefined\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1mp0w9zxnu82m-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1mp0w9zxnu82m-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1mp0w9zxnu82m-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/Screenshot-2025-09-13-at-20.43.44.png\" alt=\"Image description\" width=\"300\" height=\"undefined\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.43.44-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.43.44-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.43.44-md.png 768w\"></figure><p>Here’s the original map with digital labels:</p><pre><code class=\"language-wl\">In[]:= With[\n   {cf = ColorData[91], plantLabels = Normal[plantPositions]}, \n   {colors = cf /@ Range[Length[#]] &amp;@Keys[plantLabels]}, \n   Labeled[HighlightImage[garden, Thread[{colors, Values[plantLabels]}]],SwatchLegend[##, LegendLayout -&gt; {&quot;Column&quot;, 2}] &amp; @@ {colors, Keys[plantLabels]}, Right] \n  ]\n</code></pre>\n<figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/49/1vekqgrzks5j4.png\" alt=\"\" width=\"1492\" height=\"1224\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1vekqgrzks5j4-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1vekqgrzks5j4-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1vekqgrzks5j4-md.png 768w\"></figure><p>And here’s the network representation of the path:</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/1kzout3gawhly.png\" alt=\"\" width=\"329\" height=\"216\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1kzout3gawhly-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1kzout3gawhly-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1kzout3gawhly-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/0s66s0ibad5d5.png\" alt=\"\" width=\"562\" height=\"864\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/0s66s0ibad5d5-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0s66s0ibad5d5-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0s66s0ibad5d5-md.png 768w\"></figure><h2 id=\"investigating-the-structure-of-the-digital-garden\">Investigating the structure of the digital garden</h2>\n<p>Now that I have these computational representations of the garden, I can use them to answer pretty cool conceptual questions about the data. For example:</p><ul>\n<li><p>On a long random walk through the garden, where am I likely to spend most of my time?</p></li>\n<li><p>To what extent can I simplify the path network without losing the essence of the path’s design and overall pattern? </p></li>\n<li><p>What communities do the garden plants form with their neighbors at different scales?</p></li>\n</ul>\n<h3 id=\"wandering-about-the-garden\">Wandering about the garden</h3>\n<h4 id=\"taking-random-walks\">Taking random walks</h4>\n<p>If I were to walk the garden path randomly or according to some method, I might like to know where I’m most likely to end up after some time. It turns out that this sort of thing is quite easy to simulate assuming that my heuristics for deciding where to go can be well approximated by deterministic or probabilistic rules (and they usually can).</p><p>For example, if I walked the path completely at random, I could describe my walk as an algorithm: “Before I take my next step, I’ll choose a random direction along the path.” It turns out that when we aimlessly wander along garden paths, this specific algorithm does not capture what we do well as it results in a high probability of backtracking. In practice, when wandering about a garden, we are much more likely to follow the direction we started with than we are to backtrack. A better algorithmic approximation would be to say that we walk randomly but only allow ourselves to backtrack when we’ve reached a dead end. </p><p>Here’s a simulation of such a random walk on the garden path network:</p><pre><code class=\"language-wl\">In[]:= ListAnimate[\n   With[{n = 100}, Map[\n     HighlightGraph[gardenPath, Style[Last[#], StandardGreen], VertexSize -&gt; .5] &amp;, \n     NestList[\n      Apply[{#2, RandomChoice[\n           With[{possibleNextSteps = VertexOutComponent[gardenPath, #2, {1}]}, \n            If[\n             VertexDegree[gardenPath, #2] &gt; 1, \n             Complement[VertexOutComponent[gardenPath, #2, {1}], {#1}],\n             possibleNextSteps]]]} &amp;, #] &amp;, \n      {Null, 1}, n]]], \n   AnimationRunning -&gt; False, AnimationTimeIndex -&gt; 5, DefaultDuration -&gt; 10]\n</code></pre>\n<figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/49/randomwalk.gif\" alt=\"\" width=\"569\" height=\"864\"></figure><p>Okay, so if I were to randomly wander around the garden for a long time, never backtracking, what locations along the path am I likely to spend most of my time in? </p><p>To estimate an answer to this question, we can take a sample of simulated random non-backtracking walks through the garden, and tally the number of visits to each location. We should make the additional assumption that the walks start at one of the garden entrances, chosen at random. Here’s what that looks like with the tallies represented as the sizes of the nodes on the garden path network:</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/1rxncra20r6yl.png\" alt=\"\" width=\"2358\" height=\"1488\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1rxncra20r6yl-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1rxncra20r6yl-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1rxncra20r6yl-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/1ni29au7ly1tt.png\" alt=\"\" width=\"1255\" height=\"948\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1ni29au7ly1tt-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1ni29au7ly1tt-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1ni29au7ly1tt-md.png 768w\"></figure><p>Of course, this is an approximation and the results are biased by the specific choices involved in my translation of the continuous real-world path into a discrete network representation. That said, it’s a reasonable approximation, and one that matches my personal experience of leisurely strolling through the garden with no clear direction.</p><h4 id=\"a-short-statistical-tangent\">A short statistical tangent</h4>\n<p>Across trajectories, the distribution of path-location visit frequencies looks like this:</p><pre><code class=\"language-wl\">In[]:= Histogram[\n   Flatten[Map[Values@*Normal@*Counts, walks]], \n   ChartStyle -&gt; Lighter[StandardBlue, .5]]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/1ndgnsonoyh3f.png\" alt=\"\" width=\"720\" height=\"427\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1ndgnsonoyh3f-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1ndgnsonoyh3f-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1ndgnsonoyh3f-md.png 768w\"></figure><p>Here’s a model distribution that fits the observed histogram well:</p><pre><code class=\"language-wl\">In[]:= dist = FindDistribution[Flatten[Map[Values@*Normal@*Counts, walks]]]\n</code></pre>\n<pre><code class=\"language-wl\">Out[]= MixtureDistribution[{0.798666, 0.201334}, {BenfordDistribution[6], BinomialDistribution[124, 0.0535239]}]\n</code></pre>\n<p>It can be represented as a piecewise function:</p><pre><code class=\"language-wl\">In[]:= TraditionalForm[PDF[dist, x]]\n</code></pre>\n<p>Likewise, I can generate histograms of visit frequencies for specific locations in the garden:</p><pre><code class=\"language-wl\">In[]:= Dataset[Dataset[KeySort@DeleteMissing[Normal[Transpose[Dataset[Map[Counts, walks]]]], \\[Infinity]]][All, Histogram[#, ChartStyle -&gt; Lighter[StandardBlue, .5]] &amp;], MaxItems -&gt; 4]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/08x6b11a9yb4b.png\" alt=\"\" width=\"362\" height=\"720\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/08x6b11a9yb4b-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/08x6b11a9yb4b-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/08x6b11a9yb4b-md.png 768w\"></figure><p>And I can estimate fit distributions to the histograms for each location:</p><pre><code class=\"language-wl\">In[]:= Dataset[Dataset[KeySort@DeleteMissing[Normal[Transpose[Dataset[Map[Counts, walks]]]], \\[Infinity]]][All, FindDistribution], MaxItems -&gt; 4]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/Screenshot-2025-09-13-at-20.49.05.png\" alt=\"Image description\" width=\"2086\" height=\"284\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.05-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.05-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.05-md.png 768w\"></figure><p>Since these distributions are not normal, we can use the median as our measure of central tendency:</p><pre><code class=\"language-wl\">In[]:= Dataset[Dataset[KeySort@Map[Values, GroupBy[Flatten[Map[Normal@*Counts, walks]], First]]][All, Median], MaxItems -&gt; 4]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/Screenshot-2025-09-13-at-20.49.35.png\" alt=\"Image description\" width=\"250\" height=\"undefined\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.35-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.35-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.35-md.png 768w\"></figure><h3 id=\"the-skeleton-of-the-garden-path\">The skeleton of the garden path</h3>\n<p>That statistical dive in the last section was helpful for getting a sense of the network’s structure, but it also made me curious about something else: what happens if we start stripping it down to its bones? We have this detailed representation of every path junction and connection, but how much of that complexity is actually doing any work? </p><p>How much can I simplify the network without damaging the pattern? This is pretty subjective, as we don’t all agree on what might qualify as a destructive act, or what ought to be preserved in the first place. I’ve chosen to consider distances along the path to be unimportant, but the cycles on the path to be fundamental. </p><p>There are 21 cycles in the network. Each cycle is made up of a set of edges on the network, and for every cycle, the edge cycle matrix provides the list of these edges.</p><pre><code class=\"language-wl\">In[]:= With[{m = EdgeCycleMatrix[gardenPath]}, \n   ArrayPlot[m, FrameTicks -&gt; True, PlotLegends -&gt; Automatic, ImageSize -&gt; Medium, PlotLabel -&gt; Text[Style[&quot;Edge cycle matrix of the garden path network:&quot;, 14]]] \n  ]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/122y8z9xg3lkd.png\" alt=\"\" width=\"793\" height=\"266\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/122y8z9xg3lkd-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/122y8z9xg3lkd-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/122y8z9xg3lkd-md.png 768w\"></figure><p>Up to this point I’ve presented the garden path network with its vertices in positions that match their locations on the garden map, but I can use other layouts. Here it is laid out using a spring embedding method:</p><pre><code class=\"language-wl\">In[]:= Graph[EdgeList[gardenPath]]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/0gbdnpkehdzsx.png\" alt=\"\" width=\"720\" height=\"298\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/0gbdnpkehdzsx-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0gbdnpkehdzsx-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0gbdnpkehdzsx-md.png 768w\"></figure><p>The network looks different, but as far as I’m concerned, it’s the same. The patterns that matter to me (the cycles) are preserved. So how might I simplify the network as much as possible while still preserving all the cycles? </p><p>Notice that if distances along the path aren’t important, we can replace any node that has exactly two neighbors with a new edge that goes directly between its neighbors. Essentially, anywhere that we find a connected to exactly two other nodes, we can remove it and directly connect its neighboring nodes. This operation is a form of path pruning that simplifies the network into a kind of ****skeleton representation. The resulting network retains all loop structures but loses path length information. </p><p>To apply this simplification to the network, we must be able to perform two tasks: identifying nodes on the network that have exactly two neighbors, and replacing any such node with an edge between its two neighbors. I’ve implemented this functionality below:</p><pre><code class=\"language-wl\">In[]:= ClearAll[selectTwoNeighborNodes]\n selectTwoNeighborNodes[g_Graph] := Keys[Select[AssociationThread[VertexList[g] -&gt; VertexDegree[g]], # == 2 &amp;]]\n</code></pre>\n<pre><code class=\"language-wl\">In[]:= ClearAll[deletePassThroughNodes]\n deletePassThroughNodes[g_Graph] := First[NestWhile[{#, First[selectTwoNeighborNodes[#]], Length[selectTwoNeighborNodes[#]]} &amp;@EdgeAdd[VertexDelete[#[[1]], #[[2]]], (UndirectedEdge @@ VertexOutComponent[#[[1]], #[[2]], {1}])] &amp;, {g, First[selectTwoNeighborNodes[g]], Length[selectTwoNeighborNodes[g]]}, TrueQ[Last[#] &gt; 1] &amp;, 1]] /; MemberQ[VertexDegree[g], 2]\n</code></pre>\n<p>Here’s the simplified path network with a geographic layout:</p><pre><code class=\"language-wl\">In[]:= deletePassThroughNodes[gardenPath]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/1e5ofbtjscfec.png\" alt=\"\" width=\"573\" height=\"864\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1e5ofbtjscfec-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1e5ofbtjscfec-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1e5ofbtjscfec-md.png 768w\"></figure><p>And here it is with a spring layout:</p><pre><code class=\"language-wl\">In[]:= Graph[EdgeList[deletePassThroughNodes[gardenPath]]]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/0fjxv0l1wnb10.png\" alt=\"\" width=\"720\" height=\"261\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/0fjxv0l1wnb10-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0fjxv0l1wnb10-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0fjxv0l1wnb10-md.png 768w\"></figure><h3 id=\"spatial-network-community-analysis-of-the-sunken-garden-plants\">Spatial network community analysis of the Sunken Garden plants</h3>\n<p>Let’s shift from the paths to the plants themselves. Here’s a breakdown of the Sunken Garden’s plant community make-up (the human-designed component):</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/49/1v0p13ny7tbkc.png\" alt=\"\" width=\"2539\" height=\"369\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1v0p13ny7tbkc-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1v0p13ny7tbkc-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1v0p13ny7tbkc-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/0966puyqeqwz7.png\" alt=\"\" width=\"500\" height=\"undefined\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/0966puyqeqwz7-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0966puyqeqwz7-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0966puyqeqwz7-md.png 768w\"></figure><p>We’ve been thinking about how people might move through the space, but the plants have spatial relationships of their own: clusters and neighborhoods that form based on proximity, growing conditions, etc. Can we detect these plant communities computationally? How do they change depending on the scale at which we search for them? </p><p>To answer these questions, we need to know how strongly plants interact with each other as a function of their distances from one another. This will vary from plant to plant and between plant pairs as individual plants may prefer to interact with some species above others. Since we don’t have this information readily available but still have the intuition that the degree of interaction between plants is somewhat a function of the distance between them, I’m going to make an obviously wrong assumption that will still turn out to be instructive: That the amount of interaction between any two plants decreases linearly as a function of mutual distance, and that the slope and y intercept are the same across plants. </p><p>Botanists, suspend your disbelief! But you’re right to ask: why should we decide to make this assumption, especially if we expect it to be inaccurate? The answer is that although it flattens the world and its complexity somewhat, it’s about to allow us to tease out some other interesting properties of the network of plants in the garden.</p><p>Let’s imagine that our assumption is true: That the amount of interaction that happens between any two plants is described by the same linear function of the distance between the plants. In that case, to model the network of interactions between plants at a spatial scale $r$, we can simply imagine disks of radius $r$ centered at every plant and take note of which nodes fall inside what disks. Wherever a plant finds itself in a disk, we assess that the plant is close enough to its neighbor at the center of the disk for them to interact in some way. When two plants interact at a designated scale, we draw a link between them, building a model spatial network of the Sunken Garden’s plant interactions.</p><p>Here’s an interactive demonstration of the process:</p><pre><code class=\"language-wl\">In[]:= Manipulate[\n   Show[\n    garden, \n    With[\n     {g = NearestNeighborGraph[#, {All, N[172/10]*radius}] &amp;@Flatten[Values[Normal[plantPositions]], 1]}, \n     With[\n      {labelRules = ((Thread[Keys[#1] -&gt; Callout @@@ #1] &amp;)[Flatten[Thread /@ Reverse /@ Normal[Normal[plantPositions]]]])},\n      {edges = EdgeList[g] /. labelRules}, \n      Graph[Values[labelRules], edges, VertexCoordinates -&gt; Thread[Values[Association[labelRules]] -&gt; GraphEmbedding[g]], EdgeStyle -&gt; Thick] \n     ] \n    ]], {{radius, 5}, 0, 10}, SaveDefinitions -&gt; True]\n</code></pre>\n<figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/49/1rs758hzqi6w9.gif\" alt=\"\" width=\"500\" height=\"undefined\"></figure><p>Since we can now estimate spatial networks of plant interactions based on distance, we can also apply community detection methods to these networks to make estimates of where interactions concentrate in the network at different scales:</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/0ydgmlj7ow2fk.png\" alt=\"\" width=\"2014\" height=\"726\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/0ydgmlj7ow2fk-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0ydgmlj7ow2fk-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0ydgmlj7ow2fk-md.png 768w\"></figure><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/49/1betucekiu8z2.gif\" alt=\"\" width=\"500\" height=\"undefined\"></figure><p>This spatial network analysis reveals how the Sunken Garden’s plant communities might emerge at different interaction scales. For radii under approximately 1.75 feet, there are no detected communities, as no plants are within that distance of one another. At radii between two and three feet, we see tightly clustered micro-communities. For radii between four and five feet, we find medium-sized communities that overlap meaningfully with the intentional design and pattern of the garden. At this scale, the garden path seems to contribute to delineating the community structure. As we increase the interaction radius to six to ten feet, these smaller communities merge. For a radius of ten feet, there are four detected communities, two of which cover the majority of the garden:</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/0zb92jxye00nb.png\" alt=\"\" width=\"500\" height=\"undefined\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/0zb92jxye00nb-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0zb92jxye00nb-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0zb92jxye00nb-md.png 768w\"></figure><p>The modularity-based community detection shows that even under our simplified assumption of uniform distance-based interactions, the garden shows clear spatial clustering that changes meaningfully with scale. At intermediate scales, the communities appear to align with the garden’s major design elements—the central beds, perimeter plantings, and transitional zones.</p><p>Of course, our linear distance model is a deliberate oversimplification. In reality, plant interactions depend on species compatibility, root systems, light requirements, soil preferences, and many other factors that vary between species pairs. Some plants are natural companions that thrive in close proximity, while others compete aggressively or have allelopathic effects on their neighbors.</p><p>Despite these limitations, the spatial community analysis shows how computational methods can reveal organizational patterns in designed landscapes that might not be immediately apparent. The scale-dependent nature of the detected communities suggests that the Sunken Garden operates as a multi-layered spatial system. The alignment of intermediate-scale communities with major design elements reflects the fact that the garden’s layout creates natural zones of interaction.</p><h3 id=\"plant-data-analysis\">Plant data analysis</h3>\n<p>I reached out to some contacts at the college for information about the garden plants that I could add to the garden website. [<strong>Name</strong>], the current Sunken Garden curator shared a species information booklet he wrote with me, the Edible Plant List of the Sunken Garden, which contained all sorts of helpful information about the plants. I used OCR alongside a mix of methods to extract the data from the booklet, and convert them to a JSON dataset, which I’ve reproduced here:</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/49/0krwxhsw9rjxb.png\" alt=\"\" width=\"831\" height=\"39\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/0krwxhsw9rjxb-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0krwxhsw9rjxb-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0krwxhsw9rjxb-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/Screenshot-2025-09-13-at-20.50.42.png\" alt=\"Image description\" width=\"1882\" height=\"636\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.50.42-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.50.42-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.50.42-md.png 768w\"></figure><p>The dataset contains detailed information about 56 plant species in the Sunken Garden, including their Latin names, families, growing requirements, physical characteristics, and seasonal information.</p><p>The data reveal clear patterns in plant selection. Most species are adaptable to varying light conditions:</p><pre><code class=\"language-wl\">In[]:= Dataset[ReverseSort@KeyMap[First, Normal[Counts[Values[Dataset[ConstructColumns[plantData, &quot;sun&quot;]]]]]]]\n</code></pre>\n<table>\n<thead>\n<tr>\n<th>Full sun to partial shade</th>\n<th>Partial shade to full shade</th>\n<th>Full sun</th>\n<th>Partial shade</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>32</td>\n<td>13</td>\n<td>8</td>\n<td>3</td>\n</tr>\n</tbody></table>\n<p>The tally of plant water requirements show a similar preference for adaptable species:</p><pre><code class=\"language-wl\">In[]:= Dataset[ReverseSort@KeyMap[First, Normal[Counts[Values[Dataset[ConstructColumns[plantData, &quot;water&quot;]]]]]]]\n</code></pre>\n<table>\n<thead>\n<tr>\n<th>Medium</th>\n<th>Medium to wet</th>\n<th>Dry to medium</th>\n<th>Low</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>38</td>\n<td>11</td>\n<td>6</td>\n<td>1</td>\n</tr>\n</tbody></table>\n<p>Plant heights cluster around smaller values, with almost all species under 10 feet, and most 5 feet or under:</p><pre><code class=\"language-wl\">In[]:= Histogram[Flatten[Normal[Values[Dataset[ConstructColumns[plantData, {\n         &quot;height&quot; -&gt; Function[Around[Mean[#], Mean[#] - Last[#]] &amp;@ToExpression[\n             &quot;{&quot; &lt;&gt; StringReplace[#&quot;height&quot;, {&quot; to &quot; -&gt; &quot;,&quot;, &quot; feet&quot; | &quot;foot&quot; -&gt; &quot;&quot;}] &lt;&gt; &quot;}&quot;]]}]]]]], \n   PlotRange -&gt; Full, ChartStyle -&gt; Lighter[StandardBlue]]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/02ft24cmj2pt4.png\" alt=\"\" width=\"720\" height=\"449\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/02ft24cmj2pt4-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/02ft24cmj2pt4-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/02ft24cmj2pt4-md.png 768w\"></figure><p>Spread values show a similar pattern, with most plants staying compact:</p><pre><code class=\"language-wl\">In[]:= Histogram[Flatten[Normal[Values[Dataset[ConstructColumns[plantData, {\n         &quot;spread&quot; -&gt; Function[Around[Mean[#], Mean[#] - Last[#]] &amp;@ToExpression[\n             &quot;{&quot; &lt;&gt; StringReplace[#&quot;spread&quot;, {&quot; to &quot; -&gt; &quot;,&quot;, &quot; feet&quot; | &quot;foot&quot; -&gt; &quot;&quot;}] &lt;&gt; &quot;}&quot;]]}]]]]], \n   PlotRange -&gt; Full, ChartStyle -&gt; Lighter[StandardBlue]]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/1n0e1h3g3zydg.png\" alt=\"\" width=\"720\" height=\"449\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1n0e1h3g3zydg-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1n0e1h3g3zydg-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1n0e1h3g3zydg-md.png 768w\"></figure><p>Height and spread scatter plot with a LOESS fit:</p><pre><code class=\"language-wl\">In[]:= ListFitPlot[Normal[Values[Dataset[ConstructColumns[plantData, {\n        &quot;height&quot; -&gt; Function[Around[Mean[#], Mean[#] - Last[#]] &amp;@ToExpression[\n            &quot;{&quot; &lt;&gt; StringReplace[#&quot;height&quot;, {&quot; to &quot; -&gt; &quot;,&quot;, &quot; feet&quot; | &quot;foot&quot; -&gt; &quot;&quot;}] &lt;&gt; &quot;}&quot;]], \n        &quot;spread&quot; -&gt; Function[Around[Mean[#], Mean[#] - Last[#]] &amp;@ToExpression[\n            &quot;{&quot; &lt;&gt; StringReplace[#&quot;spread&quot;, {&quot; to &quot; -&gt; &quot;,&quot;, &quot; feet&quot; | &quot;foot&quot; -&gt; &quot;&quot;}] &lt;&gt; &quot;}&quot;]]}]]]], \n   PlotRange -&gt; Full, PlotFit -&gt; &quot;Local&quot;, PlotFitElements -&gt; &quot;BandCurves&quot;]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/0ifdxwc5akzzx.png\" alt=\"\" width=\"720\" height=\"458\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/0ifdxwc5akzzx-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0ifdxwc5akzzx-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0ifdxwc5akzzx-md.png 768w\"></figure><p>The plant data analysis confirms that the Sunken Garden prioritizes adaptable, compact species that do well in variable conditions.</p><h2 id=\"packaging-and-deploying-a-website\">Packaging and deploying a website</h2>\n<p>The primary goal was always to create an accessible digital companion for garden visitors. The website allows people to click on plant locations for detailed species information, click on path nodes to see what plants are within short and medium distance radii of that spot, and toggle between different organizational views (by species, growing requirements, bloom time, and other characteristics).</p><p>The computational analyses presented here emerged from my curiosity about the underlying spatial patterns in this designed landscape. While some insights, like meaningful plant interaction distances, influenced minor interface details, the mathematical investigations are primarily an addendum for visitors interested in exploring the garden through a computational lens. </p><p>Here’s the sunken garden website directory tree:</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/49/1mjnn1jubt0kw.png\" alt=\"\" width=\"1995\" height=\"40\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1mjnn1jubt0kw-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1mjnn1jubt0kw-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1mjnn1jubt0kw-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/1vhdd4pplaj9f.png\" alt=\"\" width=\"1355\" height=\"965\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1vhdd4pplaj9f-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1vhdd4pplaj9f-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1vhdd4pplaj9f-md.png 768w\"></figure><p>The website uses a straightforward structure with JSON data files containing the computational representations developed through the Wolfram analysis. The network visualizations use the force-graph library, while most of the implementation work went into defining the logic for different information modals and user interactions. I deployed the site using GitHub Pages for free hosting.</p><h2 id=\"parting-thoughts\">Parting thoughts</h2>\n<p>Gardens occupy a middle ground between artificial and natural systems. They blend human intention with processes that operate beyond conscious control. This hybrid status makes them revealing subjects for computational analysis because they illuminate how spatial patterns emerge independent of design intentions.</p><p>When the distance-based community detection occasionally aligns with garden design elements, it raises interesting questions about the relationship between our analytical frameworks and spatial reality. The patterns emerge from specific modeling choices - the distance thresholds we select, the assumption that all plants interact uniformly, the particular community detection algorithm we apply. Yet the occasional alignment with actual design elements suggests these simplified models can still capture meaningful aspects of spatial organization.</p><p>The computational approach offers a way to think systematically about spatial relationships, even when our assumptions are deliberately oversimplified. Gardens provide a useful testing ground for these methods precisely because we can compare analytical results against known design intentions and see where the models succeed or fall short.</p><p>You can explore the interactive map <a href=\"https://phileasdg.github.io/coa-sunken-garden/\">here</a>.</p><h2 id=\"appendix-code-initializations\">Appendix: Code Initializations</h2>\n<h3 id=\"project-variables\">Project variables</h3>\n<figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/49/1phbx87cq593e.png\" alt=\"\" width=\"266\" height=\"216\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/1phbx87cq593e-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1phbx87cq593e-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1phbx87cq593e-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/19f9obkqzl49e.png\" alt=\"\" width=\"394\" height=\"40\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/19f9obkqzl49e-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/19f9obkqzl49e-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/19f9obkqzl49e-md.png 768w\"></figure><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/49/17sc7czxhzxy4.png\" alt=\"\" width=\"314\" height=\"216\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/17sc7czxhzxy4-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/17sc7czxhzxy4-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/17sc7czxhzxy4-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/49/01wokmrx0usvg.png\" alt=\"\" width=\"765\" height=\"38\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/49/responsive/01wokmrx0usvg-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/01wokmrx0usvg-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/01wokmrx0usvg-md.png 768w\"></figure><pre><code class=\"language-wl\">In[]:= walks = With[{\n         (*Walk trajectory samples:*) walks = 2000, \n         (*Steps per walk:*) steps = 200, \n         (*Garden entrances:*) startNodes = {1, 6, 64, 69}}, \n        \n        Table[Map[Last, NestList[\n           Apply[{#2, RandomChoice[\n                With[{possibleNextSteps = VertexOutComponent[gardenPath, #2, {1}]}, \n                 If[\n                  VertexDegree[gardenPath, #2] &gt; 1, \n                  Complement[VertexOutComponent[gardenPath, #2, {1}], {#1}],\n                  possibleNextSteps]]]} &amp;, #] &amp;, \n           {Null, RandomChoice[startNodes]}, steps]], walks] \n        ];\n</code></pre>\n<pre><code class=\"language-wl\">In[]:= dist = FindDistribution[Flatten[Map[Values@*Normal@*Counts, walks]]];\n</code></pre>\n<pre><code class=\"language-wl\">In[]:= ClearAll[selectTwoNeighborNodes]\n selectTwoNeighborNodes[g_Graph] := Keys[Select[AssociationThread[VertexList[g] -&gt; VertexDegree[g]], # == 2 &amp;]]\n</code></pre>\n<pre><code class=\"language-wl\">In[]:= ClearAll[deletePassThroughNodes]\n deletePassThroughNodes[g_Graph] := First[NestWhile[\n         {#, First[selectTwoNeighborNodes[#]], Length[selectTwoNeighborNodes[#]]} &amp;@EdgeAdd[VertexDelete[#[[1]], #[[2]]], (UndirectedEdge @@ VertexOutComponent[#[[1]], #[[2]], {1}])] &amp;, \n         {g, First[selectTwoNeighborNodes[g]], Length[selectTwoNeighborNodes[g]]}, TrueQ[Last[#] &gt; 1] &amp;, 1]] /; MemberQ[VertexDegree[g], 2]\n</code></pre>\n<h3 id=\"misc-tools\">Misc tools</h3>\n<h4 id=\"drawing-blobs\">Drawing blobs</h4>\n<p>Define a function to draw blobs:</p><pre><code class=\"language-wl\">In[]:= ClearAll[iBlobs]\n iBlobs[style_, pts_, size_] := Block[{epts}, \n       epts = Flatten[Tuples[CoordinateBounds[#, size]] &amp; /@ pts, 1]; \n       {style, FilledCurve@BSplineCurve[\n              MeshPrimitives[ConvexHullMesh[epts], 1][[All, 1, 1]], \n              SplineClosed -&gt; True, SplineDegree -&gt; 2]}]\n</code></pre>\n",
            "image": "https://phileasdg.github.io/media/posts/49/banner.png",
            "author": {
                "name": "Phileas Dazeley-Gaist"
            },
            "tags": [
                   "Wolfram Language",
                   "Network Science",
                   "Modelling",
                   "Mathematica",
                   "Environmental Science",
                   "Ecology"
            ],
            "date_published": "2025-08-23T02:06:57+02:00",
            "date_modified": "2025-10-10T17:45:15+02:00"
        },
        {
            "id": "https://phileasdg.github.io/terrestrial-ecoregions-of-the-world-computational-insights-into-global-biodiversity/",
            "url": "https://phileasdg.github.io/terrestrial-ecoregions-of-the-world-computational-insights-into-global-biodiversity/",
            "title": "Terrestrial Ecoregions of the World: Computational Insights Into Global Biodiversity",
            "summary": "Note: This post was originally a short technical article I shared on&hellip;",
            "content_html": "<p><strong>Note:</strong> This post was originally a short technical article I shared on the Wolfram Community forums. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3445374\">here</a>. </p><h2 id=\"introduction\">Introduction</h2>\n<p>Ecoregions are distinct ecological zones with specific environmental conditions (climate, topography, soil composition…), habitats, and species. Each ecoregion contains characteristic species and ecological communities that are adapted to the region’s environment.</p><p>The Ecoregions2017©Resolve map is a revised version of the widely used 2001 map of terrestrial ecoregions of the world, originally developed by <a href=\"https://doi.org/10.1641/0006-3568(2001)051%5B0933:TEOTWA%5D2.0.CO;2\">Olson et al</a>. The new map breaks up the Earth’s land into 846 distinct terrestrial ecoregions nested within 14 terrestrial <a href=\"https://en.wikipedia.org/wiki/Biome\">biomes</a>. An interactive version of the map is available online <a href=\"https://ecoregions.appspot.com/\">here</a>, and the work is discussed in the following article in BioScience: <a href=\"https://academic.oup.com/bioscience/article/67/6/534/3102935?login=false\">An Ecoregion-Based Approach to Protecting Half the Terrestrial Realm</a> <a href=\"https://academic.oup.com/bioscience/article/67/6/534/3102935?login=false\">(Dinerstein et al. 2017)</a>.</p><p>Terrestrial biomes of the world according to Dinerstein and Olson (also used in the <a href=\"https://www.worldwildlife.org/publications/global-200\">WWF Global 200 classification</a>) already have computational representations in Wolfram Language. Here’s how one might represent them on a map:</p><p><em>Define a list of biomes:</em></p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/47/0svwohkmtobvo.png\" alt=\"\" width=\"2522\" height=\"108\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/0svwohkmtobvo-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0svwohkmtobvo-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0svwohkmtobvo-md.png 768w\"></figure><p><em>Produce a map of major world biomes:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/0ufjsmh9hw8yp.png\" alt=\"\" width=\"1262\" height=\"168\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/0ufjsmh9hw8yp-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0ufjsmh9hw8yp-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0ufjsmh9hw8yp-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/13376kglpv3ht.png\" alt=\"\" width=\"1152\" height=\"576\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/13376kglpv3ht-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/13376kglpv3ht-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/13376kglpv3ht-md.png 768w\"></figure><p>The Ecoregions2017©Resolve data provide a more detailed ecological classification compared to the broader biome categories. While biomes represent large ecological zones based on similar climate conditions and dominant vegetation types, ecoregions offer finer granularity by incorporating specific environmental conditions, habitats, and species unique to each region.</p><p>Applications for the Ecoregions2017©Resolve include:</p><ul>\n<li>Depicting the global distributions of species and ecological communities</li>\n<li>Modeling ecological impacts of climate change</li>\n<li>Assisting in the development of conservation strategies</li>\n<li>Reporting progress toward international conservation targets such as the <a href=\"https://www.cbd.int/sp/targets\">Aichi targets established by the Convention on Biological Diversity</a>.</li>\n</ul>\n<p>In this short article, I’ll construct a dataset of Ecoregions2017©Resolve data, demonstrate how to create ecoregion maps, apply data science techniques to filter and summarize the data, and make use of the <a href=\"https://resources.wolframcloud.com/FunctionRepository/resources/INaturalistSearch/\">INaturalistSearch</a> function to search for species observations within ecoregions.</p><h2 id=\"setup\">Setup</h2>\n<p>The Ecoregions2017©Resolve data are available <a href=\"https://storage.googleapis.com/teow2016/Ecoregions2017.zip\">here</a>, licensed under <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY 4.0</a>. Let’s load them in.</p><p>With the zip file downloaded from this page unzipped and copied to my chosen project directory, the data are ready to import.</p><p><em>Import the ecoregion shapefile data:</em></p><pre><code class=\"language-wl\">In[]:= freshwaterEcoregionsShapefileData = Association[Import[(*Path to the shapefile:*)FileNameJoin[{NotebookDirectory[], &quot;2017 Ecoregions&quot;, &quot;Ecoregions2017&quot;, &quot;Ecoregions2017.shp&quot;}], &quot;Data&quot;]];\n</code></pre>\n<p>In addition to the data found in the shapefile, the online interactive map also includes links to informative ecoregion descriptions hosted on <a href=\"http://www.oneearth.org\">www.oneearth.org</a>. Let’s incorporate these links into our dataset.</p><p><em>Define an association of ecoregion OneEarth pages:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/1imj3zkxicqz0.png\" alt=\"\" width=\"327\" height=\"41\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/1imj3zkxicqz0-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1imj3zkxicqz0-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1imj3zkxicqz0-md.png 768w\"></figure><p><em>Wrangle the data to produce a nice tabular dataset:</em></p><pre><code class=\"language-wl\">In[]:= ecoregionsTab = Tabular[Join[\n       (*LabeledData columns:*) ## &amp; @@ KeyValueMap[Dataset[Map[Association, Thread[#1 -&gt; #2]]] &amp;, Association[freshwaterEcoregionsShapefileData[&quot;LabeledData&quot;]]],\n       (*Geometry column:*) Dataset[Map[&lt;|&quot;Geometry&quot; -&gt; #|&gt; &amp;, freshwaterEcoregionsShapefileData[&quot;Geometry&quot;]]], 2]] // \n     (*Clean up the data and create new columns:*) \n      TransformColumns[#, {\n        (*Interpret color data:*) \n         &quot;COLOR&quot; -&gt; (RGBColor[#&quot;COLOR&quot;] &amp;), &quot;COLOR_BIO&quot; -&gt; (RGBColor[#&quot;COLOR_BIO&quot;] &amp;), &quot;COLOR_NNH&quot; -&gt; (RGBColor[#&quot;COLOR_NNH&quot;] &amp;), \n        (*Ecoregion OneEarth page column:*) \n         &quot;OneEarthPage&quot; -&gt; Function[If[KeyMemberQ[ecoregionPages, #&quot;ECO_NAME&quot;], ecoregionPages[#&quot;ECO_NAME&quot;], Missing[&quot;Not available&quot;]]], \n        (*GeoBounds regions column:*) \n         &quot;GeoBoundsRegion&quot; -&gt; Function[GeoBoundsRegion[GeoBounds[#Geometry]]]}] &amp; //(*Update column names:*)RenameColumns[#, {&quot;ObjectID&quot;, &quot;EcoregionName&quot;, &quot;BiomeNumber&quot;, &quot;BiomeName&quot;, &quot;Realm&quot;, &quot;EcoBiome&quot;, &quot;ProtectionStatusID&quot;, &quot;EcoregionID&quot;, &quot;ShapeLength&quot;, &quot;ShapeArea&quot;, &quot;ProtectionStatus&quot;, &quot;EcoregionColor&quot;, &quot;BiomeColor&quot;, &quot;ProtectionStatusColor&quot;, &quot;License&quot;}] &amp;;\n</code></pre>\n<p>To avoid having to recompute this, I’ll save it to a parquet file and reload the data:</p><p><em>Define the save path :</em></p><pre><code class=\"language-wl\">In[]:= ecoregionsTabPath = FileNameJoin[{NotebookDirectory[], &quot;2017 Ecoregions&quot;, &quot;ecoregions2017.parquet&quot;}];\n</code></pre>\n<p><em>Save the dataset :</em></p><pre><code class=\"language-wl\">In[]:= Export[ecoregionsTabPath, ecoregionsTab];\n</code></pre>\n<p><em>Load the data from the file, casting ID columns as machine integers:</em></p><pre><code class=\"language-wl\">In[]:= ecoregionsTab = CastColumns[Import[ecoregionsTabPath], {&quot;ObjectID&quot; -&gt; &quot;MachineInteger&quot;, &quot;BiomeNumber&quot; -&gt; &quot;MachineInteger&quot;, &quot;ProtectionStatusID&quot; -&gt; &quot;MachineInteger&quot;, &quot;EcoregionID&quot; -&gt; &quot;MachineInteger&quot;}]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/01pn8ye1s90is.png\" alt=\"\" width=\"1788\" height=\"595\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/01pn8ye1s90is-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/01pn8ye1s90is-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/01pn8ye1s90is-md.png 768w\"></figure><p><em>Inspect the structure of the dataset:</em></p><pre><code class=\"language-wl\">In[]:= TabularStructure[ecoregionsTab]\n</code></pre>\n<table>\n<thead>\n<tr>\n<th>ColumnKey</th>\n<th>ColumnType</th>\n<th>NonMissingCount</th>\n<th>MissingCount</th>\n<th>ByteCount</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ObjectID</td>\n<td>Integer64</td>\n<td>847</td>\n<td>0</td>\n<td>7016</td>\n</tr>\n<tr>\n<td>EcoregionName</td>\n<td>String</td>\n<td>847</td>\n<td>0</td>\n<td>32271</td>\n</tr>\n<tr>\n<td>BiomeNumber</td>\n<td>Integer64</td>\n<td>847</td>\n<td>0</td>\n<td>7016</td>\n</tr>\n<tr>\n<td>BiomeName</td>\n<td>String</td>\n<td>847</td>\n<td>0</td>\n<td>37478</td>\n</tr>\n<tr>\n<td>Realm</td>\n<td>String</td>\n<td>847</td>\n<td>0</td>\n<td>15195</td>\n</tr>\n<tr>\n<td>EcoBiome</td>\n<td>String</td>\n<td>847</td>\n<td>0</td>\n<td>10411</td>\n</tr>\n<tr>\n<td>ProtectionStatusID</td>\n<td>Integer64</td>\n<td>847</td>\n<td>0</td>\n<td>7016</td>\n</tr>\n<tr>\n<td>EcoregionID</td>\n<td>Integer64</td>\n<td>847</td>\n<td>0</td>\n<td>7016</td>\n</tr>\n<tr>\n<td>ShapeLength</td>\n<td>Real64</td>\n<td>847</td>\n<td>0</td>\n<td>7008</td>\n</tr>\n<tr>\n<td>ShapeArea</td>\n<td>Real64</td>\n<td>847</td>\n<td>0</td>\n<td>7008</td>\n</tr>\n<tr>\n<td>ProtectionStatus</td>\n<td>String</td>\n<td>847</td>\n<td>0</td>\n<td>26600</td>\n</tr>\n<tr>\n<td>EcoregionColor</td>\n<td>InertExpression</td>\n<td>847</td>\n<td>0</td>\n<td>102016</td>\n</tr>\n<tr>\n<td>BiomeColor</td>\n<td>InertExpression</td>\n<td>847</td>\n<td>0</td>\n<td>102016</td>\n</tr>\n<tr>\n<td>ProtectionStatusColor</td>\n<td>InertExpression</td>\n<td>847</td>\n<td>0</td>\n<td>102016</td>\n</tr>\n<tr>\n<td>License</td>\n<td>String</td>\n<td>847</td>\n<td>0</td>\n<td>14647</td>\n</tr>\n<tr>\n<td>Geometry</td>\n<td>InertExpression</td>\n<td>847</td>\n<td>0</td>\n<td>1471945560</td>\n</tr>\n<tr>\n<td>OneEarthPage</td>\n<td>String</td>\n<td>844</td>\n<td>3</td>\n<td>63549</td>\n</tr>\n<tr>\n<td>GeoBoundsRegion</td>\n<td>InertExpression</td>\n<td>847</td>\n<td>0</td>\n<td>244312</td>\n</tr>\n</tbody></table>\n<h2 id=\"exploration\">Exploration</h2>\n<h3 id=\"visualizing-terrestrial-ecoregions\">Visualizing Terrestrial Ecoregions</h3>\n<h4 id=\"producing-ecoregion-maps\">Producing ecoregion maps</h4>\n<p>For a start, let’s suppose we’d like to plot the footprint of a specific ecoregion. Here’s one approach:</p><p><em>Extract and plot ecoregion geometry selected from a row in which the “EcoregionName” column matches a provided name:</em></p><pre><code class=\"language-wl\">In[]:= ecoregionsTab // Select[#, Function[#&quot;EcoregionName&quot; == &quot;Irrawaddy moist deciduous forests&quot;]] &amp; // First[Normal[Dataset[#][All, &quot;Geometry&quot;]]] &amp; // GeoGraphics // Rasterize\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/0cg3z0mxchqmk.png\" alt=\"\" width=\"438\" height=\"840\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/0cg3z0mxchqmk-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0cg3z0mxchqmk-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0cg3z0mxchqmk-md.png 768w\"></figure><p>In case you’re unfamiliar with the notation, “//“ (called <a href=\"https://reference.wolfram.com/language/ref/Postfix\">PostFix</a>) can be read as “and then”, and is one of the ways one can chain together function calls in Wolfram Language. For new WL users coming form scientific backgrounds, this is quite similar to pipes in Python and R.</p><p>We may also like to plot several ecoregion footprints. This time, let’s assume we’re matching to a list of ecoregion IDs.</p><p><em>Extract and plot ecoregion geometry from rows where the “EcoregionID” column matches one of the IDs in the provided list:</em></p><pre><code class=\"language-wl\">In[]:= ecoregionsTab // Select[#, Function[MemberQ[{649, 695, 812, 815}, #&quot;EcoregionID&quot;]]] &amp; // Normal[Dataset[#][All, \n       (*Extract geometry and ecoregion colors, and add tooltips to the footprints:*) {#EcoregionColor, Tooltip[#Geometry, #EcoregionName]} &amp;]] &amp; // Legended[\n     (*Plot the map:*) GeoGraphics[{GeoStyling[Opacity[.6]], #}], \n     (*Construct the legend:*) SwatchLegend[## &amp; @@ {#1, #2[[All, 2]]} &amp; @@ Transpose[#]]] &amp; // Rasterize\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/08u4lj1xmvw3p.png\" alt=\"\" width=\"1112\" height=\"840\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/08u4lj1xmvw3p-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/08u4lj1xmvw3p-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/08u4lj1xmvw3p-md.png 768w\"></figure><p>Note that in order to share this article online, I’ve had to rasterize these plots, which disables the tooltips. To enable the tooltips in this notebook, simply download it and delete calls to <a href=\"https://reference.wolfram.com/language/ref/Rasterize\">Rasterize</a>.</p><p>To make a world map of terrestrial ecoregions, we simply include all ecoregions in the plot.</p><p><em>Make a world Ecoregions map:</em></p><pre><code class=\"language-wl\">In[]:= Rasterize[GeoGraphics[{GeoStyling[Opacity[1]], Values[Normal[Dataset[ConstructColumns[ecoregionsTab, {&quot;EcoregionColor&quot;, &quot;Geometry&quot;}]]]]}, GeoProjection -&gt; &quot;Mercator&quot;, GeoBackground -&gt; White], ImageSize -&gt; Full]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/0h58k9z8lkdxs.png\" alt=\"\" width=\"1359\" height=\"1359\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/0h58k9z8lkdxs-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0h58k9z8lkdxs-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0h58k9z8lkdxs-md.png 768w\"></figure><h4 id=\"grouping-and-plotting-ecoregions-programmatically\">Grouping and plotting ecoregions programmatically</h4>\n<p>You’re likely to want to select many ecoregions at a time according to logical or mathematical criteria. Here are a few examples to get you started:</p><p><em>Find and plot the 3 largest ecoregions:</em></p><pre><code class=\"language-wl\">In[]:= Take[ReverseSortBy[ecoregionsTab, #&quot;ShapeArea&quot; &amp;], {2, 4}] // ConstructColumns[#, {&quot;EcoregionName&quot;, &quot;Geometry&quot;}] &amp; // MapApply[GeoGraphics[#2, PlotLabel -&gt; #1] &amp;, FromTabular[#, &quot;Matrix&quot;]] &amp;\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/0jqvkdooppmyi.png\" alt=\"\" width=\"1137\" height=\"288\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/0jqvkdooppmyi-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0jqvkdooppmyi-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0jqvkdooppmyi-md.png 768w\"></figure><p><em>Find and plot all ecoregions within a particular biome:</em></p><pre><code class=\"language-wl\">In[]:= Select[ecoregionsTab, Function[#BiomeName == &quot;Deserts &amp; Xeric Shrublands&quot;]] // Normal[Dataset[#][All, \n       (*Extract geometry and ecoregion colors, and add tooltips to the footprints:*) {#EcoregionColor, Tooltip[#Geometry, #EcoregionName]} &amp;]] &amp; // GeoGraphics[{GeoStyling[Opacity[.6]], #}, ImageSize -&gt; Large] &amp; // Rasterize\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/0jw1vmd4pjcrj.png\" alt=\"\" width=\"1152\" height=\"576\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/0jw1vmd4pjcrj-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0jw1vmd4pjcrj-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0jw1vmd4pjcrj-md.png 768w\"></figure><p><em>Find and plot all ecoregions within a particular realm:</em></p><pre><code class=\"language-wl\">In[]:= Select[ecoregionsTab, Function[#Realm == &quot;Indomalayan&quot;]] // Normal[Dataset[#][All, \n       (*Extract geometry and ecoregion colors, and add tooltips to the footprints:*) {#EcoregionColor, Tooltip[#Geometry, #EcoregionName]} &amp;]] &amp; // GeoGraphics[{GeoStyling[Opacity[.6]], #}, ImageSize -&gt; Large] &amp; // Rasterize\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/19q26rrj2pve0.png\" alt=\"\" width=\"1152\" height=\"673\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/19q26rrj2pve0-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/19q26rrj2pve0-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/19q26rrj2pve0-md.png 768w\"></figure><p><em>Find and plot all ecoregions whose names contain the word “forest”:</em></p><pre><code class=\"language-wl\">In[]:= Select[ecoregionsTab, Function[StringContainsQ[ToLowerCase[#EcoregionName], &quot;forest&quot;]]] // Normal[Dataset[#][All, \n       (*Extract geometry and ecoregion colors, and add tooltips to the footprints:*) {#EcoregionColor, Tooltip[#Geometry, #EcoregionName]} &amp;]] &amp; // GeoGraphics[{GeoStyling[Opacity[.6]], #}, ImageSize -&gt; Large, GeoCenter -&gt; {0, 0}] &amp; // Rasterize\n</code></pre>\n<figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/47/1jt8yiqx0ov1y.png\" alt=\"\" width=\"1152\" height=\"576\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/1jt8yiqx0ov1y-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1jt8yiqx0ov1y-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1jt8yiqx0ov1y-md.png 768w\"></figure><p><em>Plot protection status of neotropic tropical and subtropical moist broadleaf forests:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/1r87ybh8686m1.png\" alt=\"\" width=\"2789\" height=\"212\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/1r87ybh8686m1-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1r87ybh8686m1-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1r87ybh8686m1-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/0jl3eszfxz97s.png\" alt=\"\" width=\"1307\" height=\"738\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/0jl3eszfxz97s-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0jl3eszfxz97s-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0jl3eszfxz97s-md.png 768w\"></figure><h4 id=\"bonus-ecoregion2017-geoservers\"><em>Bonus: Ecoregion2017 GeoServers</em></h4>\n<p>For larger maps, assuming you’d like to include every ecoregion in your map’s geographic range, you may elect to connect to one of the Ecoregions2017 GeoServer services for your plotting. This is generally faster.</p><p><em>Construct a dataset of Ecoregions2017 GeoServers:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/060qitwoevl7m.png\" alt=\"\" width=\"1365\" height=\"85\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/060qitwoevl7m-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/060qitwoevl7m-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/060qitwoevl7m-md.png 768w\"></figure><p><em>Create world maps for each GeoServer:</em></p><pre><code class=\"language-wl\">In[]:= Dataset[GeoGraphics[&quot;World&quot;, GeoServer -&gt; #, GeoZoomLevel -&gt; 1] &amp; /@ ecoGeoServers]\n</code></pre>\n<figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/47/1jgp7saxb9n8n.png\" alt=\"\" width=\"1399\" height=\"1360\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/1jgp7saxb9n8n-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1jgp7saxb9n8n-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1jgp7saxb9n8n-md.png 768w\"></figure><p><em>Define the Legends for each map type:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/1pt735is35rm6.png\" alt=\"\" width=\"507\" height=\"41\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/1pt735is35rm6-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1pt735is35rm6-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1pt735is35rm6-md.png 768w\"></figure><h4 id=\"fetching-ecoregion-images\">Fetching ecoregion images</h4>\n<p>The ecoregion descriptions hosted on <a href=\"http://www.oneearth.org\">www.oneearth.org</a> contain illustrative of ecoregion landscapes and emblematic wildlife. Let’s define a function to fetch these images programmatically:</p><p><em>Define a function to collect ecoregion images:</em></p><pre><code class=\"language-wl\">In[]:= ClearAll[ecoregionImages] \n  (*OneEarth page URL input:*)\n ecoregionImages[ecoregionOneEarthPage_URL] := Dataset[Join[\n     (*Import ecoregion page header images (typically landscapes):*) \n      Cases[\n       Import[ecoregionOneEarthPage, &quot;XMLObject&quot;], XMLElement[&quot;img&quot;, {&quot;src&quot; -&gt; url_, &quot;alt&quot; -&gt; description_, &quot;data-image&quot; -&gt; &quot;data-image&quot;, &quot;v-imageloaded&quot; -&gt; &quot;v-imageloaded&quot;}, _] :&gt; &lt;|&quot;Image&quot; -&gt; Import[url], &quot;ImageDescription&quot; -&gt; description|&gt;, {17}], \n     (*Import ecoregion page body images (typically animals or landscapes):*) \n      Cases[\n       Import[ecoregionOneEarthPage, &quot;XMLObject&quot;], XMLElement[&quot;figure&quot;, {}, {XMLElement[&quot;img&quot;, {&quot;src&quot; -&gt; url_}, {}], XMLElement[&quot;figcaption&quot;, {}, {XMLElement[&quot;span&quot;, {&quot;class&quot; -&gt; &quot;caption&quot;}, {}], XMLElement[&quot;p&quot;, {}, {description_}], &quot; &quot;}]}] :&gt; &lt;|&quot;Image&quot; -&gt; Import[url], &quot;ImageDescription&quot; -&gt; description|&gt;, \\[Infinity]] \n     ]] \n   \n  (*Ecoregion name input:*)\n ecoregionImages[ecoregionName_String] := ecoregionImages[URL[First[Values[Normal[First[\n          ConstructColumns[Select[ecoregionsTab, Function[#EcoregionName == ecoregionName]], &quot;OneEarthPage&quot;]]]]]]] \n   \n  (*ID input:*)\n ecoregionImages[ecoregionID_Integer] := ecoregionImages[URL[First[Values[Normal[First[\n         ConstructColumns[Select[ecoregionsTab, Function[#EcoregionID == ecoregionID]], &quot;OneEarthPage&quot;]]]]]]]\n</code></pre>\n<p><em>Fetch images for a specified ecoregion, along with their descriptions:</em></p><pre><code class=\"language-wl\">In[]:= ecoregionImages[&quot;Myanmar coastal rain forests&quot;]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/0apewhueieqfw.png\" alt=\"\" width=\"1359\" height=\"507\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/0apewhueieqfw-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0apewhueieqfw-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0apewhueieqfw-md.png 768w\"></figure><h3 id=\"searching-for-inaturalist-species-observations-within-ecoregions\">Searching for iNaturalist Species Observations Within Ecoregions</h3>\n<p>Finally, here’s an example showing one way you might use the ecoregions data explored in this text in combination with other Wolfram Language ecology functionality. </p><p>iNaturalist is a citizen science project and online community of naturalists, biologists, and ordinary people who record and share observations of plants, animals, and other life forms. Users can upload photos and sounds, identify species, and contribute to a global biodiversity database.</p><p>Observations shared to the iNaturalist platform can be retrieved using the <a href=\"https://resources.wolframcloud.com/FunctionRepository/resources/INaturalistSearch/\">INaturalistSearch</a> function from the Wolfram Function Repository. Let’s use this function to fetch species observations from an specified ecoregion.</p><p><em>Define the region in which to search for observations:</em></p><pre><code class=\"language-wl\">In[]:= region = GeoGroup[Normal[First[Select[ecoregionsTab, Function[#&quot;EcoregionName&quot; == &quot;Puerto Rican moist forests&quot;]]]][&quot;Geometry&quot;]];\n</code></pre>\n<p><em>Plot this region on a map:</em></p><pre><code class=\"language-wl\">In[]:= GeoGraphics[region] // Rasterize\n</code></pre>\n<figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/47/090jv8xpyxzy7.png\" alt=\"\" width=\"840\" height=\"369\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/090jv8xpyxzy7-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/090jv8xpyxzy7-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/090jv8xpyxzy7-md.png 768w\"></figure><p><em>Fetch observations made within this region and within a specified date range (here, set to the last 10 days at time of computation):</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/1uroqt2g1edge.png\" alt=\"\" width=\"2339\" height=\"103\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/1uroqt2g1edge-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1uroqt2g1edge-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1uroqt2g1edge-md.png 768w\"></figure><p><em>Extract the positions and species names from the resulting dataset, and plot them on a map:</em></p><pre><code class=\"language-wl\">In[]:= GeoListPlot[Flatten[FromTabular[ConstructColumns[observations, &quot;LabeledPosition&quot; -&gt; Function[Labeled[#&quot;GeoPosition&quot;, #&quot;TaxonName&quot;]]], &quot;Matrix&quot;]], ImageSize -&gt; 850] // Rasterize\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/47/0tp97ku72duyh.png\" alt=\"\" width=\"1173\" height=\"515\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/47/responsive/0tp97ku72duyh-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0tp97ku72duyh-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0tp97ku72duyh-md.png 768w\"></figure><h2 id=\"conclusion\">Conclusion</h2>\n<p>The Ecoregions2017©Resolve dataset lets us explore the incredible variety of ecosystems around the globe. By breaking down Earth’s landscapes into distinct ecological zones, it gives us a fresh perspective on Earth’s diverse habitats and the species that inhabit them. Whether you’re interested in research, conservation, or simply appreciating the beauty and complexity of life on Earth, this dataset offers a clear and engaging way to use computation to explore questions  about ecology, biodiversity, and environmental science.</p><h2 id=\"cite-this-work\">Cite this work</h2>\n<p><a href=\"https://community.wolfram.com/groups/-/m/t/3445374\">Terrestrial ecoregions of the world: computational insights into global biodiversity</a>\nby <a href=\"https://community.wolfram.com/web/phileasdg\">Phileas Dazeley-Gaist</a>\nWolfram Community, STAFF PICKS, April 17, 2025\n<a href=\"https://community.wolfram.com/groups/-/m/t/3445374\">https://community.wolfram.com/groups/-/m/t/3445374</a></p>",
            "image": "https://phileasdg.github.io/media/posts/47/Ecoregions_BannerImage-2.png",
            "author": {
                "name": "Phileas Dazeley-Gaist"
            },
            "tags": [
                   "Wolfram Language",
                   "Programming",
                   "Mathematica",
                   "GIS",
                   "Environmental Science",
                   "Ecology"
            ],
            "date_published": "2025-08-16T04:21:47+02:00",
            "date_modified": "2025-08-16T17:58:57+02:00"
        },
        {
            "id": "https://phileasdg.github.io/trading-places-a-network-analysis-of-global-commerce/",
            "url": "https://phileasdg.github.io/trading-places-a-network-analysis-of-global-commerce/",
            "title": "Trading Places: a Network Analysis of Global Commerce",
            "summary": "Note: This post was originally a short technical article I shared on&hellip;",
            "content_html": "<p><strong>Note:</strong> This post was originally a short technical article I shared on the Wolfram Community forums. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3416904\">here</a>. </p><h2 id=\"introduction\">Introduction</h2>\n<p>The global trade network is the backbone of international commerce, linking countries through a complex web of import and export relationships. Not only does it characterise the flow of goods and services, but it also shapes economic strategies and geopolitical landscapes. </p><p>While the true global trade network is incredibly complex, with millions of individual transactions occurring daily across countless products and services, we can still build meaningful representations that capture important aspects of global commerce ties. In this article, I’ll use Wolfram Knowledgebase country data from <a href=\"https://www.cia.gov/the-world-factbook/\">The World Factbook</a> to define graphs of major import and export relationships on the global stage. </p><p>By constructing network representations of international trade, we can visualize and quantify the connections between nations, revealing patterns that might otherwise remain hidden in tables of statistics. Which countries serve as central hubs in global commerce? How do smaller economies interact with larger ones? Where do we see asymmetric dependencies? And how do natural trading communities form? In this short article, I’ll explore these questions through a series of visualizations and analyses.</p><h2 id=\"setup-building-a-dataset-of-international-commercial-relationships\">Setup: Building a Dataset of International Commercial Relationships</h2>\n<p>The first thing we need to do is gather data on import and export relationships between countries. We can get this information from the Wolfram Knowledgebase.</p><p>Let’s start by creating a list of all countries: </p><p> <figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/46/0mhu7w08drqns.png\" alt=\"countries\" width=\"914\" height=\"49\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/0mhu7w08drqns-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0mhu7w08drqns-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0mhu7w08drqns-md.png 768w\"></figure></p><p>We’re going to extract values associated with country entities above. Manually, we might access one such value like this:</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/1axwz1yc3p4za.png\" alt=\"\" width=\"424\" height=\"47\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1axwz1yc3p4za-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1axwz1yc3p4za-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1axwz1yc3p4za-md.png 768w\"></figure><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/46/0rhtbmil6fzi4.png\" alt=\"\" width=\"1084\" height=\"48\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/0rhtbmil6fzi4-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0rhtbmil6fzi4-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0rhtbmil6fzi4-md.png 768w\"></figure><p>We can also ask Wolfram Language to check the source of entity property data like so: </p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/096za5tfkwtq2.png\" alt=\"\" width=\"606\" height=\"47\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/096za5tfkwtq2-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/096za5tfkwtq2-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/096za5tfkwtq2-md.png 768w\"></figure><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/46/1hbx1q5bewf0p-2.png\" alt=\"\" width=\"276\" height=\"48\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1hbx1q5bewf0p-2-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1hbx1q5bewf0p-2-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1hbx1q5bewf0p-2-md.png 768w\"></figure><p>Now, let’s create a dataset of import and export information for these countries. We’ll extract key trade properties and remove entries with missing data.</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/0ob3dcrtldzxu.png\" alt=\"\" width=\"2243\" height=\"278\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/0ob3dcrtldzxu-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0ob3dcrtldzxu-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0ob3dcrtldzxu-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/0ovu7bhsqczea.png\" alt=\"dataset preview\" width=\"1452\" height=\"546\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/0ovu7bhsqczea-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0ovu7bhsqczea-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0ovu7bhsqczea-md.png 768w\"></figure><p>Since these are tabular data, we can represent them in a <a href=\"https://reference.wolfram.com/language/ref/Tabular\">Tabular</a> object (introduced in Wolfram Language 14.2). The Tabular representation makes it possible to apply <a href=\"https://reference.wolfram.com/language/guide/TabularProcessing\">standard data science pipeline </a>techniques including filtering, aggregation, transformation, and visualisation to our data easily.</p><p>The dataset we’ve built contains international trade information for countries around the world, with data sourced from <a href=\"https://www.cia.gov/the-world-factbook/\">The World Factbook</a>. Each column represents a key aspect of a country’s trade profile: </p><ul>\n<li><em>ImportCommodities:</em> Major goods and product categories that each country primarily imports from international markets. These represent key dependencies on foreign products.</li>\n<li><em>ExportCommodities:</em> Major goods and product categories that each country primarily sells to international markets. These represent the country’s key commercial outputs.</li>\n<li><em>ImportPartners:</em> Major countries from which each nation sources its imports. These represent the primary international suppliers for each country.</li>\n<li><em>ExportPartners:</em> Major countries to which each nation sells its exports. These represent the primary international customers for each country.</li>\n<li><em>ImportPartnersFractions:</em> The approximate percentage of total imports that come from each major import partner. This quantifies the relative importance of each supplier country.</li>\n<li><em>ExportPartnersFractions:</em> The approximate percentage of total exports that go to each major export partner. This quantifies the relative importance of each customer country.</li>\n</ul>\n<p>Not only do these data provide a coarse sense of who trades with whom, but also what they trade and how significant those relationships are in percentage terms.</p><h2 id=\"construction-and-analysis-of-network-representations-of-global-commerce\">Construction and Analysis of Network Representations of Global Commerce</h2>\n<p>Global commerce naturally lends itself to network analysis, where countries represent nodes (vertices) and trade relationships form the connections (edges) between them. Using our dataset, we can construct several different graph representations that reveal different aspects of international trade patterns. </p><h3 id=\"unweighted-international-trade-network-representations\">Unweighted international trade network representations</h3>\n<p>The simplest representations we can construct from our dataset are unweighted directed graphs where an edge from country A to country B indicates that B is a major trading partner of A. We can create two complementary networks:</p><ul>\n<li><strong>Import Network:</strong> In these networks, an edge from country A to country B means that country A imports goods from country B. The direction of the edge follows the flow of money (A pays B for goods).</li>\n<li><strong>Export Network</strong>: Here, an edge from country A to country B means that country A exports goods to country B. The direction follows the flow of goods.</li>\n</ul>\n<p>Let’s construct and visualise these graphs.</p><p>*Construct the global major import partner graph: *</p><pre><code class=\"language-wl\">In[]:= globalImportRelationships = Graph[Normal[Dataset[internationalCommerceData][All, Keys][Keys]], \n    Flatten[FromTabular[ConstructColumns[internationalCommerceData, \n       &quot;Edges&quot; -&gt; (Thread[#Entity -&gt; #ImportPartners] &amp;)], &quot;Matrix&quot;]], ImageSize -&gt; Small]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/1m3tks5pkbkxu.png\" alt=\"\" width=\"360\" height=\"305\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1m3tks5pkbkxu-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1m3tks5pkbkxu-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1m3tks5pkbkxu-md.png 768w\"></figure><p><em>Construct the global major export partner graph:</em></p><pre><code class=\"language-wl\">In[]:= globalExportRelationships = Graph[\n    Normal[Dataset[internationalCommerceData][All, Keys][Keys]], \n    Flatten[FromTabular[ConstructColumns[internationalCommerceData, \n       &quot;Edges&quot; -&gt; (Thread[#Entity -&gt; #ExportPartners] &amp;)], &quot;Matrix&quot;]], ImageSize -&gt; Small]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/1g9a5cg22b41i.png\" alt=\"\" width=\"360\" height=\"367\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1g9a5cg22b41i-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1g9a5cg22b41i-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1g9a5cg22b41i-md.png 768w\"></figure><p>These networks are quite tangled, so it will help to represent them geographically.</p><p><em>Visualise these graphs on maps:</em></p><pre><code class=\"language-wl\">In[]:= Row[Rasterize[#, ImageSize -&gt; Large, RasterSize -&gt; 1500] &amp; /@ {\n     GeoGraphPlot[globalImportRelationships, \n      EdgeStyle -&gt; Thin, VertexSize -&gt; Small, \n      GeoProjection -&gt; &quot;LambertAzimuthal&quot;, ImageSize -&gt; 600, PlotRangePadding -&gt; .1, \n      PlotLabel -&gt; Style[&quot;Global Major Import Partner Network&quot;, 15], \n      GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}], \n     GeoGraphPlot[globalExportRelationships, \n      EdgeStyle -&gt; Thin, VertexSize -&gt; Small, \n      GeoProjection -&gt; &quot;LambertAzimuthal&quot;, ImageSize -&gt; 600, PlotRangePadding -&gt; .1, \n      PlotLabel -&gt; Style[&quot;Global Major Export Partner Network&quot;, 15], \n      GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}] \n    }]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/GlobalMajorImportPartnerNetwork.png\" alt=\"\" width=\"1500\" height=\"1543\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorImportPartnerNetwork-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorImportPartnerNetwork-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorImportPartnerNetwork-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/GlobalMajorExportPartnerNetwork.png\" alt=\"\" width=\"1500\" height=\"1543\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorExportPartnerNetwork-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorExportPartnerNetwork-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorExportPartnerNetwork-md.png 768w\"></figure><h3 id=\"analysis-of-discrepancies-between-import-and-export-networks\">Analysis of discrepancies between import and export networks</h3>\n<p>While both networks are very visually similar, because they take different perspectives, the import and export graphs paint slightly different pictures of global trade. One source of discrepancies between the networks is asymmetries in trade relationships: The fact that country A features in the list of major partners to country B does not always entail that B features in the list of major partners of A. To better understand these asymmetries, we can study which relationships appear in one network but not the other.</p><ul>\n<li><strong>Two-way major partnerships:</strong> If an edge A  B is found in both graphs, it means that B is a major provider of goods to A (relative to A’s total imports) and A is a major exporter to B (relative to A’s total exports). This suggests A is economically dependent on its import and export relationships with B, as they make up significant portions of A’s total imports and exports.</li>\n<li><strong>Import dependencies:</strong> If a A  B exists in the import network but not in the export network, it means B is a major source of imports to A, but is not a major export destination for A’s goods. This suggests A depends on B’s goods, but B is not a significant market for A.</li>\n<li><strong>Export dependencies:</strong> Conversely, if  A  B exists in the export network but not in the import network, it means B is a major destination for A’s exports, but not one of A’s major import sources. ****This suggests A depends on B as a market for its goods, but not on imports from B.</li>\n</ul>\n<p>Let’s examine which countries most frequently appear in these “one-way” relationships:</p><p>The charts below show the 20 countries which most frequently appear as the “source” country (country A) in these asymmetric import and export relationships. The left chart ranks countries by the number of major trade partners with whom they have major import dependencies. The right chart ranks countries by the number of major trade partners with whom they have major export dependencies.</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/46/0qssf2f86q1zq.png\" alt=\"\" width=\"1386\" height=\"539\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/0qssf2f86q1zq-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0qssf2f86q1zq-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0qssf2f86q1zq-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/Top20CountryOneWayImportDependencies.png\" alt=\"\" width=\"1086\" height=\"577\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayImportDependencies-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayImportDependencies-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayImportDependencies-md.png 768w\"></figure>\n<figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/46/Top20CountryOneWayExportDependencies.png\" alt=\"\" width=\"1000\" height=\"580\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayExportDependencies-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayExportDependencies-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayExportDependencies-md.png 768w\"></figure><p>Notably, smaller economies like Vanuatu, Samoa, and Guinea appear frequently in these one-way relationships, suggesting they may have significant dependencies on specific trading partners that don’t reciprocally depend on them.</p><p>These next charts reveal which countries most frequently appear as the “destination” country (country B) in asymmetric relationships. The left chart shows countries that are most frequently considered important import sources, but not major export destinations for their partners goods. The right chart shows countries that are most frequently considered important export destinations, but not major import sources:</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/1sv1x08hlj4a0.png\" alt=\"\" width=\"1383\" height=\"539\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1sv1x08hlj4a0-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1sv1x08hlj4a0-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1sv1x08hlj4a0-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/Top20CountryCriticalImportSources.png\" alt=\"\" width=\"1000\" height=\"596\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalImportSources-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalImportSources-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalImportSources-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/Top20CountryCriticalExportMarkets.png\" alt=\"\" width=\"1000\" height=\"626\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalExportMarkets-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalExportMarkets-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalExportMarkets-md.png 768w\"></figure><p>China dominates as a critical import source for numerous countries that don’t reciprocally consider China a major export destination. Meanwhile, the United Kingdom and United States serve as vital export markets for many nations that don’t rely heavily on them for imports. These patterns highlight the uneven dependencies in global trade - smaller economies often have one-way trade relationships with economic powerhouses, while major economies maintain more balanced bilateral trade relationships with their key partners. This asymmetry creates potential vulnerabilities where countries depend economically on partners who don’t equally depend on them.</p><h3 id=\"country-centrality-in-global-commerce\">Country Centrality in Global Commerce</h3>\n<p>Network centrality measures help us identify which countries play pivotal roles in the global trade network. Different centrality metrics capture different aspects of a country’s importance in international trade.</p><p>Betweenness centrality measures the extent to which a country acts as an intermediary in the trade network. It is calculated based on the number of times a country falls on the shortest path between other countries. High betweenness centrality indicates that a country is a major hub for trade, facilitating transactions between many other nations. This can highlight countries that play a vital role in the distribution of goods globally.</p><p><em>Visualization of vertex betweenness centrality on the global imports network:</em></p><pre><code class=\"language-wl\">In[]:= Module[{g = globalImportRelationships}, \n   g = Graph[g, VertexCoordinates -&gt; Map[First[GeoGridPosition[#, &quot;WinkelTripel&quot;]] &amp;, VertexList[g]]]; \n   GeoBubbleChart[Thread[VertexList[g] -&gt; BetweennessCentrality[g]], \n    GeoProjection -&gt; &quot;WinkelTripel&quot;, \n    PlotLabel -&gt; Style[&quot;Global Trade Import Vertex Betweenness-Centrality&quot;, 14], \n    GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}] \n  ]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/1l8auoboznwi6.png\" alt=\"\" width=\"1304\" height=\"829\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1l8auoboznwi6-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1l8auoboznwi6-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1l8auoboznwi6-md.png 768w\"></figure><p><em>Visualization of vertex betweenness centrality on the global exports network:</em></p><pre><code class=\"language-wl\">In[]:= Module[{g = globalExportRelationships}, \n   g = Graph[g, VertexCoordinates -&gt; Map[First[GeoGridPosition[#, &quot;WinkelTripel&quot;]] &amp;, VertexList[g]]]; \n   GeoBubbleChart[Thread[VertexList[g] -&gt; BetweennessCentrality[g]], \n    GeoProjection -&gt; &quot;WinkelTripel&quot;, \n    PlotLabel -&gt; Style[&quot;Global Trade Export Vertex Betweenness-Centrality&quot;, 14], \n    GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}] \n  ]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/0j6jsiinemtns.png\" alt=\"\" width=\"1301\" height=\"827\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/0j6jsiinemtns-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0j6jsiinemtns-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0j6jsiinemtns-md.png 768w\"></figure><p>Nations like the United States, China, and Germany show substantial centrality, reflecting their critical positions in both importing and exporting goods. These countries are central players in the international market, not just due to their economic size but also because they serve as major conduits for international trade.</p><p>Countries with high betweenness centrality play a significant role in the stability of global trade networks. Disruptions in these countries, be it political instability, natural disasters, or economic sanctions, could have ripple effects, impacting trade flows globally.</p><h3 id=\"weighted-international-trade-network-representations\">Weighted international trade network representations</h3>\n<p>While our previous unweighted network analysis provided insights into the structure of global trade relationships, it treated all connections equally. In reality, trade relationships vary significantly in their importance. Some countries depend heavily on specific trading partners, with a large percentage of their imports or exports flowing through them.</p><p>By incorporating the percentage data from our dataset (ImportPartnersFractions and ExportPartnersFractions), we can create weighted networks that better reflect the actual economic significance of each relationship. In these weighted networks, the thickness of each edge represents the percentage of a country’s total imports or exports that flows through that relationship. </p><p>*Construct the weighted global import partner graph: *</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/46/1us4mokwx5dfd.png\" alt=\"\" width=\"2660\" height=\"259\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1us4mokwx5dfd-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1us4mokwx5dfd-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1us4mokwx5dfd-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/1gp61mwnbbhvs.png\" alt=\"\" width=\"360\" height=\"405\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1gp61mwnbbhvs-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1gp61mwnbbhvs-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1gp61mwnbbhvs-md.png 768w\"></figure><p>*Construct the weighted global export partner graph: *</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/46/12nuslpcvt9tk.png\" alt=\"\" width=\"2654\" height=\"259\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/12nuslpcvt9tk-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/12nuslpcvt9tk-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/12nuslpcvt9tk-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/17a0eaya4u61j.png\" alt=\"\" width=\"360\" height=\"300\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/17a0eaya4u61j-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/17a0eaya4u61j-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/17a0eaya4u61j-md.png 768w\"></figure><p>Once again, let’s plot these networks geographically:</p><p><em>Visualise the weighted global import and export partner networks on a map:</em></p><pre><code class=\"language-wl\">In[]:= Row[Rasterize[#, ImageSize -&gt; Large, RasterSize -&gt; 1500] &amp; /@ {\n     GeoGraphValuePlot[globalWeightedImportRelationships, \n      GeoProjection -&gt; &quot;LambertAzimuthal&quot;, ImageSize -&gt; 500, ColorFunction -&gt; &quot;Aquamarine&quot;, \n      EdgeValueRange -&gt; {0, 1}, EdgeValueSizes -&gt; 1/100, PlotRangePadding -&gt; .1, VertexSize -&gt; 5, \n      PlotLegends -&gt; Automatic, MinPointSeparation -&gt; None, PlotLabel -&gt; Style[&quot;Global Weighted Major Import Partner Network&quot;, 15], \n      GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}], \n     GeoGraphValuePlot[globalWeightedExportRelationships, \n      GeoProjection -&gt; &quot;LambertAzimuthal&quot;, ImageSize -&gt; 500, ColorFunction -&gt; &quot;Aquamarine&quot;, \n      EdgeValueRange -&gt; {0, 1}, EdgeValueSizes -&gt; 1/100, PlotRangePadding -&gt; .1, VertexSize -&gt; 5, \n      PlotLegends -&gt; Automatic, MinPointSeparation -&gt; None, PlotLabel -&gt; Style[&quot;Global Weighted Major Export Partner Network&quot;, 15], \n      GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}] \n    }]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/GlobalWeightedMajorImportPartnerNetwork.png\" alt=\"\" width=\"1500\" height=\"1339\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorImportPartnerNetwork-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorImportPartnerNetwork-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorImportPartnerNetwork-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/GlobalWeightedMajorExportPartnerNetwork.png\" alt=\"\" width=\"1500\" height=\"1339\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorExportPartnerNetwork-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorExportPartnerNetwork-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorExportPartnerNetwork-md.png 768w\"></figure><p>These plots highlight strong regional trade patterns and commerce hubs centred at major economic powers. Thicker lines represent relationships where a higher percentage of a country’s imports or exports flow through that connection. </p><h3 id=\"comparison-of-import-and-export-relationship-weights\">Comparison of import and export relationship weights</h3>\n<p>By comparing the weights of common edges in our import and export networks, we can identify key patterns of dependency and influence in international trade. </p><p><em>Produce a scatter plot of import and export edge weights for edges common to both weighted networks:</em></p><pre><code class=\"language-wl\">In[]:= Module[{\n     importEdges = EdgeList[globalWeightedImportRelationships], \n     importWeights = AnnotationValue[globalWeightedImportRelationships, EdgeWeight], \n     exportEdges = EdgeList[globalWeightedExportRelationships], \n     exportWeights = AnnotationValue[globalWeightedExportRelationships, EdgeWeight], \n     threadEm = Function[{a, b}, Thread[a -&gt; b]], commonEdges}, \n    \n    commonEdges = Intersection[importEdges, exportEdges]; \n    \n    Labeled[Labeled[Show[\n       Plot[x, {x, 0, 1}, PlotStyle -&gt; Directive[Dashed, LightGray]], \n       ListPlot[KeyValueMap[Callout[#2, #1] &amp;, Merge[{\n          (*x axis values*) KeySort[FilterRules[threadEm[importEdges, importWeights], commonEdges]], \n          (*y axis values*) KeySort[FilterRules[threadEm[exportEdges, exportWeights], commonEdges]]}, \n          First[List[#]] &amp;]], PlotRange -&gt; Full], ImageSize -&gt; Large], Map[Text, {&quot;Import network edge weight (fraction of total imports to country A coming from country B)&quot;, &quot;Export network edge weight (fraction of total exports of country A going to country B)&quot;}], {Bottom, Left}, RotateLabel -&gt; True], \n     Text[Style[&quot;Scatterplot of Major Import and Export Relationship Weights in Global Commerce&quot;, 15]], Top] \n   ] // Rasterize[#, ImageSize -&gt; Large, RasterSize -&gt; 1500] &amp;\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/1x8fe3jjsmh5a.png\" alt=\"\" width=\"1230\" height=\"871\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1x8fe3jjsmh5a-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1x8fe3jjsmh5a-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1x8fe3jjsmh5a-md.png 768w\"></figure><p>In this scatter plot:</p><ol>\n<li>Points above the diagonal line represent relationships where the export dependency (y-axis) is stronger than the import dependency (x-axis). For example, Puerto Rico depends on the United States as a market for a about 90% of its exports, whereas it imports a little under 60% of its goods from the US.</li>\n<li>Points below the diagonal line represent relationships where the import dependency is stronger than the export dependency. For instance, the Falklands import over 70% of their imported goods from the UK, but the UK is a market for under 10% of the Falklands exports.</li>\n<li>Clustered points near the origin indicate that most trading relationships involve relatively small percentages of total trade (&lt;20%), showing diversification in most countries’ trading patterns.</li>\n</ol>\n<p>The scatter plot highlights how smaller economies often have highly concentrated trade relationships with major economic powers, while most countries maintain diversified trading portfolios with their major partners. This pattern of asymmetric dependencies is particularly evident in relationships influenced by geographic proximity, historical colonial ties, and economic size disparities. It’s important to remember that these edges represent only the major commercial relationships as identified by the World Factbook, meaning they capture the most significant trade flows from each country’s perspective rather than all trade relationships globally.</p><p>By subtracting the import network weights from the export network weights, and plotting a histogram of the resulting data, we can estimate the distribution of commercial relationships from most import-dependent to most export-dependent:</p><pre><code class=\"language-wl\">In[]:= With[{\n     importEdges = EdgeList[globalWeightedImportRelationships], \n     importWeights = AnnotationValue[globalWeightedImportRelationships, EdgeWeight], \n     exportEdges = EdgeList[globalWeightedExportRelationships], \n     exportWeights = AnnotationValue[globalWeightedExportRelationships, EdgeWeight]}, \n    ReverseSort[Map[Subtract @@ Values[#] &amp;, GroupBy[FilterRules[Join[Thread[exportEdges -&gt; exportWeights], Thread[importEdges -&gt; importWeights]], Intersection[importEdges, exportEdges]], First]]] // Labeled[Histogram[#, PlotRange -&gt; Full, PlotLabel -&gt; Style[&quot;Distribution of Trade Dependency Asymmetries in Global Commerce&quot;, 14]], Text /@ {&quot;Export dependency minus import dependency&quot;, &quot;Frequency&quot;}, {Bottom, Left}, RotateLabel -&gt; True] &amp; \n   ] // Rasterize[#, ImageSize -&gt; Large, RasterSize -&gt; 1500] &amp;\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/1pi2xibkyrpkm.png\" alt=\"\" width=\"1194\" height=\"816\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1pi2xibkyrpkm-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1pi2xibkyrpkm-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1pi2xibkyrpkm-md.png 768w\"></figure><p>The x-axis measures the difference between import and export dependencies for each trading relationship. A value of zero on this axis represents a balanced trade relationship, in the sense that a country’s reliance on imports from another is equal to its reliance on exports to that same country. Negative values indicate a stronger import dependency, meaning a country imports more goods from another than it exports to them. Positive values suggest a stronger export dependency, where a country exports more to another than it imports.</p><p>We can also produce rankings of countries by the magnitude of their dependencies. Here are the top 10 largest trade asymmetries according to our data:</p><pre><code class=\"language-wl\">In[]:= With[{\n      importEdges = EdgeList[globalWeightedImportRelationships], \n      importWeights = AnnotationValue[globalWeightedImportRelationships, EdgeWeight], \n      exportEdges = EdgeList[globalWeightedExportRelationships], \n      exportWeights = AnnotationValue[globalWeightedExportRelationships, EdgeWeight]}, \n     Labeled[#1, Text[Style[#2, 14]], Top] &amp; @@@ Thread[{\n        ReverseSort[Map[Subtract @@ Values[#] &amp;, GroupBy[FilterRules[Join[Thread[exportEdges -&gt; exportWeights], Thread[importEdges -&gt; importWeights]] \n             , Intersection[importEdges, exportEdges]], First]]] // Map[Dataset, {Take[#, 10], Take[#, -10]}] &amp;, \n        {&quot;Top 10 Relationships Where Countries Are Most Dependent on Partners as Export Markets&quot;, &quot;Top 10 Relationships Where Countries Are Most Dependent on Partners as Import Sources&quot;} \n       }] \n    ] // Reverse // Row[#, Spacer[10]] &amp;\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/Screenshot-2025-08-16-at-11.31.11.png\" alt=\"\" width=\"1666\" height=\"744\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/Screenshot-2025-08-16-at-11.31.11-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/Screenshot-2025-08-16-at-11.31.11-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/Screenshot-2025-08-16-at-11.31.11-md.png 768w\"></figure><p>Countries at the top of the import-dependent list (like Uruguay with Argentina) rely heavily on specific partners for their imports while exporting proportionally less to those same partners. Conversely, countries at the top of the export-dependent list (like Chad with the United States) are highly dependent on specific markets for their exports while importing proportionally less from those partners.</p><h3 id=\"global-export-communities-by-modularity\">Global export communities by modularity</h3>\n<p>The network visualizations we’ve examined so far don’t immediately show us how countries naturally cluster into trading groups or blocs. To identify these natural groupings, we can apply community detection algorithms to our weighted export network. Using modularity-based community detection on our weighted export network, we can identify clusters of countries that trade more with each other than with the rest of the world. </p><p><em>Visualise groups of countries whose mutual exports represent larger shares of total national exports than exports from other countries (white represents missing data):</em></p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/46/1whb0nt21kpwe.png\" alt=\"\" width=\"2758\" height=\"462\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1whb0nt21kpwe-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1whb0nt21kpwe-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1whb0nt21kpwe-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/1a1ddw0auqv6f.png\" alt=\"\" width=\"2637\" height=\"2009\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/1a1ddw0auqv6f-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1a1ddw0auqv6f-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1a1ddw0auqv6f-md.png 768w\"></figure><p><em>Compare the plot above to this map of free trade areas worldwide form Wikipedia:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/46/0pk71zdgnpvxx.png\" alt=\"\" width=\"1386\" height=\"639\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/46/responsive/0pk71zdgnpvxx-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0pk71zdgnpvxx-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0pk71zdgnpvxx-md.png 768w\"></figure><p><em>(<strong><a href=\"https://en.wikipedia.org/wiki/Trade_bloc\">Wikipedia: Trade bloc</a></strong>, Free trade areas worldwide, by user</em> <em><a href=\"https://commons.wikimedia.org/wiki/User:Emilfaro\">Emilfaro</a>**)</em></p><p>The modularity-based community detection results show striking regional patterns that largely overlap with established trade blocs and agreements. North America, South America, Europe, Russia and parts of Central Asia, China and parts of Southeast Asia, and Australia/New Zealand each form distinct communities. These natural groupings often mirror formal trade agreements like NAFTA, MERCOSUR, the EU, ASEAN, and others, demonstrating how geographic proximity and policy decisions reinforce natural trading patterns.</p><h2 id=\"reflection-and-concluding-notes\">Reflection and Concluding Notes</h2>\n<p>The analysis here reveals how smaller economies often develop asymmetric trade relationships with larger ones, sometimes relying heavily on a single partner for either imports or exports without reciprocity. These dependencies create potential vulnerabilities but also reflect practical economic realities shaped by geography, historical connections, and resource distribution.</p><p>Perhaps most interesting is how the detected trade communities largely align with formal trade agreements while occasionally revealing unexpected connections. These natural groupings demonstrate that while policy decisions certainly influence trade patterns, underlying economic complementarity and geographic proximity remain important forces in shaping global commerce.</p><p>This network perspective on international trade provides a different lens through which to understand global economic relationships; one that emphasizes connections and interdependencies rather than just individual country statistics. As global trade continues to evolve amid changing geopolitical landscapes, these network representations offer valuable insights into the resilience and vulnerability of international commercial relationships.</p><h2 id=\"cite-this-work\">Cite this work</h2>\n<p><a href=\"https://community.wolfram.com/groups/-/m/t/3416904\">Trading places: a network analysis of global commerce</a>\nby <a href=\"https://community.wolfram.com/web/phileasdg\">Phileas Dazeley-Gaist</a>\nWolfram Community, STAFF PICKS, March 14, 2025\n<a href=\"https://community.wolfram.com/groups/-/m/t/3416904\">https://community.wolfram.com/groups/-/m/t/3416904</a></p>",
            "image": "https://phileasdg.github.io/media/posts/46/world_trade_banner.png",
            "author": {
                "name": "Phileas Dazeley-Gaist"
            },
            "tags": [
                   "Work at Wolfram",
                   "Wolfram Language",
                   "Programming",
                   "Network Science",
                   "Modelling",
                   "Mathematica",
                   "GIS",
                   "Economics"
            ],
            "date_published": "2025-08-16T04:20:01+02:00",
            "date_modified": "2025-10-10T17:45:24+02:00"
        },
        {
            "id": "https://phileasdg.github.io/delphai-structured-communication-with-llms-in-a-simulated-delphi-process/",
            "url": "https://phileasdg.github.io/delphai-structured-communication-with-llms-in-a-simulated-delphi-process/",
            "title": "DelphAI: Structured Communication with LLMs in a Simulated Delphi Process",
            "summary": "Note: This post was originally a short technical article I shared on&hellip;",
            "content_html": "<p><strong>Note:</strong> This post was originally a short technical article I shared on the Wolfram Community forums. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3393596\">here</a>. </p><h2 id=\"introduction\">Introduction</h2>\n<h3 id=\"an-overview-of-the-delphi-method\">An Overview of the Delphi Method</h3>\n<p>The Delphi method is a structured communication technique originally designed as a forecasting technique, that relies on a panel of experts. It was developed by the RAND Corporation in the 1950s and 1960s. The method involves multiple rounds of questionnaires or writing prompts sent to a panel of experts. The anonymised responses are aggregated and shared with the group after each round. The experts are encouraged to revise their earlier answers in light of the replies of other members of the panel. With some luck, the answers will converge to consensus over the course of several rounds. The method is widely used for forecasting and decision-making in business and education. </p><p><em>Illustration of one round of the Delphi process:</em></p><pre><code class=\"language-wl\">In[]:= Show[\n   Graph[{0 -&gt; 1, 1 -&gt; 2, 1 -&gt; 3, 1 -&gt; 4, 2 -&gt; 5, 3 -&gt; 6, 4 -&gt; 7, 5 -&gt; 8, 6 -&gt; 8, 7 -&gt; 8, 8 -&gt; 9, 9 -&gt; 10}, \n    VertexShape -&gt; Thread[Range[0, 10] -&gt; Map[diskFrame[#, 250, 30] &amp;, {&quot;🕵&quot;, &quot;📑&quot;, &quot;👱🏼‍♀️&quot;, &quot;👩‍🎨&quot;, &quot;👷🏽‍♀️&quot;, &quot;📝&quot;, &quot;📝&quot;, &quot;📝&quot;, &quot;🕵&quot;, &quot;📑&quot;, &quot;\\[Bullet]\\[Bullet]\\[Bullet]&quot;}]], \n    VertexSize -&gt; .8, GraphLayout -&gt; {&quot;LayeredDigraphEmbedding&quot;, &quot;Orientation&quot; -&gt; Left, &quot;RootVertex&quot; -&gt; 0}, \n    ImageSize -&gt; 700], \n   Graphics[{Line[{{-3.2, 4.8}, {-3.2, 5}, {2.6, 5}, {2.6, 4.8}}], Text[Style[&quot;A single Delphi process round&quot;, 14, TextAlignment -&gt; Left], {-2.12, 4.8}]}] \n  ]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/18afa53ilb1yy-2.png\" alt=\"Illustration of one round of the Delphi process:\" width=\"1328\" height=\"642\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/18afa53ilb1yy-2-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/18afa53ilb1yy-2-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/18afa53ilb1yy-2-md.png 768w\"></figure><h3 id=\"what-does-it-look-like-in-practice\">What does it look like in practice?</h3>\n<p>Here’s a step-by-step breakdown of the Delphi method. </p><ol>\n<li>After gathering volunteers, the facilitator distributes a questionnaire or initial prompt to the participants.</li>\n<li>The participants fill out the questionnaire/or prepare their contribution to the first round of the process, and turn in their work to the facilitator.</li>\n<li>The facilitator anonymises and summarises the perspectives of the participants, making sure to represent each in a balanced and nonjudgmental way, highlighting areas of agreement and disagreement between them. The facilitator then produces and shares this information in a report to participants, initiating the next round of the process.</li>\n<li>The process begins again: participants respond to the report by refilling the questionnaire/writing a new contribution taking account of the contents of the report, clarifying ambiguities and addressing disagreements.</li>\n<li>Once a predefined stopping criterion is fulfilled (e.g. the desired number of rounds has been reached, or there is global consensus) the facilitator produces a final report which either becomes or is used to produce the proceedings of the Delphi process.</li>\n</ol>\n<p><em>Animation representing a three-round Delphi process:</em></p><pre><code class=\"language-wl\">In[]:= ListAnimate[Join[Join @@ Table[Join[\n       Table[delphiMethodPlot[distanceFromOrigin, True, False, &quot;Round &quot; &lt;&gt; ToString[i]], {distanceFromOrigin, Subdivide[0, .75, 30]}], \n       Table[delphiMethodPlot[.75, True, False, &quot;Round &quot; &lt;&gt; ToString[i]],15], Table[delphiMethodPlot[.75, False, False, &quot;Round &quot; &lt;&gt; ToString[i]], 15], \n       Table[delphiMethodPlot[distanceFromOrigin, False, False, &quot;Round &quot; &lt;&gt; ToString[i]], {distanceFromOrigin, Subdivide[.75, 0, 30]}], \n       Table[delphiMethodPlot[0, False, False, &quot;Round &quot; &lt;&gt; ToString[i]],15], Table[delphiMethodPlot[0, True, False, &quot;Round &quot; &lt;&gt; ToString[i]], 15]], {i, 3}], \n    Table[delphiMethodPlot[0, True, False, &quot;End: The facilitator produces a final report.&quot;], 60]], AnimationRate -&gt; 30]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0k6j4neosl4i7.png\" alt=\"Snapshot from an animation representing the Delphi process\" width=\"820\" height=\"907\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0k6j4neosl4i7-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0k6j4neosl4i7-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0k6j4neosl4i7-md.png 768w\"></figure><h3 id=\"why-simulate-a-delphi-process-with-llms\">Why simulate a Delphi process with LLMS?</h3>\n<h4 id=\"studying-llm-capabilities\">Studying LLM Capabilities</h4>\n<p>LLMs provide a unique laboratory for studying artificial intelligence capabilities in structured dialogue. We can systematically evaluate how well these models maintain consistent expertise and viewpoints across multiple rounds of interaction - a key test of their ability to maintain coherent personas. The controlled environment allows us to study how AI systems incorporate new information while maintaining logical reasoning threads, and observe how they handle disagreements and work toward consensus. Perhaps most importantly, what would take weeks or months with human experts can be simulated in minutes, enabling rapid experimentation with different approaches and parameters. </p><h4 id=\"benefits-for-studying-structured-communication\">Benefits for Studying Structured Communication</h4>\n<p>The digital nature and speed of LLM interactions offers unprecedented opportunities to study structured communication processes. Every exchange can be logged and analyzed computationally, revealing patterns in how consensus emerges and how different viewpoints influence each other. Researchers can precisely control and vary process parameters. This reproducibility and scalability simply isn’t possible with traditional human-based studies, making LLM simulations a powerful tool for understanding and possibly improving structured communication protocols. </p><h4 id=\"limitations-and-considerations\">Limitations and Considerations</h4>\n<p>While promising, this approach comes with important limitations that must be considered. LLMs lack the deep, embodied experience of human experts - their expertise is ultimately derived from training data rather than years of lived experience. Since all participants in a simulation draw from the same underlying model, there’s a risk of artificial consensus that doesn’t reflect the true diversity of expert opinions. Additionally, LLMs don’t have professional reputations or real-world consequences to consider when making judgments, potentially limiting the relevance of their decisions. Findings should be interpreted with appropriate awareness of these constraints.</p><h3 id=\"motivation-for-using-wolfram-language\">Motivation for using Wolfram Language</h3>\n<p>A few advantages of using Wolfram Language to implement an LLM Delphi process simulation are:</p><ul>\n<li><p>The LLM connectivity functions in Wolfram Language are of exceptionally high quality. They are versatile and very well-documented.</p></li>\n<li><p>There are many great LLM-related functions like <a href=\"https://reference.wolfram.com/language/ref/ChatObject\">ChatObject</a>, <a href=\"https://reference.wolfram.com/language/ref/ChatEvaluate\">ChatEvaluate</a>, <a href=\"https://reference.wolfram.com/language/ref/LLMSynthesize\">LLMSynthesize</a>, <a href=\"https://reference.wolfram.com/language/ref/LLMPromptGenerator\">LLMPromptGenerator</a>, <a href=\"https://reference.wolfram.com/language/ref/LLMFunction\">LLMFunction</a>, <a href=\"https://reference.wolfram.com/language/ref/LLMTool\">LLMTool</a>. </p></li>\n<li><p>Being able to connect LLMs to the full Wolfram Language standard library of functions and symbols, the wolfram resource system, and wolfram knowledgebase.</p></li>\n</ul>\n<h2 id=\"llm-delphi-process-implementation\"><em>LLM Delphi Process Implementation</em></h2>\n<h3 id=\"defining-a-project-prompt-bank\">Defining a project prompt bank</h3>\n<p>Define a dataset of project prompts:</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/19u9mclxjw50y.png\" alt=\"Definition of a dataset of project prompts\" width=\"1195\" height=\"719\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/19u9mclxjw50y-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/19u9mclxjw50y-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/19u9mclxjw50y-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/Screenshot-2025-08-15-at-22.39.36.png\" alt=\"Prompt bank dataset preview (cut off)\" width=\"1398\" height=\"1058\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.39.36-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.39.36-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.39.36-md.png 768w\"></figure><h3 id=\"participants-setup\">Participants setup</h3>\n<h4 id=\"defining-a-dataset-of-persona-details\">Defining a dataset of persona details</h4>\n<p><em>Generate 24 conflicting opinions:</em></p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/0um5kz93vlo6r.png\" alt=\"Generate 24 conflicting opinions\" width=\"796\" height=\"85\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0um5kz93vlo6r-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0um5kz93vlo6r-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0um5kz93vlo6r-md.png 768w\"></figure><p><em>Generate a dataset of participant details (name, persona prompt, a sample of preexisting perspectives):</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0ang0i5eq7168.png\" alt=\"Generate a dataset of participant details\" width=\"2530\" height=\"323\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0ang0i5eq7168-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0ang0i5eq7168-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0ang0i5eq7168-md.png 768w\"></figure><p><em>Let’s load a pre-generated dataset of participant parameters:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/05a87xett01ev.png\" alt=\"Load a pre-generated dataset of participant parameters\" width=\"567\" height=\"78\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/05a87xett01ev-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/05a87xett01ev-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/05a87xett01ev-md.png 768w\"></figure><table>\n<thead>\n<tr>\n<th>Emoji</th>\n<th>Name</th>\n<th>Persona Prompt</th>\n<th>Prior Perspectives</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>🌱👩‍🌾</td>\n<td>Horticulturist</td>\n<td>You are a horticulturist specializing in plant selection and care. Your role is to provide expert advice on the types of plants and vegetables that would thrive in the local climate and soil conditions. Consider factors such as sunlight, water requirements, and pest resistance in your recommendations.</td>\n<td>{The garden should feature a diverse range of exotic plants to make it visually appealing and unique., It should be on the outskirts of town, where it’s quieter and more peaceful for gardening without disturbances., The primary purpose of the garden is to grow food for the community, and any surplus should be donated to local food banks.}</td>\n</tr>\n<tr>\n<td>🌳👨‍🎨</td>\n<td>Landscape architect</td>\n<td>You are a landscape architect with expertise in designing outdoor spaces. Your task is to offer insights into the optimal layout and design of the community garden. Consider elements such as garden aesthetics, accessibility, and efficient use of space in your suggestions.</td>\n<td>{We should keep the garden small and manageable to maintain quality rather than quantity., Mandatory volunteer days feel forced; it should be up to individual gardeners to maintain their own plots., The garden should be expanded to include more plots in order to serve additional community members.}</td>\n</tr>\n<tr>\n<td>🌍👫</td>\n<td>Community organizer</td>\n<td>You are a community organizer focused on engaging and mobilizing local residents. Your goal is to propose strategies for involving the community in the garden project, ensuring it meets their needs and encourages participation. Think about ways to organize events, workshops, and volunteer opportunities.</td>\n<td>{We should have scheduled volunteer days every week to keep the garden maintained and foster community bonds., We should focus on native plants to promote local biodiversity and sustainability., Everyone should have equal say, and decisions should be made through community votes to promote democratic involvement.}</td>\n</tr>\n<tr>\n<td>🔬👩‍🔬</td>\n<td>Environmental scientist</td>\n<td>You are an environmental scientist with a focus on sustainable practices. Your responsibility is to advise on environmentally friendly gardening techniques, such as composting, water conservation, and organic pest control. Provide guidance on minimizing the garden’s ecological footprint.</td>\n<td>{We should focus on creating educational programs for local schools to teach kids about gardening and sustainability., The garden should be an exclusive space for members to harvest fruits and vegetables for their own households only., All gardening practices should be strictly organic; chemicals have no place in a community garden.}</td>\n</tr>\n</tbody></table>\n<h4 id=\"initializing-participant-chat-objects\">Initializing participant chat objects</h4>\n<p><em>Initialise a participant chat object with the system prompt, participant persona prompt, and participant prior (preexisting) perspectives:</em></p><pre><code class=\"language-wl\">In[]:= ClearAll[initialiseParticipantChat] \n  \n initialiseParticipantChat[participantData_] := ChatObject[StringTemplate[promptBank[&quot;Initial participant prompt template&quot;]][&lt;|\n          (*Shared system prompt*) &quot;SystemPrompt&quot; -&gt; promptBank[&quot;Shared participant prompt&quot;], \n          (*Persona prompt:*) &quot;PersonaPrompt&quot; -&gt; participantData[&quot;Persona Prompt&quot;], \n          (*Prior perspectives:*) &quot;PriorPerspectives&quot; -&gt; (If[ListQ[#1], StringRiffle[Normal[#1], &quot;\\n--------------\\n&quot;], #1] &amp;@Normal[participantData[&quot;Prior Perspectives&quot;]]) \n          |&gt;]] /; MemberQ[{Association, Dataset}, Head[participantData]]\n</code></pre>\n<p><em>Initialise a participant chat object:</em></p><pre><code class=\"language-wl\">In[]:= initialiseParticipantChat[participantParameterDataset[[1]]]\n</code></pre>\n<pre><code class=\"language-wl\">Out[]= &quot;The garden should feature a diverse range of exotic plants to make it visually appealing and unique.--------------It should be on the outskirts of town, where it&#39;s quieter and more peaceful for gardening without disturbances.--------------The primary purpose of the garden is to grow food for the community, and any surplus should be donated to local food banks.&quot;\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/1ny77ybl4x6ee-2.png\" alt=\"\" width=\"237\" height=\"86\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1ny77ybl4x6ee-2-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1ny77ybl4x6ee-2-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1ny77ybl4x6ee-2-md.png 768w\"></figure><p><em>Initializing all participant chat objects at once:</em></p><pre><code class=\"language-wl\">In[]:= ClearAll[participantChats]\n participantChats = Dataset[Association[Map[#Name -&gt; initialiseParticipantChat[#] &amp;, Normal[participantParameterDataset]]]]\n</code></pre>\n<table>\n<thead>\n<tr>\n<th>Horticulturist</th>\n<th>Landscape architect</th>\n<th>Community organizer</th>\n<th>Environmental scientist</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>-ChatObject-</td>\n<td>-ChatObject-</td>\n<td>-ChatObject-</td>\n<td>-ChatObject-</td>\n</tr>\n</tbody></table>\n<h3 id=\"facilitator-setup\">Facilitator setup</h3>\n<h4 id=\"providing-instructions-from-the-facilitator-to-the-participants-and-getting-participant-contributions\">Providing instructions from the facilitator to the participants, and getting participant contributions</h4>\n<p><em>Construct facilitator instructions to participants:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0aykn2josyvjv.png\" alt=\"\" width=\"1739\" height=\"119\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0aykn2josyvjv-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0aykn2josyvjv-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0aykn2josyvjv-md.png 768w\"></figure><p><em>Construct the initial instructions to participants from the facilitator:</em></p><pre><code class=\"language-wl\">In[]:= (*constructInstructionsFromFacilitator[]*)\n</code></pre>\n<p><em>Construct instructions from the facilitator, a list of materials:</em></p><pre><code class=\"language-wl\">In[]:= (*constructInstructionsFromFacilitator[{&lt;|Step-&gt;1,Report-&gt;REPORT CONTENTS|&gt;}]*)\n</code></pre>\n<p><em>Request an initial (first round) contribution from one participant:</em></p><pre><code class=\"language-wl\">In[]:= (*ChatEvaluate[\n initialiseParticipantChat[participantParameterDataset[[1]]],\n (*Initial (first round) participant contribution request:*)\n constructInstructionsFromFacilitator[]\n ]*)\n</code></pre>\n<p><em>Request initial (first round) participant contributions from all participants:</em></p><pre><code class=\"language-wl\">In[]:= (*Map[ChatEvaluate[#,constructInstructionsFromFacilitator[]]&amp;,participantChats]*)\n</code></pre>\n<h4 id=\"providing-instructions-to-the-facilitator-and-getting-the-facilitator-to-produce-intermediate-reports\">Providing instructions to the facilitator, and getting the facilitator to produce intermediate reports</h4>\n<p><em>Initialize a facilitator chat object:</em></p><pre><code class=\"language-wl\">In[]:= ClearAll[facilitatorChat]\n facilitatorChat = ChatObject[promptBank[&quot;Initial instructions to facilitator&quot;]]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/15vejcwe3gdmg.png\" alt=\"Chat object\" width=\"237\" height=\"86\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/15vejcwe3gdmg-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/15vejcwe3gdmg-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/15vejcwe3gdmg-md.png 768w\"></figure><p><em>Extract the latest participant responses:</em></p><pre><code class=\"language-wl\">In[]:= ClearAll[latestParticipantResponses]\n latestParticipantResponses[participantChats_Dataset] := participantChats[All, Last[#[&quot;Messages&quot;]] &amp;][Select[#&quot;Role&quot; == &quot;Assistant&quot; &amp;], &quot;Content&quot;, Last, #&quot;Data&quot; &amp;]\n</code></pre>\n<p><em>Example:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0y00znl27qdxv-2.png\" alt=\"\" width=\"545\" height=\"41\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0y00znl27qdxv-2-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0y00znl27qdxv-2-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0y00znl27qdxv-2-md.png 768w\"></figure><p><em>Construct an instructions prompt for the facilitator to produce a report based on the latest round of participant contributions:</em></p><pre><code class=\"language-wl\">In[]:= ClearAll[constructInstructionsToFacilitator]\n constructInstructionsToFacilitator[latestParticipantResponses_Dataset] := StringTemplate[\n        promptBank[&quot;Facilitator materials template&quot;]][&lt;|&quot;LatestParticipantResponses&quot; -&gt; StringRiffle[KeyValueMap[\n                   StringTemplate[&quot;Contributor: `1`\\nContribution:\\n`2`&quot;][##] &amp;,\n                   Normal[latestParticipantResponses]], &quot;\\n--------------\\n\\n&quot;]|&gt;]\n</code></pre>\n<p><em>Example:</em></p><p><em>Submit people’s latest round of contributions to the facilitator and ask the facilitator to produce a report:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/1a62mzg18g6x8.png\" alt=\"\" width=\"1378\" height=\"41\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1a62mzg18g6x8-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1a62mzg18g6x8-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1a62mzg18g6x8-md.png 768w\"></figure><h4 id=\"sending-facilitator-reports-to-participants\">Sending facilitator reports to participants</h4>\n<p><em>Get the latest response (report) from the facilitator:</em></p><pre><code class=\"language-wl\">In[]:= ClearAll[latestFacilitatorResponse]\n latestFacilitatorResponse[facilitatorChat_ChatObject, defaultResponse_ : promptBank[&quot;Initial writing prompt&quot;]] := If[Length[#] == 1, \n         defaultResponse, Last[Last[Select[#, #Role == &quot;Assistant&quot; &amp;]][[&quot;Content&quot;]]][&quot;Data&quot;]] &amp;@facilitatorChat[&quot;Messages&quot;]\n</code></pre>\n<p><em>Example:</em></p><pre><code class=\"language-wl\">In[]:= (*latestFacilitatorResponse[facilitatorChat]*)\n</code></pre>\n<p><em>Send all participants the report for the latest round, and prompt them to share their perspectives again:</em></p><pre><code class=\"language-wl\">In[]:= (*Map[ChatEvaluate[#,constructInstructionsFromFacilitator[\n {&lt;|Round-&gt;1,Report-&gt;latestFacilitatorResponse[facilitatorChat]|&gt;}]]&amp;,participantChats]*)\n</code></pre>\n<p><em>Extract the new latest responses:</em></p><pre><code class=\"language-wl\">In[]:= (*latestParticipantResponses[%]*)\n</code></pre>\n<h3 id=\"tying-it-all-together-simulating-the-delphi-process\">Tying it all together: simulating the Delphi process</h3>\n<p>A Delphi process round is made from the contributions of participants + the report produced by the facilitator.</p><p><em>Define a function to perform a single round of an automated Delphi process:</em></p><pre><code class=\"language-wl\">In[]:= ClearAll[delphiProcessRound]\n delphiProcessRound[{round_Integer, participantChats_Dataset, facilitatorChat_ChatObject}] := {round + 1, #, ChatEvaluate[\n          facilitatorChat, constructInstructionsToFacilitator[latestParticipantResponses[#](*,round+1*)]]} &amp;@Map[\n            ChatEvaluate[#, constructInstructionsFromFacilitator[\n                   {&lt;|&quot;Round&quot; -&gt; round, If[round == 0, &quot;Instructions&quot;, &quot;Report&quot;] -&gt; latestFacilitatorResponse[facilitatorChat]|&gt;}]] &amp;, \n            participantChats]\n</code></pre>\n<p>After the last round, the facilitator produces a final report.</p><p><em>Define a function to produce the final Delphi process report from the facilitator:</em></p><pre><code class=\"language-wl\">In[]:= ClearAll[delphiProcessFinalReport]\n delphiProcessFinalReport[facilitatorChat_ChatObject] := ChatEvaluate[facilitatorChat, promptBank[&quot;Final report generation prompt&quot;]]\n</code></pre>\n<p><em>Run 1 round of a Delphi process:</em></p><pre><code class=\"language-wl\">In[]:= (*delphiProcessRound[{0,participantChats,facilitatorChat}]*)\n</code></pre>\n<p><em>Run a 3 round Delphi process:</em></p><pre><code class=\"language-wl\">In[]:= (*threeRoundDelphiProcessData=AbsoluteTiming[Nest[delphiProcessRound,{0,participantChats,facilitatorChat},3]];*)\n</code></pre>\n<p><em>Conclude the 3 round Delphi process with a final report:</em></p><pre><code class=\"language-wl\">In[]:= (*latestFacilitatorResponse[delphiProcessFinalReport[Last[Last[threeRoundDelphiProcessData]]]]*)\n</code></pre>\n<p><em>In one go, perform a 3 round Delphi process, and generate the final report:</em></p><pre><code class=\"language-wl\">In[]:= threeRoundDelphiProcessData = MapAt[delphiProcessFinalReport, Nest[delphiProcessRound, {0, participantChats, facilitatorChat}, 3],3];\n</code></pre>\n<pre><code class=\"language-wl\">In[]:= Iconize[threeRoundDelphiProcessData]\n</code></pre>\n<figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/04f11y5b1vhzy.png\" alt=\"Iconized data\" width=\"88\" height=\"41\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/04f11y5b1vhzy-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/04f11y5b1vhzy-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/04f11y5b1vhzy-md.png 768w\"></figure><p>Let’s load a precomputed simulation result:</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/17ugn9x2lpitf.png\" alt=\"Image description\" width=\"1089\" height=\"38\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/17ugn9x2lpitf-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/17ugn9x2lpitf-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/17ugn9x2lpitf-md.png 768w\"></figure><h3 id=\"fetching-participant-contributionsfacilitator-reports-from-completed-simulations\">Fetching participant contributions/facilitator reports from completed simulations</h3>\n<h4 id=\"implementation-nthroundcontributions-nthroundcontributionspeechbubbles-nthroundreport-nthroundreportspeechbubble\"><em>Implementation:</em> (nthRoundContributions, nthRoundContributionSpeechBubbles, nthRoundReport, nthRoundReportSpeechBubble)</h4>\n<p><em>Define a function to retrieve the contributions of the participants at the nth Delphi process round:</em></p><pre><code class=\"language-wl\">In[]:= ClearAll[nthRoundContributions]\n nthRoundContributions[participantChats_Dataset, n_Integer?Positive] :=participantChats[All, Select[#[&quot;Messages&quot;], #Role == &quot;Assistant&quot; &amp;][[n]][&quot;Content&quot;][[1]][&quot;Data&quot;] &amp;]\n</code></pre>\n<p><em>Retrieve the nth round participant contributions:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/Screenshot-2025-08-15-at-22.55.37.png\" alt=\"\" width=\"1706\" height=\"572\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.55.37-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.55.37-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.55.37-md.png 768w\"></figure><ol>\n<li><strong>Understanding Soil Composition and Local Climate</strong>: The notion that any plant can thrive with enough watering and fertilization overlooks the critical role of soil health and structure. Different plants have varying requirements for soil pH, drainage, and nutrient availability. For example, root vegetables like carrots and beets prefer sandy loam for proper growth, while leafy greens may do better in richer, loamy soils. It is essential to assess soil composition and amend it appropriately before deciding on plant varieties.</li>\n<li><strong>Sustainable Plant Selection</strong>: Emphasizing diversity in our plant selection can encourage resilience against pests and diseases. Instead of exotic plants that may not adapt well to our local conditions, we should focus on selecting a mix of native and well-adapted species. Native plants often require less water and fertilizer and can support local biodiversity by attracting pollinators and beneficial insects. Some great examples include coneflowers and black-eyed Susans, which are visually appealing and attract bees and butterflies while requiring minimal maintenance.</li>\n<li><strong>Balancing Aesthetics and Functionality</strong>: While I understand the desire for ornamental beauty in the garden, it’s important to recognize that aesthetics can coexist with productivity. Many flowering plants are not only attractive but also serve practical purposes. For example, marigolds can deter pests and even help with vegetable production. Incorporating edible ornamental plants, such as kale or swiss chard that have beautiful foliage, can enhance the garden’s visual appeal while contributing to food security.</li>\n<li><strong>Educational Opportunities</strong>: Community gardens can and should serve as platforms for education about sustainable gardening practices and the importance of local ecosystems. This involves showcasing both ornamental plants and edible crops, thus providing visitors with a comprehensive understanding of gardening. Workshops on growing food, composting, and pest management can create a deeper connection amongst community members and foster a sense of shared responsibility in maintaining the garden.</li>\n<li><strong>The Role of Community Involvement</strong>: To strengthen the sense of community, it’s essential to involve local residents in the decision-making process regarding plant choices. Engaging community members in selecting plants that reflect their preferences while being considerate of environmental conditions will promote a sense of ownership and pride in the garden. By co-creating the space, we can cultivate a richer community connection to our garden.</li>\n</ol>\n<p>Overall, my approach emphasizes the importance of informed plant selection that suits our local conditions and fosters both ecological health and community engagement. Let’s continue the conversation focusing on sustainable practices, integrating diverse plant types, and enhancing community involvement to create a resilient and beautiful space for everyone. | As a landscape architect with a focus on community gardens, I appreciate the rich tapestry of ideas presented regarding the design and functionality of these vital spaces. The key themes emerging from our discussions include aesthetics, biodiversity, sustainability, and community engagement. </p><p>First, I wholeheartedly support the pragmatic perspective advocating for the integration of edible landscaping. The blend of fruit trees, berry bushes, and perennial herbs with traditional vegetable plots not only enhances the garden’s visual appeal but also contributes to biodiversity and food accessibility, which are critical in urban settings. The aesthetic value of such a diverse garden can serve as a powerful tool for attracting community involvement, as people are often drawn to vibrant spaces where they can witness the results of their labor. </p><p>The consensual perspective adds an important layer by emphasizing sustainable design principles. Incorporating elements such as rain gardens and permeable pathways not only addresses stormwater management but also creates a more resilient ecosystem within the garden. This can significantly enhance the overall health of the garden while creating spaces that encourage local wildlife, thus bolstering pollinator populations which, in turn, improves vegetable and fruit production. </p><p>However, I understand the concern raised from the incoherent perspective that prioritizes functionality over aesthetics. While practicality is essential—especially with features like raised beds, composting areas, and secure tool storage—these elements need not be mutually exclusive with design. I propose a solution that intertwines functionality and aesthetics by deliberately positioning practical structures to create an alluring layout. For instance, raised beds can be designed with engaging shapes and materials that complement the natural surroundings, while composting areas can be concealed using native plant screens, maintaining a visually appealing environment.</p><p>Moreover, flexible zones for seasonal activities, as highlighted in the consensual perspective, offer a fantastic way to cater to community needs and desires. These adaptable spaces could allow for a range of activities including gardening workshops, children’s programs, or social gatherings, significantly enhancing community spirit and ownership of the garden. </p><p>That said, we must also consider the challenges of engaging a diverse community with varying levels of gardening experience and physical ability. Therefore, the design should prioritize accessibility. This can involve ensuring paths are wide enough for all users, incorporating raised beds at various heights, and providing seating that accommodates all community members.</p><p>In summary, the ideal community garden should be a harmonious blend of aesthetics, functionality, and sustainability. By leveraging the best aspects of the differing perspectives we’ve discussed, we can design a community garden that not only thrives ecologically and socially but also stands as a cherished space for all. I look forward to further discussions and collaborations that build upon these insights to create an inclusive and flourishing garden space. | As a community organizer focused on fostering meaningful engagement and participation in local initiatives, I appreciate the diverse perspectives shared regarding the establishment of our community garden project. There are several key themes that echo throughout these viewpoints, and I believe addressing them will enhance not just the garden’s design and implementation but also its overall success and sustainability.</p><p><strong>1. Inclusion and Accessibility:</strong>\nThe concern regarding potential exclusion, particularly for lower-income residents and those with mobility challenges, resonates deeply with me. It’s paramount that our planning phase prioritizes incorporating the voices and needs of the entire community. To achieve this, I suggest forming a Community Advisory Board that includes representation from marginalized groups. This board can be instrumental in advising on site selection, design features (such as raised beds for wheelchair access), and ensuring equitable access to resources.</p><p><strong>2. Sustained Involvement:</strong>\nThe idea of fostering ongoing local ownership through mentorship programs makes great sense. We could establish a tiered volunteer system, where experienced gardeners mentor novices not only in gardening skills but also in other areas, such as community organizing and sustainability practices. Additionally, implementing a regular schedule of volunteer days that specifically caters to varied schedules can encourage more residents to participate.</p><p><strong>3. Cultural Relevance and Diversity:</strong>\nI wholeheartedly support the notion of integrating local cultural elements into the garden. In addition to individual sharing of gardening practices and culinary traditions, we can organize themed planting days or workshops that celebrate specific cultural events or festivals, enhancing the diversity of our plantings and attracting participants from various backgrounds. This could culminate in intercultural potlucks that honor and showcase the different connections our community has to food, growing practices, and identity.</p><p><strong>4. Potential Challenges:</strong>\nWhile the proposed ideas hold great promise, potential challenges such as funding for maintaining infrastructure, ongoing volunteer engagement, and managing diverse opinions exist. To address funding, we can explore partnerships with local businesses and schools, applying for grants specifically aimed at urban agriculture and community development. We can also incentivize ongoing volunteer work through a points system where volunteers earn rewards, such as seeds, gardening tools, or local produce.</p><p>In conclusion, I believe that through intentional outreach, continuous engagement strategies, and inclusive programming, we can build a community garden that not only serves as a hub for gardening but also as a symbol of community resilience and collaboration. I look forward to our continued discussions and to exploring how we can collaboratively implement these strategies to address both the benefits and challenges presented. | As an environmental scientist focused on sustainable gardening practices, I appreciate the perspectives shared and believe they highlight critical themes for fostering a sustainable community garden. Here are my thoughts on the points raised, along with additional insights and recommendations.</p><p>Firstly, the emphasis on integrating native plant species is spot-on. Native plants are not only adapted to local environmental conditions, which reduces the need for extensive watering and chemical inputs, but they also play a crucial role in supporting local pollinators and wildlife. By creating a biodiverse ecosystem, we enhance resilience against pests and diseases, making the garden more sustainable in the long run. I would encourage community members to participate in workshops or educational sessions to learn about local flora, which can further deepen their connection to the environment and motivate stewardship. </p><p>However, we must also address the challenge many face regarding the misconceptions about synthetic fertilizers. While they may initially provide a quick fix for nutrient deficiencies, their prolonged use can degrade soil health and disrupt local ecosystems through nutrient runoff. It’s essential to shift the narrative towards looking at organic amendments, like compost or well-aged manure, as viable alternatives for enhancing soil fertility. Composting not only enriches the soil but also helps in reducing waste and fostering a closed-loop system within the garden. I recommend establishing a community composting program, where participants can contribute kitchen scraps and garden waste, thereby promoting shared responsibility for waste management and soil health.</p><p>Additionally, the idea of employing companion planting is invaluable. This approach fosters mutual benefits amongst plant species. For example, planting marigolds among vegetables can help deter pests, while legumes can naturally fix nitrogen in the soil, reducing the need for external fertilizers. Integrating such practices can create a harmonious ecosystem while educating the community about the interdependence of species.</p><p>Furthermore, I would urge the garden community to consider water conservation techniques such as rainwater harvesting and drip irrigation. These methods not only minimize water use but also prevent soil erosion and water wastage, making our gardens more resilient to droughts.</p><p>In conclusion, I believe that through a combination of native planting, organic amendment practices, companion planting, and water conservation, we can cultivate a community garden that is both productive and sustainable. Let us work collaboratively to create educational programs that empower community members to adopt these practices, while also addressing potential challenges to foster a robust and environmentally friendly gardening culture. I look forward to hearing how others might build upon or challenge these ideas in our subsequent discussions. |</p><p>Define a function to construct speech bubbles for the nth round contribution of a participant specification <em>participants</em> (which could be All, a single participant name, or a list of participant names):</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/090s6if3in8jv.png\" alt=\"\" width=\"1106\" height=\"233\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-md.png 768w\"></figure><p>*Example: *</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/1gaifup1y9wd1.png\" alt=\"\" width=\"1520\" height=\"41\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1gaifup1y9wd1-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1gaifup1y9wd1-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1gaifup1y9wd1-md.png 768w\"></figure><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/1h5ybo970k9qi.png\" alt=\"\" width=\"1226\" height=\"855\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1h5ybo970k9qi-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1h5ybo970k9qi-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1h5ybo970k9qi-md.png 768w\"></figure><p><em>Define a function to retrieve the facilitator reports at the nth Delphi process round:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0ljlk3quiqz29.png\" alt=\"\" width=\"2262\" height=\"68\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0ljlk3quiqz29-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0ljlk3quiqz29-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0ljlk3quiqz29-md.png 768w\"></figure><p><em>Retrieve the nth round facilitator report:</em></p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/1l0peedx4yo34.png\" alt=\"\" width=\"478\" height=\"41\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1l0peedx4yo34-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1l0peedx4yo34-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1l0peedx4yo34-md.png 768w\"></figure><p><em>Define a function to construct nth round facilitator report speech bubbles:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0lv37w7ofd568.png\" alt=\"\" width=\"1577\" height=\"236\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0lv37w7ofd568-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0lv37w7ofd568-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0lv37w7ofd568-md.png 768w\"></figure><p>*Example: *</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/1cm44wjglqejj.png\" alt=\"\" width=\"1194\" height=\"41\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1cm44wjglqejj-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1cm44wjglqejj-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1cm44wjglqejj-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0m65zjrnlrk4h.png\" alt=\"\" width=\"1181\" height=\"774\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0m65zjrnlrk4h-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0m65zjrnlrk4h-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0m65zjrnlrk4h-md.png 768w\"></figure><h4 id=\"visualising-the-full-dialogue-from-a-simulated-delphi-process\">Visualising the full dialogue from a simulated Delphi process:</h4>\n<p><em>Visualise the sequence of communications between agents in the Delphi process:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/1v8y6wfhn3sfw.png\" alt=\"\" width=\"1801\" height=\"349\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1v8y6wfhn3sfw-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1v8y6wfhn3sfw-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1v8y6wfhn3sfw-md.png 768w\"></figure><p>(see the included visualisation at the end of this text)</p><h3 id=\"other-miscellaneous-visualisation-tools\">Other miscellaneous visualisation tools</h3>\n<h4 id=\"implementation-diskframe-delphimethodplot\"><em>Implementation:</em> (diskFrame, delphiMethodPlot)</h4>\n<p><em>Create disk frame around an expression:</em></p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/090s6if3in8jv-2.png\" alt=\"\" width=\"1106\" height=\"233\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-2-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-2-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-2-md.png 768w\"></figure><p><em>Create a Delphi process illustration:</em></p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/1vzaoomjz8zr0.png\" alt=\"\" width=\"2536\" height=\"403\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1vzaoomjz8zr0-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1vzaoomjz8zr0-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1vzaoomjz8zr0-md.png 768w\"></figure><p><em>Make an animation illustrating the process:</em></p><pre><code class=\"language-wl\">In[]:= ListAnimate[Join[Join @@ Table[Join[\n       Table[delphiMethodPlot[distanceFromOrigin, True, False, &quot;Round &quot; &lt;&gt; ToString[i]], {distanceFromOrigin, Subdivide[0, .75, 30]}], \n       Table[delphiMethodPlot[.75, True, False, &quot;Round &quot; &lt;&gt; ToString[i]],15], Table[delphiMethodPlot[.75, False, False, &quot;Round &quot; &lt;&gt; ToString[i]], 15], \n       Table[delphiMethodPlot[distanceFromOrigin, False, False, &quot;Round &quot; &lt;&gt; ToString[i]], {distanceFromOrigin, Subdivide[.75, 0, 30]}], \n       Table[delphiMethodPlot[0, False, False, &quot;Round &quot; &lt;&gt; ToString[i]],15], Table[delphiMethodPlot[0, True, False, &quot;Round &quot; &lt;&gt; ToString[i]], 15]], {i, 3}], \n    Table[delphiMethodPlot[0, True, False, &quot;End: The facilitator produces a final report.&quot;], 30]], AnimationRate -&gt; 30]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/1jrowcy9twoa8.png\" alt=\"\" width=\"820\" height=\"907\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1jrowcy9twoa8-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1jrowcy9twoa8-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1jrowcy9twoa8-md.png 768w\"></figure><h2 id=\"case-study-establishing-and-maintaining-a-community-garden\">Case Study: Establishing and Maintaining a Community Garden</h2>\n<h3 id=\"the-case-study-setting\">The case study setting</h3>\n<p>This case study simulates a Delphi process focused on developing a comprehensive plan for establishing and maintaining a community garden. </p><p>The simulation employs 4 LLM “expert” participants, each represented by their role and emoji identifier:</p><ol>\n<li>Horticulturist (🌱👩‍🌾) - Plant selection and care specialist</li>\n<li>Landscape Architect (🌳👨‍🎨) - Design and spatial planning expert</li>\n<li>Community Organizer (🌍👫) - Community engagement and program coordination</li>\n<li>Environmental Scientist (🔬👩‍🔬) - Environmental impact and sustainability advisor</li>\n</ol>\n<p>Plus a Facilitator (🕵️) who guides the process, summarizes findings, and produces reports. </p><h3 id=\"participant-system-prompts\">Participant system prompts</h3>\n<p>The LLM expert participants are given the following shared instructions: </p><p>Shared participant system prompt:</p><pre><code class=\"language-wl\">In[]:= Framed[Text[Style[promptBank[&quot;Shared participant prompt&quot;], Italic]], RoundingRadius -&gt; 5]\n</code></pre>\n<figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/1hq1mwjuuylfb.png\" alt=\"\" width=\"2786\" height=\"289\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1hq1mwjuuylfb-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1hq1mwjuuylfb-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1hq1mwjuuylfb-md.png 768w\"></figure><p>In addition to these shared instructions, each participant gets their own persona prompt which describes the general , and some of the beliefs they should defend. For example:</p><p>Participant persona prompt example: The Horticulturist</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0l7d8px336ljg.png\" alt=\"\" width=\"1880\" height=\"137\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0l7d8px336ljg-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0l7d8px336ljg-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0l7d8px336ljg-md.png 768w\"></figure><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/1cozki4smkasv.png\" alt=\"\" width=\"2182\" height=\"680\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1cozki4smkasv-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1cozki4smkasv-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1cozki4smkasv-md.png 768w\"></figure><p>Participant beliefs are generated automatically using an LLM using the prompt:</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/1m8rvekmhvg8o.png\" alt=\"\" width=\"685\" height=\"41\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1m8rvekmhvg8o-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1m8rvekmhvg8o-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1m8rvekmhvg8o-md.png 768w\"></figure><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/0bgll1krzz5nh.png\" alt=\"\" width=\"1721\" height=\"56\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0bgll1krzz5nh-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0bgll1krzz5nh-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0bgll1krzz5nh-md.png 768w\"></figure><p>The resulting text is then converted into a list of first person statements using the prompt:</p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/1adufvrvtmh3b.png\" alt=\"\" width=\"685\" height=\"41\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/1adufvrvtmh3b-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1adufvrvtmh3b-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1adufvrvtmh3b-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0gwv7g2o5hcwh.png\" alt=\"\" width=\"1864\" height=\"250\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0gwv7g2o5hcwh-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0gwv7g2o5hcwh-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0gwv7g2o5hcwh-md.png 768w\"></figure><p>where $\\text{$\\grave{ }$1$\\grave{ }$}$ stands for the conflicting opinions list generated at the last step. </p><p>The participants are then assigned three randomly sampled perspectives. The sampling is set up such that no two personas will share identical beliefs.</p><p>Here is the dataset of the participant perspectives used in this case-study: </p><pre><code class=\"language-wl\">In[]:= participantParameterDataset[KeyDrop[&quot;Persona Prompt&quot;], &lt;|#, &quot;Prior Perspectives&quot; -&gt; Column[#&quot;Prior Perspectives&quot;]|&gt; &amp;]\n</code></pre>\n<table>\n<thead>\n<tr>\n<th>Emoji</th>\n<th>Name</th>\n<th>Prior Perspectives</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>🌱👩‍🌾</td>\n<td>Horticulturist</td>\n<td>{{The garden should feature a diverse range of exotic plants to make it visually appealing and unique.}, {It should be on the outskirts of town, where it’s quieter and more peaceful for gardening without disturbances.}, {The primary purpose of the garden is to grow food for the community, and any surplus should be donated to local food banks.}}</td>\n</tr>\n<tr>\n<td>🌳👨‍🎨</td>\n<td>Landscape architect</td>\n<td>{{We should keep the garden small and manageable to maintain quality rather than quantity.}, {Mandatory volunteer days feel forced; it should be up to individual gardeners to maintain their own plots.}, {The garden should be expanded to include more plots in order to serve additional community members.}}</td>\n</tr>\n<tr>\n<td>🌍👫</td>\n<td>Community organizer</td>\n<td>{{We should have scheduled volunteer days every week to keep the garden maintained and foster community bonds.}, {We should focus on native plants to promote local biodiversity and sustainability.}, {Everyone should have equal say, and decisions should be made through community votes to promote democratic involvement.}}</td>\n</tr>\n<tr>\n<td>🔬👩‍🔬</td>\n<td>Environmental scientist</td>\n<td>{{We should focus on creating educational programs for local schools to teach kids about gardening and sustainability.}, {The garden should be an exclusive space for members to harvest fruits and vegetables for their own households only.}, {All gardening practices should be strictly organic; chemicals have no place in a community garden.}}</td>\n</tr>\n</tbody></table>\n<p>When designing AI personas to represent different viewpoints in a multi-party dialogue, it’s important to carefully consider how to generate and manage disagreement while maintaining ethical safeguards. The approach used in this implementation is safe for several key reasons:</p><ol>\n<li>The domain is constrained to community gardening, a relatively non-controversial topic</li>\n<li>The perspective generation is focused on practical rather than ideological disagreements</li>\n<li>The shared participant prompt emphasizes constructive collaboration</li>\n<li>The facilitator role helps moderate and guide discussion toward consensus</li>\n<li>The system is designed to surface and resolve differences through reasoned dialogue</li>\n<li>The participant system prompt is completely transparent about the artificial nature of these perspectives. There’s no deception - the beliefs are explicitly described as aspects of a role the agent is playing.</li>\n<li>While the AI personas may adopt different perspectives, they are still bound by the underlying model’s learned safety constraints. The base reinforcement learning training acts as a fundamental safety rail that prevents egregiously harmful outputs, regardless of the assigned persona.</li>\n</ol>\n<p>The experimental justification for assigning the participant AI agents heterogenous perspectives is to ensure that the participants will disagree on some issues, and to echo real-world group negotiation processes. LLMs tend to be very inoffensive by design and will rarely diverge from mainstream social, political, or cultural norms. When we don’t explicitly enforce heterogeneity of agent opinions, they tend to converge to unanimous agreement very quickly, obstructing meaningful study of group decision-making and consensus-building processes.</p><p>At the start of each round, the participants are sent instructions from the facilitator in the following form:</p><pre><code class=\"language-wl\">In[]:= Framed[Text[Style[promptBank[&quot;Instructions from facilitator template&quot;], Italic]],RoundingRadius -&gt; 5]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0mls12ptpekcj.png\" alt=\"\" width=\"2478\" height=\"563\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0mls12ptpekcj-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0mls12ptpekcj-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0mls12ptpekcj-md.png 768w\"></figure><p>Each participant then responds to this prompt.</p><h3 id=\"the-facilitator-system-prompt\">The facilitator system prompt</h3>\n<p>The facilitator has the task of coordinating and directing the Delphi process. Unlike the expert participants who are given specific personas and perspectives, the facilitator is instructed to remain neutral and focus on process management. The facilitator is instructed using the following system prompt:</p><pre><code class=\"language-wl\">In[]:= Framed[Text[Style[promptBank[&quot;Initial instructions to facilitator&quot;], Italic]], RoundingRadius -&gt; 5]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/035sfh91ajxpx.png\" alt=\"\" width=\"2452\" height=\"250\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/035sfh91ajxpx-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/035sfh91ajxpx-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/035sfh91ajxpx-md.png 768w\"></figure><p>At each round, when the participants have completed their contributions, the facilitator is sent the latest list of contributions in the following template:</p><pre><code class=\"language-wl\">In[]:= Framed[Text[Style[promptBank[&quot;Facilitator materials template&quot;], Italic]], RoundingRadius -&gt; 5]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/06nt3vbqzfi37.png\" alt=\"\" width=\"2741\" height=\"563\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/06nt3vbqzfi37-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/06nt3vbqzfi37-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/06nt3vbqzfi37-md.png 768w\"></figure><p>The report the facilitator produces in response is sent out to the participants at the start of the next round. For the final round, the facilitator uses its latest report to produce a final report concluding the Delphi process.</p><h3 id=\"the-delphi-process\">The Delphi process</h3>\n<p>The simulated Delphi process of this case study consists of three rounds of structured communication between expert participants and a facilitator, culminating in a final report. A key feature of the implementation is the use of chat objects to provide each agent its own chat history and context throughout the process. </p><p>The core simulation can be executed with just three key components:</p><ol>\n<li>A dataset mapping participant names to their chat obbjects (containing participant system prompts)</li>\n<li>A facilitator ChatObject (containing the facilitator system prompt)</li>\n<li>The number of rounds to perform.</li>\n</ol>\n<p>Here’s the code that runs the complete process: </p><pre><code class=\"language-wl\">In[]:= threeRoundDelphiProcessData = MapAt[delphiProcessFinalReport, Nest[delphiProcessRound, {\n      (*Initial step number:*) 0, \n      (*Dataset of participant chat objects:*) participantChats, \n      (*Facilitator chat object:*) facilitatorChat},(*Number of rounds:*)3], 3];\n</code></pre>\n<p>The result looks like this:</p><pre><code class=\"language-wl\">In[]:= Dataset[AssociationThread[{&quot;Round Count&quot;, &quot;Participant Chats&quot;, &quot;Facilitator Chat&quot;}, threeRoundDelphiProcessData]]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/11da8zqwcppmx.png\" alt=\"\" width=\"1359\" height=\"1023\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/11da8zqwcppmx-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/11da8zqwcppmx-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/11da8zqwcppmx-md.png 768w\"></figure><p>The simulation results can be retrieved as plain text or speech bubbles. For more detail on this functionality, see the <em>Fetching participant contributions/facilitator reports from completed simulations</em> subsection of the <em>LLM Delphi Process Implementation</em> section of this article. </p><p>To make a speech bubble of the nth round response from a participant, we might write:</p><pre><code class=\"language-wl\">In[]:= First[nthRoundContributionSpeechBubbles[threeRoundDelphiProcessData[[2]], 2, \n    &quot;Landscape architect&quot;, \n    &quot;SnippetForm&quot; -&gt; True, &quot;SnippetLength&quot; -&gt; 10]]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/13qyjo9rab6t5.png\" alt=\"\" width=\"1244\" height=\"632\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/13qyjo9rab6t5-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/13qyjo9rab6t5-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/13qyjo9rab6t5-md.png 768w\"></figure><p>Likewise, to make a speech bubble for the nth round report, we might say:</p><pre><code class=\"language-wl\">In[]:= nthRoundReportSpeechBubble[Last[threeRoundDelphiProcessData], 1, \n   &quot;SnippetForm&quot; -&gt; True, &quot;SnippetLength&quot; -&gt; 10]\n</code></pre>\n<figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/0g9j5mu9p8p5g.png\" alt=\"\" width=\"1178\" height=\"620\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/0g9j5mu9p8p5g-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0g9j5mu9p8p5g-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0g9j5mu9p8p5g-md.png 768w\"></figure><h3 id=\"case-study-full-exchange-transcript\"><em>Case-study full exchange transcript</em></h3>\n<p>Visualise the full sequence of exchanges between agents in the case-study Delphi process simulation:</p><figure class=\"post__image\"><img src=\"https://phileasdg.github.io/media/posts/45/010t8jgipvpxf.png\" alt=\"\" width=\"1801\" height=\"349\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/010t8jgipvpxf-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/010t8jgipvpxf-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/010t8jgipvpxf-md.png 768w\"></figure><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://phileasdg.github.io/media/posts/45/fulltranscript.png\" alt=\"Full transcript\" width=\"902\" height=\"13790\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/45/responsive/fulltranscript-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/fulltranscript-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/fulltranscript-md.png 768w\"></figure><h3 id=\"qualitatively-speaking-how-did-the-llm-participants-and-facilitator-do\">Qualitatively speaking, how did the LLM participants and facilitator do?</h3>\n<p>I’m personally quite pleased with the results here. Using Anthropic’s Claude 3.5 Sonnet, the results feel remarkably natural and productive. Several aspects stand out:</p><ul>\n<li>The facilitator maintained neutrality while effectively summarizing key points, successfully identified areas of agreement and conflict, kept discussions focused and constructive, and succeeded at in anonymising contributions while preserving their marrow.</li>\n<li>The participants showed consistent role adherence while remaining flexible enough to engage with others’ ideas. They successfully balanced advocacy for their positions with willingness to find common ground, and brought forward new solutions and questions as discussions evolved. They also defended their distinct perspectives without becoming aggressive or rude.</li>\n</ul>\n<p>The simulation demonstrated that LLMs can effectively maintain consistent personas while engaging in meaningful negotiation and consensus-building. The quality of discourse suggests that this approach could be valuable for studying group decision-making processes and testing different facilitation strategies.</p><h2 id=\"what-next\">What Next?</h2>\n<p>This case study suggests the potential of using LLMs to study structured communication protocols. Wolfram proved to be an ideal environment for this work thanks to its powerful LLM functions, flexible syntax, and rich visualization capabilities.</p><p>Future work could explore several promising directions: </p><ul>\n<li>Quantitative analysis of semantic convergence in LLM-based Delphi processes</li>\n<li>Comparison of different LLM models in maintaining consistency across multiple rounds</li>\n<li>Application to other structured communication protocols beyond the Delphi method</li>\n<li>Development of tools for real-time monitoring and intervention in LLM-based group discussions</li>\n</ul>\n<p>The code and methodology presented here provide a foundation for researchers interested in using LLMs to study group decision-making and consensus-building processes.</p><h2 id=\"cite-this-work\">Cite this work</h2>\n<p><a href=\"https://community.wolfram.com/groups/-/m/t/3393596\">DelphAI: Structured communication with LLMs in a simulated Delphi process</a>\nby <a href=\"https://community.wolfram.com/web/phileasdg\">Phileas Dazeley-Gaist</a>\nWolfram Community, STAFF PICKS, February 14, 2025\n<a href=\"https://community.wolfram.com/groups/-/m/t/3393596\">https://community.wolfram.com/groups/-/m/t/3393596</a></p>",
            "image": "https://phileasdg.github.io/media/posts/45/Banner-image-Community-Post-LLM-Delphi-Method.png",
            "author": {
                "name": "Phileas Dazeley-Gaist"
            },
            "tags": [
                   "Work at Wolfram",
                   "Wolfram Language",
                   "Modelling",
                   "Mathematica",
                   "AI"
            ],
            "date_published": "2025-08-16T04:17:42+02:00",
            "date_modified": "2025-08-16T17:39:16+02:00"
        },
        {
            "id": "https://phileasdg.github.io/creative-generative-design-with-mathematical-marbling/",
            "url": "https://phileasdg.github.io/creative-generative-design-with-mathematical-marbling/",
            "title": "Creative Generative Design with Mathematical Marbling",
            "summary": "Note: This post was originally a short technical article I shared on&hellip;",
            "content_html": "<p class=\"msg msg--info\"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forums. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3258063\">here</a>. </p>\n<p class=\"msg--highlight msg \">See also: <a href=\"https://community.wolfram.com/groups/-/m/t/3271633\">M<span class=\"cc6\" data-native-text=\"true\">athematical marbling animation</span></a>, for even more marbling magic.</p>\n<h2>Paper Marbling and Mathematical Marbling</h2>\n<h3>What is Paper Marbling?</h3>\n<p>Ink marbling is the practice of dipping or dripping colorful inks or dyes onto a liquid surface, and swirling, displacing, cutting, dragging, and otherwise forming the ink into a design, often akin to patterns in marble. The earliest verified accounts of ink marbling date back to 12th century Japan, but the practice has a rich history throughout Asia, the Islamic World, and in Europe where it was extensively used to decorate book bindings. In Turkey, the practice is called “ebru” after the Persian word “ebrū”, which means “cloud-like”.</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-20.48.07.png\" alt=\"\" width=\"538\" height=\"345\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.48.07-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.48.07-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.48.07-md.png 768w\"></figure>\n<p>I find ink marbling deeply enchanting. The imprecision of the medium results in organic-seeming, flowing shapes - never perfectly regular or completely random. By combining techniques, artists can create a wide variety of motifs and designs, from waves and spirals to scallop shells, flowers, and trees.</p>\n<h3>Mathematical Marbling</h3>\n<p><span class=\"cc1\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">Mathematical marbling refers to the mathematical reproduction of the marbling process. Aubrey Jaffer has an excellent series of blog posts on the subject </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://people.csail.mit.edu/jaffer/Marbling/\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\" style=\"font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"><span class=\"cc4\" data-native-text=\"true\">on his website</span></a><span class=\"cc1\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">. He has also co-authored </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://ieeexplore.ieee.org/author/38513250100\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\" style=\"font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"><span class=\"cc4\" data-native-text=\"true\">several papers</span></a><span class=\"cc1\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> on mathematical and computational methods for marbling, </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://ieeexplore.ieee.org/document/7478444\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\" style=\"font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"><span class=\"cc4\" data-native-text=\"true\">including on marbling in 3D</span></a><span class=\"cc1\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">. In this technical article, I will describe, reproduce, and demonstrate some mathematical marbling methods from his work.</span></p>\n<p><span class=\"cc1\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">In his blog post </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://people.csail.mit.edu/jaffer/Marbling/Mathematics\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\" style=\"font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"><span class=\"cc4\" data-native-text=\"true\">The mathematics of marbling</span></a><span class=\"cc1\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">, Jaffer outlines several marbling methods that don’t require fluid mechanics theory to perform. This article will explore vector graphics implementations of three of these methods in Wolfram Language, respectively, for dripping ink drops on a marbling canvas such that new drops displace and distort previous ones, for tracing lines through the ink using a pointed object (or tine), and for tracing circles through the ink using a pointed object. The lines and curves produced by displacing ink using a sharp tool like a toothpick are known as tine lines.</span></p>\n<p><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">For each of these methods, I’ll split my exploration into a short description of the process, an implementation section containing my code, and an exploratory examples section demonstrating how you can use and combine these techniques to produce computational marbling art.</span></p>\n<div id=\"cell-2060b4c3-02e0-c040-9f43-92dbf2116dcf\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"cell-content\">\n<h2>Ink Drop Marbling</h2>\n<h3>Dropping Ink in a Marbling Tank</h3>\n<p>As we drip ink drops into the marbling tank, new drops will displace old ones such that given a point <em>P</em>, and a new paint drop of radius <em>r</em> centered at <em>C</em>, <em>P</em> will be displaced radially to the position:</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-20.53.05.png\" alt=\"\" width=\"234\" height=\"84\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.53.05-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.53.05-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.53.05-md.png 768w\"></figure>\n<p>This transformations preserves the area of all neighbourhoods not containing <em>C</em> (though it is not guaranteed to preserve the area of individual polygons due to their finite detail). </p>\n<p>Please visit <a href=\"https://people.csail.mit.edu/jaffer/Marbling/Dropping-Paint\">Aubrey Jaffer's website</a> for a more in-depth explanation.</p>\n<h2><em>Implementation:</em> inkDrop, marbleDisplace, and dripDrops</h2>\n<p>To download the original code, please consult the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3258063\">here</a>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-20.54.54.png\" alt=\"\" width=\"1780\" height=\"1586\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.54.54-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.54.54-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.54.54-md.png 768w\"></figure>\n<h3>Examples</h3>\n<p>The <em>dripDrops</em> function takes as its arguments: </p>\n<ol>\n<li>A list of polygons, or an empty list defining the existing geometry on the canvas.</li>\n<li>A list defining the sequence of new drop positions.</li>\n<li>A list of drop sizes. </li>\n</ol>\n<p>It returns the transformed geometry after dripping. With this function defined, we can begin to make marbling designs. </p>\n<h4>Basic examples</h4>\n<p><em>Drop 5 randomly coloured drops with radius 1 in the same place:</em></p>\n<figure class=\"post__image\"><em><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.00.08.png\" alt=\"\" width=\"507\" height=\"150\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.08-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.08-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.08-md.png 768w\"></figure></em></p>\n<p><em>Drop 12 randomly coloured drops with increasing radii in equally spaced intervals on a circle:</em></p>\n<figure class=\"post__image\"><em><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.00.43.png\" alt=\"\" width=\"455\" height=\"132\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.43-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.43-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.43-md.png 768w\"></figure></em></p>\n<p><em>Drop 25 randomly coloured identically sized drops randomly dripped in a rectangular region of the marbling tank: </em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.01.26.png\" alt=\"\" width=\"584\" height=\"368\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.01.26-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.01.26-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.01.26-md.png 768w\"></figure>\n<p>Note that in the displacement process, ink is pushed outside the ink-dropping region.</p>\n<p><em>Drop 50 randomly coloured drops with random radii in a defined interval, in random positions in a disk:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.02.20.png\" alt=\"\" width=\"594\" height=\"389\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.02.20-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.02.20-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.02.20-md.png 768w\"></figure>\n<h4>Layered designs</h4>\n<p>We can create layered designs by partitioning an ordered list of drops such as one generated by <em>dripDrops</em> into groups, and plotting the groups in different colours:</p>\n<p><em>Make a layered design by dropping ink, and interpreting a partition of the result as different colour layers:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.08.06.png\" alt=\"\" width=\"442\" height=\"392\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.06-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.06-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.06-md.png 768w\"></figure>\n<p><em>We can design a setup to generate a layered marbling automatically given a list of the numbers of drops in each layer: </em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.08.37.png\" alt=\"\" width=\"465\" height=\"500\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.37-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.37-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.37-md.png 768w\"></figure>\n<h4>Other ink drop shapes</h4>\n<p>By specifying a different ink drop function to <em>dripDrops</em> with the \"InkDropFunction\" Option, you can use arbitrary geometry as ink drops:</p>\n<p><em>Define a function to generate n-gons:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.09.25.png\" alt=\"\" width=\"536\" height=\"94\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.25-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.25-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.25-md.png 768w\"></figure>\n<p><em>Use it as the ink drop function in a dripDrops call:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.09.51.png\" alt=\"\" width=\"488\" height=\"353\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.51-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.51-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.51-md.png 768w\"></figure>\n<p>Note that while changing ink drop shapes results in different designs, the method by which points are displaced stays constant.</p>\n<h4>Filling arbitrary shapes or text with ink drops</h4>\n<p><span class=\"cc1\" data-native-text=\"true\">We might naively try to fill a shape by uniformly sampling points from the inside of the shape and dripping at these points. Unfortunately, this tends to be unsuccessful because ink drops push each other outside of the sampled region. One approach to mitigate this effect is to start with equally spaced points in the region, for example using the process described in </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://mathematica.stackexchange.com/a/141215/87521\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc4\" data-native-text=\"true\">this StackExchange answer by user kirma</span></a><span class=\"cc1\" data-native-text=\"true\"> for Monte Carlo estimation of Voronoi cell centroids.</span></p>\n<p><em>Make an ink drop text marbling from roughly evenly spaced points in a text region:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.10.57.png\" alt=\"\" width=\"658\" height=\"454\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.10.57-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.10.57-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.10.57-md.png 768w\"></figure>\n<p><em>Here's an ink drop marbling from roughly evenly spaced sampled points in France:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.11.36.png\" alt=\"\" width=\"1146\" height=\"1140\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.11.36-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.11.36-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.11.36-md.png 768w\"></figure>\n<p>As you can see, there's still some bleeding outside of the regions of interest, but much less than there would be without sampling approximately equally spaced points from the target regions.</p>\n<h4>Other interesting examples</h4>\n<p><em>Displace arbitrary background geometry:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.12.33.png\" alt=\"\" width=\"621\" height=\"446\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.33-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.33-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.33-md.png 768w\"></figure>\n<p><em>Make multiple full rotations along a circle, dropping ink in regular intervals:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.12.55.png\" alt=\"\" width=\"587\" height=\"239\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.55-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.55-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.55-md.png 768w\"></figure>\n<p>Try these methods yourself. Play around with with different shapes and combine different techniques. </p>\n<h2>Pin, Comb, and Other Tine Lines</h2>\n<p>Marbling techniques often involve dragging pointed objects such as needles, pencils, or combs through ink. Displacements created this way are called tine lines.<br><br>In the following sections, I’ll implement methods to trace straight infinite tine lines, and tine circles.</p>\n<h3>Tracing Infinite Lines Through the Ink</h3>\n<p>Given <em>L</em>, a tine line with arbitrary slope, the vector mapping for a point <em>P</em> is:</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.15.41.png\" alt=\"\" width=\"168\" height=\"50\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.15.41-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.15.41-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.15.41-md.png 768w\"></figure>\n<p>Where <em>d</em> is the minimum distance from the point <em>P</em> to the tine line, |<em>(P-B)•N</em>|, <em>N</em> is a unit vector perpendicular to the tine line <em>L</em>, <em>B</em> is a point on the tine line, and <em>M</em> is a unit vector along the tine line. The parameter <em>z</em> controls the maximum displacement of the tine line, and <em>c</em> controls the maximum sharpness of the bends as ink is dragged along the tine line in a laminar flow.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.17.33.png\" alt=\"\" width=\"226\" height=\"205\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.17.33-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.17.33-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.17.33-md.png 768w\"></figure>\n<p><em>(Illustration courtesy of Aubrey Jaffer)</em></p>\n<p><span class=\"cc1\" data-native-text=\"true\">Please refer to Aubrey Jaffer’s website for a </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://people.csail.mit.edu/jaffer/Marbling/Mathematics\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc4\" data-native-text=\"true\">more in-depth explanation</span></a><span class=\"cc1\" data-native-text=\"true\">.</span></p>\n<h3><em>Implementation: </em>tineLine and combLine</h3>\n<p>To download the original code, please consult the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3258063\">here</a>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.36.47.png\" alt=\"\" width=\"572\" height=\"566\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.36.47-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.36.47-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.36.47-md.png 768w\"></figure>\n<h3>Examples: tineLine and combLine</h3>\n<h4>Distort polygons with a single tine line using tineLine</h4>\n<p>The <em>tineLine</em> function distorts a polygon along an infinite tine line defined by a point <em>b</em> and unit vector <em>m</em>, alongside the tine parameters <em>z</em> and <em>c</em>. The function takes the following arguments:</p>\n<ol>\n<li>A polygon to distort.</li>\n<li>An arbitrary point on the desired tine line.</li>\n<li>A unit vector in the direction of the tine line.</li>\n<li>The displacement magnitude parameter <em>z</em>.</li>\n<li>The bend sharpness parameter <em>c</em>.</li>\n</ol>\n<p><em>Drag a tine line through a single ink drop:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.27.01.png\" alt=\"\" width=\"580\" height=\"128\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.01-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.01-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.01-md.png 768w\"></figure>\n<p><em>Drag a tine line through 10 stacked drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.27.21.png\" alt=\"\" width=\"538\" height=\"158\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.21-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.21-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.21-md.png 768w\"></figure>\n<h4>Distort polygons with an arbitrary number of tine lines using combLine</h4>\n<p>The <em>combLine</em> function extends <em>tineLine</em>'s functionality to allow dragging multiple tines across polygons with a single function call. It takes the following arguments: </p>\n<ol>\n<li>A list of polygons, or empty list representing the canvas, or marbling tank. </li>\n<li>A list of arbitrary points on the desired tine lines.</li>\n<li>A list of unit vectors defining the line directions, or a single unit vector.</li>\n<li>A list of <em>z</em> parameters, or a single <em>z</em> parameter value. </li>\n<li>A list of <em>c</em> parameters, or a single <em>c</em> parameter value.</li>\n</ol>\n<p>The function returns the transformed geometry after applying the specified tine transformations. </p>\n<p><em>Make computational latte art by pulling a tine in a line through a stack of ink drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.29.28.png\" alt=\"\" width=\"591\" height=\"417\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.28-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.28-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.28-md.png 768w\"></figure>\n<p><em>Comb through a stack of ink drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.29.50.png\" alt=\"\" width=\"600\" height=\"451\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.50-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.50-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.50-md.png 768w\"></figure>\n<p><em>Trace a sequence of parallel tine lines in alternating directions across a stack of ink </em><em>drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.30.16.png\" alt=\"\" width=\"632\" height=\"475\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.16-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.16-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.16-md.png 768w\"></figure>\n<p><em>Draw tine lines counterclockwise around a point at the centre of a stack of ink drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.30.46.png\" alt=\"\" width=\"595\" height=\"432\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.46-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.46-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.46-md.png 768w\"></figure>\n<p><em>Draw tine lines along the edges of regular polygons, counterclockwise over a stack of drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.31.09.png\" alt=\"\" width=\"586\" height=\"335\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.09-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.09-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.09-md.png 768w\"></figure>\n<p>We can also use combLine to draw curved tines. The easiest approach to do this is to cheat somewhat first applying a nonlinear transformation to the canvas geometry, then applying tine lines, and finally reversing the initial nonlinear transformation. For example, we can use this technique to trace sinusoidal tine lines.</p>\n<p><em>Sinusoidal tine lines:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.31.44.png\" alt=\"\" width=\"588\" height=\"384\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.44-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.44-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.44-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.31.59.png\" alt=\"\" width=\"373\" height=\"412\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.59-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.59-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.59-md.png 768w\"></figure>\n<h3>Tracing Circles Lines Through the Ink</h3>\n<p>We can also marble by displacing ink along a circle of centre <em>C</em> and radius <em>r</em>. In this case, we can define the mapping from a point <em>P</em> as:</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.33.18.png\" alt=\"\" width=\"294\" height=\"57\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.18-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.18-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.18-md.png 768w\"></figure>\n<p>Where <em>a</em> is the angle of the displacement arc,</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.33.57.png\" alt=\"\" width=\"74\" height=\"44\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.57-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.57-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.57-md.png 768w\"></figure>\n<p><em>l</em> is the length of the displacement arc, <em>l=z•u^d</em>, and <em>d</em> is the distance from <em>P</em> to the closest point on the circle, <em>d=|(||P-C||-r)|</em>.</p>\n<p>Just as is the case for tine lines, the parameters <em>z</em> and <em>c</em> control the maximum displacement of the tine, and the maximum sharpness of the bends along the tine circle, respectively.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.34.58.png\" alt=\"\" width=\"227\" height=\"228\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.34.58-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.34.58-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.34.58-md.png 768w\"></figure>\n<p><em>(Illustration courtesy of Aubrey Jaffer)</em></p>\n<p><span class=\"cc1\" data-native-text=\"true\">Please read Aubrey Jaffer’s website for a </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://people.csail.mit.edu/jaffer/Marbling/Mathematics\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc4\" data-native-text=\"true\">more in-depth explanation</span></a><span class=\"cc1\" data-native-text=\"true\">.</span></p>\n<h3><em>Implementation:</em> tineCircle and combCircle</h3>\n<p>To download the original code, please consult the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3258063\">here</a>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.37.17.png\" alt=\"\" width=\"599\" height=\"584\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.37.17-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.37.17-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.37.17-md.png 768w\"></figure>\n<h3>Examples</h3>\n<h4>Distort polygons with a single tine line using tineCircle</h4>\n<p>The <em>tineCircle</em> function distorts a polygon along a tine circle defined by the central point <em>b</em> and radius <em>r</em>, alongside the tine parameters <em>z</em> and <em>c</em>. The function takes the following arguments:</p>\n<ol>\n<li>A polygon to distort.</li>\n<li>The centre of the desired tine circle.</li>\n<li>The radius of the desired tine circle.</li>\n<li>The displacement magnitude parameter <em>z</em>.</li>\n<li>The bend sharpness parameter <em>c</em>.</li>\n</ol>\n<p><em>Drag a tine circle through a single ink drop:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.38.43.png\" alt=\"\" width=\"570\" height=\"130\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.38.43-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.38.43-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.38.43-md.png 768w\"></figure>\n<p><em>Drag a tine circle through 10 stacked drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.39.01.png\" alt=\"\" width=\"594\" height=\"175\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.39.01-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.39.01-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.39.01-md.png 768w\"></figure>\n<h4>Distort polygons with an arbitrary number of tine circles using combCircle</h4>\n<p>The <em>combCircle</em> function extends <em>tineCircle</em>'s functionality to allow dragging multiple tines in circles through polygons with a single function call. It takes the following arguments: </p>\n<ol>\n<li>A list of polygons, or empty list representing the canvas, or marbling tank. </li>\n<li>A list of centre points of the desired tine circles.</li>\n<li>A list of radii of the desired tine circles, or a single radius value for all specified tine circles.</li>\n<li>A list of<em> z</em> parameters, or a single <em>z</em> parameter value. </li>\n<li>A list of <em>c</em> parameters, or a single <em>c</em> parameter value.</li>\n</ol>\n<p>The function returns the transformed geometry after applying the specified tine circle transformations. </p>\n<p><em>Trace a tine circle through a stack of drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.41.55.png\" alt=\"\" width=\"465\" height=\"400\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.41.55-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.41.55-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.41.55-md.png 768w\"></figure>\n<p><em>Comb tine circles through a stack of drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.42.15.png\" alt=\"\" width=\"562\" height=\"363\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.15-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.15-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.15-md.png 768w\"></figure>\n<p><em>Trace tine circles in alternating directions through a stack of drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.42.39.png\" alt=\"\" width=\"615\" height=\"424\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.39-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.39-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.39-md.png 768w\"></figure>\n<p>Using Module, it's easy to build up scenes by layering ink dripping and tine transformations.</p>\n<p><em>Concentric tine circles in alternating direction through a grid of ink drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.43.06.png\" alt=\"\" width=\"572\" height=\"662\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.06-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.06-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.06-md.png 768w\"></figure>\n<p><em>Trace tine circles centred on equally spaced points around a circle, alternating clockwise and counterclockwise directions through a stack of ink drops:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.43.31.png\" alt=\"\" width=\"600\" height=\"457\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.31-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.31-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.31-md.png 768w\"></figure>\n<p><em>Trace tine circles through a stack of ink drops in alternating directions along the arms of a spiral:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.43.53.png\" alt=\"\" width=\"603\" height=\"444\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.53-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.53-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.53-md.png 768w\"></figure>\n<h2>Sampling Evenly Distanced Points on Polygon Boundaries for Custom Canvas Design Geometry</h2>\n<p>To achieve good results with manually prepared canvas geometry it's good to define polygons using roughly evenly separated points along their boundaries. High-detail polygons defined by a large number of evenly spaced points also deform more fluidly and naturally than low detail or varying detail polygons. To ensure polygons are optimally defined for marbling design it helps to be able to sample evenly spaced points from the boundaries of polygons. We can define a helper function for this.</p>\n<p><em>Sample n equally spaced points on the boundary of a polygon:</em></p>\n<ul>\n<li>Based on Henrik Schumacher's answer on the Mathematica &amp; Wolfram Language StackExchange: <a href=\"https://mathematica.stackexchange.com/a/180931/87521\">https://mathematica.stackexchange.com/a/180931/87521</a></li>\n</ul>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.44.55.png\" alt=\"\" width=\"1300\" height=\"548\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.44.55-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.44.55-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.44.55-md.png 768w\"></figure>\n<p><em>Example: Take a high-detail evenly spaced point sample from a low-detail star polygon:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.45.12.png\" alt=\"\" width=\"522\" height=\"259\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.12-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.12-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.12-md.png 768w\"></figure>\n<p>Let's use this function to generate a striped background as the basis for the next marbling design:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.45.36.png\" alt=\"\" width=\"1290\" height=\"146\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.36-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.36-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.36-md.png 768w\"></figure>\n<p><em>Preview the striped background design:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.45.52.png\" alt=\"\" width=\"370\" height=\"237\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.52-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.52-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.52-md.png 768w\"></figure>\n<h2>Simulating Real Marbling Design Techniques</h2>\n<p>By combining the functions discussed in previous sections, we can generate an infinite variety of marbling patterns, and easily experiment with marbling ideas. We can also reproduce pattern-making techniques used in physical marbling designs.</p>\n<h3>Peacock Feathers</h3>\n<p><span class=\"cc1\" data-native-text=\"true\">The following pattern, sometimes called the </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://marbleart.us/Peacock-Bouquet.htm#:~:text=The%20real%20name%20for%20this,the%20comb%20and%20the%20rake.\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc4\" data-native-text=\"true\">peacock, bouquet</span></a><span class=\"cc1\" data-native-text=\"true\">, or scallop shells, is often found in end-paper designs:</span></p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/bouquet-2.png\" alt=\"\" width=\"354\" height=\"442\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/bouquet-2-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/bouquet-2-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/bouquet-2-md.png 768w\"></figure>\n<p class=\"align-center\"><em>Marbled endpaper from Die Nachfolge Christi ed. Ludwig Donin (Vienna ca. 1875) - Wikimedia Commons</em></p>\n<p><span class=\"cc1\" data-native-text=\"true\">Following </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://people.csail.mit.edu/jaffer/Marbling/Scallops\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc4\" data-native-text=\"true\">instructions from Aubrey Jaffer's website</span></a><span class=\"cc1\" data-native-text=\"true\">, we can reproduce this design by combining geometric sine transformations and tine combing, starting with the striped canvas defined previously. The result is very regular, and might benefit from additional displacement from 2D noise for a more natural effect, or from the addition of noise to the tine.</span></p>\n<p><em>Create a perfect scallop array marbling:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.48.20.png\" alt=\"\" width=\"589\" height=\"441\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.20-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.20-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.20-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.48.35.png\" alt=\"\" width=\"584\" height=\"519\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.35-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.35-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.35-md.png 768w\"></figure>\n<h3>Combinations of Dripping and Combing</h3>\n<p>By alternating dripping and combing sequences, we can produce designs resembling ebru marbling. For example, by dripping, combing up and down, then dripping again with different colours:</p>\n<p><em>Create a computational ebru marbling:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.49.23.png\" alt=\"\" width=\"596\" height=\"560\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.23-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.23-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.23-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.49.43.png\" alt=\"\" width=\"544\" height=\"533\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.43-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.43-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.43-md.png 768w\"></figure>\n<h2>The Marble-Tron: An Interactive Marbling Canvas</h2>\n<p>Download <a href=\"https://community.wolfram.com/groups/-/m/t/3258063\">this notebook</a> and make your own marbling designs with the interactive canvas below. </p>\n<h4>Usage:</h4>\n<ul>\n<li>To add a drop of ink to the canvas, click the \"Ink\" radio button, choose your drop settings using the <em>Drop scale</em> slider.</li>\n<li>By default, the colour selection is random for each ink drop. Click the \"Manual\" radio button to show manual colour selection tools.</li>\n<li>To trace a tine line through the ink, click the \"Tine\" radio button, choose your tine settings using the <em>Tine z</em> and <em>Tine c</em> sliders, then click and drag the mouse along the screen. An arrow will follow your mouse pointer, giving you a preview of the tine settings. Release the mouse to apply the tine line to the canvas.</li>\n</ul>\n<p><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">Screen capture of the interactive marbling canvas interface:</span></p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.24.33.png\" alt=\"\" width=\"485\" height=\"658\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.24.33-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.24.33-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.24.33-md.png 768w\"></figure>\n</div>\n<div class=\"cell-content\">\n<h2>Conclusion</h2>\n<p>This exploration into mathematical marbling showcases the power and flexibility of Wolfram Language for generative art exploration, process design, and process implementation. By combining mathematical transformations, we can simulate traditional marbling techniques digitally, opening up endless possibilities for experimentation and creativity.</p>\n<p>One advantage of the vector graphics marbling methods explored in this text is that a marbling process will always output a list of polygons, making it easy to pick and modify colour schemes without having to recompute the marbling from scratch. These polygons can also be magnified and exported without loss of detail for prints, or further manually or programmatically manipulated. </p>\n<p>I encourage you to try out these techniques and create your own marbling designs! Happy marbling! </p>\n<h2>Acknowledgements and Sources Cited</h2>\n<h3>Special Thank You to Aubrey Jaffer</h3>\n<p>This article would not exist without Aubrey Jaffer's mathematical marbling articles, his kind support, and advice at the 2024 Wolfram Summer School. Aubrey's work provided the foundation for this exploration, and his guidance has been invaluable. Thank you, Aubrey, for your dedication to the art and science of marbling, and for inspiring us to delve deeper into this fascinating subject, and thank you again for presenting your work at the 2024 Wolfram Summer School.</p>\n<h3>Sources Cited</h3>\n<div id=\"cell-9bddc041-7da9-af48-a5be-2e27d70ab293\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div class=\"native-layout native-layout-simple\"><a href=\"https://commons.wikimedia.org/wiki/File:Battal_Ebru.jpg\"><span class=\"cc1\" data-native-text=\"true\">Akcire.14. (2020). Battal Ebru.</span></a></div>\n</div>\n</div>\n</div>\n<div id=\"cell-3b10e018-ef9a-2041-8cd4-5d10d278c7d3\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><a href=\"https://commons.wikimedia.org/wiki/File:Marbled_endpaper_from_Die_Nachfolge_Christi_ed._Ludwig_Donin_(Vienna_ca._1875)_1000ppi_(cropped).png\"><span class=\"cc1\" data-native-text=\"true\">Aristeas, C. (1875). English: Marbled endpaper from a copy of Die Nachfolge Christi in vier Büchern von Thomas von Kempis.</span></a></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-b5342346-ec7c-cf43-a463-21b2248273ce\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><a href=\"https://people.csail.mit.edu/jaffer/Marbling/Mathematics\"><span class=\"cc1\" data-native-text=\"true\">Jaffer, A. (n.d.). The Mathematics of Marbling. Retrieved 26 August 2024</span></a></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-080ad89a-93f5-f04d-ac94-d936423e66e2\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><a href=\"https://doi.org/10.1109/MCG.2011.51\"><span class=\"cc1\" data-native-text=\"true\">Shufang Lu, Jaffer, A., Xiaogang Jin, Hanli Zhao, &amp; Xiaoyang Mao. (2012). Mathematical Marbling. IEEE Computer Graphics and Applications, 32(6), 26–35.</span></a></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-f91b2dd1-29c9-ac49-b8c9-92f290dfeb43\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><a href=\"https://www.skillshare.com/es/blog/suminagashi-aprende-el-arte-del-marmoleado-de-papel-japones/\"><span class=\"cc1\" data-native-text=\"true\">Turner, E. (2022, April 13). Suminagashi: Aprende el arte del marmoleado de papel japonés. Skillshare Blog.</span></a></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>",
            "image": "https://phileasdg.github.io/media/posts/41/Mathematical-Marbling-Banner.png",
            "author": {
                "name": "Phileas Dazeley-Gaist"
            },
            "tags": [
                   "Work at Wolfram",
                   "Wolfram Language",
                   "Programming",
                   "Modelling",
                   "Mathematica",
                   "Art"
            ],
            "date_published": "2024-10-24T21:15:01+02:00",
            "date_modified": "2025-08-11T00:12:22+02:00"
        },
        {
            "id": "https://phileasdg.github.io/earths-hottest-day-ever-recorded-july-22-2024-analyzed-and-visualised-through-climate-data/",
            "url": "https://phileasdg.github.io/earths-hottest-day-ever-recorded-july-22-2024-analyzed-and-visualised-through-climate-data/",
            "title": "Earth&#x27;s Hottest Day Ever Recorded - July 22, 2024 - Analysed and Visualised Through Climate Data",
            "summary": "July 22, 2024 was the hottest day in recorded history, according to&hellip;",
            "content_html": "<p>July 22, 2024 was the hottest day in recorded history, according to provisional data from the European climate service.</p>\n<p class=\"msg msg--info\"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forums. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3234937\">here</a>. </p>\n<h2>Introduction</h2>\n<p>On July 24 2024, <a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://apnews.com/article/hottest-day-ever-climate-change-weather-heat-extreme-global-warming-8e2b0b7fa0360ecb931ca333a832c694\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\" style=\"font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"><span class=\"cc9\" data-native-text=\"true\">the Associated Press reported that July 22, 2024 broke the record for the hottest day ever recorded on earth</span></a><span class=\"cc7\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">, according to provisional data from the European climate service, Copernicus.</span></p>\n<div id=\"cell-1755bd5b-dc13-3440-bbb3-c2a8c2f106dd\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><span class=\"cc7\" data-native-text=\"true\">In the article, Sibi Arasu and Seth Borenstein report that “Monday was 0.06 degrees Celsius (0.1 degree Fahrenheit) hotter than Sunday, which was .01 degrees Celsius hotter (0.2 degrees Fahrenheit) than the previous hottest day on record, July 6, 2023.”</span></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-48e7de22-8d3e-244e-a6a3-142436e30a7d\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><span class=\"cc7\" data-native-text=\"true\">The data they cite are from the </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc9\" data-native-text=\"true\">ECMWF Reanalysis v5 (ERA5) dataset</span></a><span class=\"cc7\" data-native-text=\"true\">, which provides hourly spatial estimates of many of atmospheric, land and oceanic climate variables, including surface air temperature and sea surface temperature, daily, from 1940 to the present day.</span></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-8862fa9c-62ac-2b4b-b299-cb9d9452881e\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div class=\"native-layout native-layout-simple\"><span class=\"cc7\" data-native-text=\"true\">While Copernicus provides free access to these data, the size of raw dataset files (which are large gridded data layer stacks stored in NetCDF format) makes many ad hoc analyses prohibitively expensive. However, and fortunately, Copernicus and the University of Maine’s Climate Change Institute both provide trackers for the average global temperature based on ERA5 data. These are:</span></div>\n<div id=\"cell-c05329c8-883f-a443-8d6b-fc38e8ce5332\" class=\"cell\">\n<ul>\n<li class=\"cell-wrapper\"><span class=\"cc7\" data-native-text=\"true\">Copernicus’ Climate Pulse: </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://pulse.climate.copernicus.eu/\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc9\" data-native-text=\"true\">https://pulse.climate.copernicus.eu/</span></a><span class=\"cc7\" data-native-text=\"true\"> (near real time, typically 2 days behind)</span></li>\n<li class=\"native-layout native-layout-simple\"><span class=\"cc7\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">The University of Maine’s Climate Reanalyzer: </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://climatereanalyzer.org/clim/t2_daily/?dm_id=world\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\" style=\"font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"><span class=\"cc9\" data-native-text=\"true\">https://climatereanalyzer.org/clim/t2_daily/?dm_id=world</span></a><span class=\"cc7\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> (a few more days delay)</span></li>\n</ul>\n</div>\n<div id=\"cell-6a3b29c0-a328-8948-934c-6fce8fd3047b\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div class=\"native-layout native-layout-simple\"><span class=\"cc7\" data-native-text=\"true\">How easy would it be to import and study these data in the Wolfram Language? Let’s find out.</span></div>\n<h2>Getting Global Mean Surface Temperature Data</h2>\n<h3>Importing and Preprocessing Data from Climate Pulse:</h3>\n<p><span class=\"cc7\" data-native-text=\"true\">Climate Pulse conveniently provides a </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://sites.ecmwf.int/data/climatepulse/data/series/era5_daily_series_2t_global.csv\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc9\" data-native-text=\"true\">link</span></a><span class=\"cc7\" data-native-text=\"true\"> to download a table of global surface air temperature data from 1940 to the latest data available. Let’s import these data:</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.20.10.png\" alt=\"\" width=\"2014\" height=\"180\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.10-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.10-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.10-md.png 768w\"></figure>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.20.43.png\" alt=\"\" width=\"371\" height=\"190\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.43-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.43-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.43-md.png 768w\"></figure>\n<p>Neat! The columns key (dropped from the .csv table during the import) defines the columns as: </p>\n<p><code># Columns:</code><br><br><code>#  2t: Daily mean absolute temperature based on hourly values from 00 to 23 UTC</code><br><code>#  clim_91-20: Daily climatology for 1991-2020</code><br><code>#  ano_91-20: Daily anomaly relative to the 1991-2020 daily climatology</code><br><code>#  status: Preliminary or final</code><br><br><code># Units: deg. C</code><br><code># Last updated: 25 Jul 2024</code></p>\n<p>To construct time series from these data, it'll help to convert the values from the date column into Wolfram Language date objects:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.21.51.png\" alt=\"\" width=\"2204\" height=\"76\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.21.51-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.21.51-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.21.51-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.22.06.png\" alt=\"\" width=\"371\" height=\"186\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.06-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.06-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.06-md.png 768w\"></figure>\n<h3>Constructing and Plotting Time Series from the Data:</h3>\n<p>Now that we have the data, we can get a time series of daily mean absolute temperatures like so:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.22.57.png\" alt=\"\" width=\"1490\" height=\"62\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.57-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.57-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.57-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.23.35.png\" alt=\"\" width=\"352\" height=\"66\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.23.35-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.23.35-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.23.35-md.png 768w\"></figure>\n<p>Plotting it is as easy as: </p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.24.05.png\" alt=\"\" width=\"548\" height=\"96\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.05-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.05-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.05-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.24.32.png\" alt=\"\" width=\"1458\" height=\"982\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.32-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.32-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.32-md.png 768w\"></figure>\n<h3>Verifying the Claims Made by the AP &amp; Others:</h3>\n<p>Based on these data, was the hottest day on record really last Monday? Let's confirm:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.25.02.png\" alt=\"\" width=\"270\" height=\"29\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.02-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.02-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.02-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.25.15.png\" alt=\"\" width=\"371\" height=\"67\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.15-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.15-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.15-md.png 768w\"></figure>\n<p>What were the top 5 hottest recorded days since 1940?</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.25.45.png\" alt=\"\" width=\"276\" height=\"26\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.45-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.45-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.45-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.26.05.png\" alt=\"\" width=\"373\" height=\"155\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.05-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.05-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.05-md.png 768w\"></figure>\n<p>Note that the top four hottest days on record were this month.</p>\n<h2>Reproducing the Famous Global Mean Surface Temperature Multi-Year Overlay Plot</h2>\n<p>With the data we have collected, we can now reproduce the now famous year over year plot of global mean surface temperatures from Climate Pulse.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.26.54.png\" alt=\"\" width=\"2610\" height=\"1398\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.54-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.54-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.54-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.27.20.png\" alt=\"\" width=\"1266\" height=\"1586\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.27.20-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.27.20-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.27.20-md.png 768w\"></figure>\n<h2>Getting These Data for Specific Time Ranges and Regions from Climate Reanalyzer</h2>\n<p>It would be helpful to have a function that automates the process of importing these data for different available regions and time ranges. <br>This task is quite straightforward using data from Climate Reanalyzer.</p>\n<p><em>Define a function to import time series from Climate Reanalyzer:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.28.05.png\" alt=\"\" width=\"1978\" height=\"424\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.28.05-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.28.05-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.28.05-md.png 768w\"></figure>\n<p>The function supports importing data from six regions, specified with the area parameter: </p>\n<ul>\n<li>\"World\" ---&gt; The whole world, 90°S-90°N, 0-360°E</li>\n<li>\"NH\" ---&gt; The northern hemisphere, 0-90°N, 0-360°E</li>\n<li>\"SH\" ---&gt; The southern hemisphere, 0-90°S, 0-360°E</li>\n<li>\"Arctic\" ---&gt; 66.5-90°N, 0-360°E</li>\n<li>\"Antarctic\" ---&gt; 66.5-90°S, 0-360°E</li>\n<li>\"Tropics\" ---&gt; 23.5°S-23.5°N, 0-360°E</li>\n</ul>\n<p>And takes an optional second argument specifying the start and end date for the requested data range in a list (from January 1st 1940 to seven days ago).</p>\n<p>Consider the following examples:</p>\n<p><em>Request and plot the time series of daily surface temperatures in the Arctic from 1990 to 2000:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.29.31.png\" alt=\"\" width=\"530\" height=\"126\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.29.31-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.29.31-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.29.31-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.31.09.png\" alt=\"\" width=\"1180\" height=\"786\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.09-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.09-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.09-md.png 768w\"></figure>\n<h2>Map Animations:</h2>\n<p>Climate Pulse hosts recent raster maps of global surface temperatures. Here is the one corresponding to last Monday:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.31.40.png\" alt=\"\" width=\"1348\" height=\"784\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.40-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.40-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.40-md.png 768w\"></figure>\n<p>I'd like to take a moment to highlight my RemoteSensing paclet, which presently provides a WL interface to NASA's GIBS and AppEEARS APIs for remote sensing data retrieval. While my paclet does not yet support access to Copernicus ERA5 data (look out for future releases), GIBS and AppEEARS both provide access to similar data products, which we can import and work with directly in the Wolfram Language.</p>\n<p>Please feel free to consult the paclet documentation here: <a href=\"https://resources.wolframcloud.com/PacletRepository/resources/PhileasDazeleyGaist/RemoteSensing/\">https://resources.wolframcloud.com/PacletRepository/resources/PhileasDazeleyGaist/RemoteSensing/</a></p>\n<p><em>To install the paclet, run the following code: </em></p>\n<p><em><code>PacletInstall[\"PhileasDazeleyGaist/RemoteSensing\"]</code></em></p>\n<p><em>Load the paclet: </em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.32.55.png\" alt=\"\" width=\"347\" height=\"29\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.32.55-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.32.55-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.32.55-md.png 768w\"></figure>\n<p><em>Using GIBSData, list global surface air temperature products:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.33.17.png\" alt=\"\" width=\"1520\" height=\"44\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.17-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.17-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.17-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.33.30.png\" alt=\"\" width=\"2434\" height=\"96\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.30-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.30-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.30-md.png 768w\"></figure>\n<p><em>Animate a map using one of these products:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.37.14.png\" alt=\"\" width=\"1732\" height=\"212\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.37.14-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.37.14-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.37.14-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/37/Animation2.gif\" alt=\"\" width=\"1114\" height=\"484\"></figure>\n<h2>Conclusion</h2>\n<p>In this article, we've explored how one can readily access and analyse global climate data using the Wolfram Language. We've shown how one can pull daily global mean surface air temperature data from specific geographical ranges and plot the data over time, as well as how to import recent raster maps of global surface temperatures from Copernicus' Climate Pulse. We've also highlighted the RemoteSensing paclet, a powerful tool that can interface with NASA's GIBS and AppEEARS APIs for convenient remote sensing data retrieval. </p>\n<p>With these functionalities, researchers in climate science and related fields are better equipped to analyse and interpret vast amounts of climate data right from within the Wolfram Language.</p>\n<p> </p>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>",
            "image": "https://phileasdg.github.io/media/posts/37/Hottest-day-on-earth-Social-Media-2.png",
            "author": {
                "name": "Phileas Dazeley-Gaist"
            },
            "tags": [
                   "Work at Wolfram",
                   "Wolfram Language",
                   "Mathematica",
                   "GIS",
                   "Environmental Science"
            ],
            "date_published": "2024-07-28T09:17:34+02:00",
            "date_modified": "2025-08-11T00:11:35+02:00"
        },
        {
            "id": "https://phileasdg.github.io/a-forest-fire-model-in-1-2-and-3-dimensions/",
            "url": "https://phileasdg.github.io/a-forest-fire-model-in-1-2-and-3-dimensions/",
            "title": "A Forest Fire Model in 1, 2, and 3 Dimensions",
            "summary": "Note: This post was originally a short technical article I shared on&hellip;",
            "content_html": "<p class=\"msg msg--info\"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forums. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3096615?p_p_auth=jA2YdLGR\">here</a>. </p>\n<h2>Introduction</h2>\n<p>The forest fire model is one of the simplest computational models to display self-organised criticality. The model is a probabilistic cellular automaton with the following rules. At each computation/time step:</p>\n<div id=\"cell-c6d531d9-bde4-e940-8566-2ff3288d6302\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"cell-content\">\n<ul>\n<li class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\">Trees on fire burn down, leaving wasteland.</span></li>\n<li>Trees catch fire if they are adjacent to at least one tree already on fire.</li>\n<li>Tree cells catch fire independently with probability <em>P(f)</em></li>\n<li>Trees grow in wasteland cells with probability <em>P(t)</em></li>\n</ul>\n<p>We'll use the following values for the possible cell states:</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.32.53.png\" alt=\"\" width=\"397\" height=\"165\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.32.53-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.32.53-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.32.53-md.png 768w\"></figure>\n<p>Here is a visualisation of the fire-spreading process in two-dimensions, with <em>P(t)</em> and <em>P(f)</em> set to 0:</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.35.46.png\" alt=\"\" width=\"619\" height=\"119\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.35.46-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.35.46-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.35.46-md.png 768w\"></figure>\n<p>In the implementation that follows, the <code>forestFireStep</code> function computes simulation steps. <em>P(f)</em> is specified using the option <code>\"NewFireProb\"</code>, and <em>P(t)</em> with <code>\"NewTreeProb\"</code>. I have introduced the two additional (optional) terms <code>\"MaxNewFires\"</code> and <code>\"MaxNewTrees\"</code>, allowing the user to specify the maximum numbers of new fires and trees per step in addition to the probabilities of spontaneous ignition and new tree growth. This allows for more intuitive and varied system setups.</p>\n<h2>Implementation: Forest Fire Functions</h2>\n<p><em>Retrieve the positions of trees, actively burning fires, and wasteland:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.37.56.png\" alt=\"\" width=\"259\" height=\"104\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.37.56-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.37.56-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.37.56-md.png 768w\"></figure>\n<p><em>Retrieve the positions of trees adjacent to actively burning fires in the landscape:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.38.21.png\" alt=\"\" width=\"673\" height=\"115\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.21-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.21-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.21-md.png 768w\"></figure>\n<p><em>Compute a forest fire simulation step:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.38.46.png\" alt=\"\" width=\"1772\" height=\"802\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.46-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.46-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.46-md.png 768w\"></figure>\n<h2>Performing Forest Fire Simulations</h2>\n<p>Given an array defining the initial state of a landscape, the forestFireStep function returns the state of the landscape at the following time step. We'll see in a moment that it is flexible enough to be used to perform simulations in one, two, and three dimensions.</p>\n<h3>Forest Fires on 2D Arrays</h3>\n<p><em>Generate some forests:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.39.30.png\" alt=\"\" width=\"549\" height=\"165\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.30-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.30-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.30-md.png 768w\"></figure>\n<p><em>Compute a single step of a forest fire simulation on a 2D array:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.39.54.png\" alt=\"\" width=\"553\" height=\"286\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.54-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.54-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.54-md.png 768w\"></figure>\n<p>You can specify the probabilities that tree cell spontaneously will catch fire, or that a wasteland cell will grow a tree with the <code>\"NewFireProb\"</code> and <code>\"NewTreeProb\"</code> options. Likewise, you can specify the maximum number of new fires or trees per step by specifying the options <code>\"MaxNewFires\"</code> and <code>\"MaxNewTrees\"</code>.</p>\n<p><em>Compute and animate 200 steps of a forest fire trajectory in a light forest with gaps and clearings:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-11.44.00.png\" alt=\"\" width=\"385\" height=\"165\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.44.00-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.44.00-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.44.00-md.png 768w\"></figure>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/ForestFireAnim1.gif\" alt=\"\" width=\"530\" height=\"404\"></figure>\n<p><span class=\"cc3\" data-native-text=\"true\">By default, </span><code><span class=\"cc6\" data-native-text=\"true\">“MaxNewFires”</span></code><span class=\"cc3\" data-native-text=\"true\"> and </span><code><span class=\"cc6\" data-native-text=\"true\">“MaxNewTrees”</span></code><span class=\"cc3\" data-native-text=\"true\"> are set to </span><code><span class=\"cc4\" data-native-text=\"true\">∞</span></code><span class=\"cc3\" data-native-text=\"true\">. When this is the case, the occurrence of new fires or trees is determined entirely by the <span class=\"cc6\" data-native-text=\"true\"><code>“NewFireProb”</code></span></span> <span class=\"cc3\" data-native-text=\"true\">and </span><code><span class=\"cc6\" data-native-text=\"true\">“NewTreeProb”</span></code><span class=\"cc3\" data-native-text=\"true\"> options.</span></p>\n<p><em>Compute and animate 200 steps of a forest fire trajectory on a partitioned landscape:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-11.46.43.png\" alt=\"\" width=\"370\" height=\"121\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.46.43-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.46.43-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.46.43-md.png 768w\"></figure>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/ForestFireAnim2.gif\" alt=\"\" width=\"529\" height=\"402\"></figure>\n<p><em>Compute and animate 200 steps of a forest fire trajectory exhibiting self-organised criticality:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-11.50.24.png\" alt=\"\" width=\"390\" height=\"221\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.50.24-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.50.24-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.50.24-md.png 768w\"></figure>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/ForestFireAnim3.gif\" alt=\"\" width=\"529\" height=\"403\"></figure>\n<p><em>Produce time-series and phase space plots for the trajectory above:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-20-at-13.17.34.png\" alt=\"\" width=\"1402\" height=\"976\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-20-at-13.17.34-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-20-at-13.17.34-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-20-at-13.17.34-md.png 768w\"></figure>\n<h3>One-Dimensional Forest Fires</h3>\n<p>We can apply the forest fire rules to one dimensional arrays as we would apply them in two dimensions. Rather than spreading to adjacent cells in two spatial dimensions, then, fires only spread along one.</p>\n<div id=\"cell-3e894a24-cbce-354d-8f40-865531a2b60e\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\">Following the convention for 1-dimensional cellular automata, we stack the arrays for subsequent time steps vertically and in sequence. In the resulting graphic, space is represented horizontally and time flows vertically from top to bottom.</span></div>\n<div>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-11.54.01.png\" alt=\"\" width=\"530\" height=\"292\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.54.01-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.54.01-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.54.01-md.png 768w\"></figure>\n<p>See some one dimensional trajectories in the animation below, or head to <a href=\"https://community.wolfram.com/groups/-/m/t/3096615\">the original post </a>to see an interactive example:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-12.07.29.png\" alt=\"\" width=\"609\" height=\"208\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-12.07.29-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-12.07.29-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-12.07.29-md.png 768w\"></figure>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/ForestFireAnim4-2.gif\" alt=\"\" width=\"434\" height=\"499\"></figure>\n<h3>Forest Fires in 3D</h3>\n<p>In three dimensions, we can also define forested landscapes with more complicated topographies, for example, by layering different cell types. </p>\n<p>The following example is of a forested layer on top of a layer of soil. Both layers vary in thickness (check out <a href=\"https://community.wolfram.com/groups/-/m/t/3096615\">the original post</a> for the interactive version).</p>\n<p><em>Three-dimensional forest fire model trajectories through a dense hilly forest.</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-13.16.57.png\" alt=\"\" width=\"1378\" height=\"616\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.16.57-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.16.57-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.16.57-md.png 768w\"></figure>\n<p>Depending on the forest initial configuration, it can be difficult to visualise all cell states at once. This is the case for forest fire trajectories through dense volumes of trees, for example:</p>\n<p><em>Three-dimensional forest fire model trajectories through a cubic forest:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-13.17.50.png\" alt=\"\" width=\"1378\" height=\"852\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.17.50-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.17.50-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.17.50-md.png 768w\"></figure>\n<h3>Closing Note</h3>\n<p>I hope you found these examples interesting and entertaining! The implementation discussed in this short text should in principle work for higher than 3-dimensional arrays but I have not tested it for such cases. If you do, please make sure to share your results in the comment section under this post. In fact, please feel free to share any interesting behaviours you find or modifications you make in the comments! I look forward to hearing your ideas and suggestions! </p>\n<h3>Sources</h3>\n<ul>\n<li><a href=\"https://en.wikipedia.org/w/index.php?title=Forest-fire_model&amp;oldid=\\%201170972820\">'Forest-Fire Model'. In Wikipedia, 18 August 2023.</a></li>\n<li><a href=\"https://mathematica.stackexchange.com/questions/39793/can-you-apply-the-cellular-automata-function-to-a-grid-containing-numbers/39863#39863\">E, C. 'Answer to \"Can You Apply the Cellular Automata Function to a Grid Containing Numbers?\"' Mathematica Stack Exchange, 5 January 2014.</a></li>\n<li><a href=\"https://www.sciencedirect.com/science/article/abs/pii/037596019090451S?via%3Dihub\">Bak, Per, Kan Chen, and Chao Tang. 'A Forest-Fire Model and Some Thoughts on Turbulence'. Physics Letters A 147, no. 5 (16 July 1990): 297\\[Dash]300.</a></li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>",
            "image": "https://phileasdg.github.io/media/posts/36/Animation1.gif",
            "author": {
                "name": "Phileas Dazeley-Gaist"
            },
            "tags": [
                   "Work at Wolfram",
                   "Programming",
                   "Modelling",
                   "Mathematica",
                   "Environmental Science",
                   "Ecology",
                   "Art"
            ],
            "date_published": "2024-05-03T23:38:15+02:00",
            "date_modified": "2025-08-11T00:12:07+02:00"
        },
        {
            "id": "https://phileasdg.github.io/a-dynamical-model-of-immune-system-response-to-mrna-live-virus-and-inactivated-vaccines-2/",
            "url": "https://phileasdg.github.io/a-dynamical-model-of-immune-system-response-to-mrna-live-virus-and-inactivated-vaccines-2/",
            "title": "A Dynamical Model of Immune-System Response to mRNA, Live Virus, and Inactivated Vaccines",
            "summary": "Note: This post was originally a short technical article I shared on&hellip;",
            "content_html": "<p class=\"msg msg--info\"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forums. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3055726\">here</a>. </p>\n<p class=\"msg msg--highlight \"><span class=\"cc1\" data-native-text=\"true\"><strong>Source article:</strong> Zhaobin Xu, Jian Song, Hongmei Zhang, Zhenlin Wei, Dongqing Wei, Jacques Demongeot, A Mathematical Model Simulating the Adaptive Immune Response in Various Vaccines and Vaccination Strategies, medRxiv 2023.10.05.23296578. DOI: </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://doi.org/10.1101/2023.10.05.23296578\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc3\" data-native-text=\"true\">https://doi.org/10.1101/2023.10.05.23296578</span></a></p>\n<h2>Introduction:</h2>\n<p><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">The accomplishments of vaccination are numerous, leading to significant advances in human health. Yet new infectious diseases and evolving pathogens constantly challenge our understanding of vaccine efficacy and immunity. Mathematical modelling is a crucial lens through which we can reach a more comprehensive understanding of these complexities. By simulating the biological responses to vaccines, models can provide critical insights into disease progression, vaccine performance, and optimal strategies for developing vaccines.</span></p>\n<div id=\"cell-fe47751b-0fbc-4ad3-bab0-ee4f1dd22fb8\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><span class=\"cc6\" data-native-text=\"true\">In this short text, we’ll explore an approach to constructing one such model in the Wolfram Language. We will reproduce a compartmental dynamical model of adaptive immune responses to vaccine treatments described in a recent preprint from medRxiv.org: </span><span class=\"cc14\" data-native-text=\"true\">A Mathematical Model Simulating the Adaptive Immune Response in Various Vaccines and Vaccination Strategies</span> <a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://www.medrxiv.org/content/10.1101/2023.10.05.23296578v1\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc9\" data-native-text=\"true\">(Xu et al. 2023)</span></a><span class=\"cc6\" data-native-text=\"true\">. Compartmental models are a class of mathematical models which divide variables of interest into sections or “compartments”. Each compartment represents a specific state within the system being studied. The models track how entities, like cells or molecules, interact within and between these compartments over time.</span></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-95dd72c5-3543-4f12-a9d7-8486a64fa8f9\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div class=\"native-layout native-layout-simple\"><span class=\"cc6\" data-native-text=\"true\">The stated goal of the paper is to construct a novel mathematical model to quantitatively research the activation of adaptive immune responses by vaccines. This model is used to simulate and compare the dynamics of antibody levels after administering different types of vaccines (inactivated, attenuated live virus, mRNA), thereby contributing to a better understanding of the mechanisms of various vaccines and vaccination strategies. Through the model, the authors aim to suggest strategies for vaccine design, while providing a comprehensive portrait of the inducible interactions between antibodies and antigens in the immune process.</span></div>\n<h2>Setup</h2>\n<h3>Dependencies</h3>\n<p><span class=\"cc6\" data-native-text=\"true\">We will make use of the </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://resources.wolframcloud.com/PacletRepository/resources/RobertNachbar/CompartmentalModeling/\" target=\"_blank\" data-testid=\"ButtonBoxView\" id=\"aui_3_4_0_1_433\" rel=\"noopener\"><span class=\"cc9\" data-native-text=\"true\">CompartmentalModelling</span></a><span class=\"cc6\" data-native-text=\"true\"> paclet. You can install and load the paclet like so:</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-09.49.26.png\" alt=\"\" width=\"560\" height=\"178\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-09.49.26-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-09.49.26-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-09.49.26-md.png 768w\"></figure>\n<p><span class=\"cc6\" data-native-text=\"true\">You can find documentation for this paclet by following </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://resources.wolframcloud.com/PacletRepository/resources/RobertNachbar/CompartmentalModeling/\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc9\" data-native-text=\"true\">this link</span></a><span class=\"cc6\" data-native-text=\"true\">.</span></p>\n<h3>Paper Tables</h3>\n<p>You can find the definitions for the tables of reactions, reaction variables, and reaction parameters in the original version of this post on <a href=\"https://community.wolfram.com/groups/-/m/t/3055726\">Wolfram Community</a>.</p>\n<h2>Reactions, Parameters, and State Variables of the Model</h2>\n<p>The authors of the paper helpfully provide three tables fully specifying the interactions between state variables (components) of the system, as well as model parameters and initial conditions. I have reproduced these tables below. Note that some parameter values and initial conditions depend on the selected vaccine treatment type. More precisely:</p>\n</div>\n<ul>\n<li>The replication rate of viral antigens, described by parameter k_14 should be set to .3 in the case of a simulation of an attenuated live virus vaccine, and 0 otherwise.</li>\n<li>The initial condition of the state variable x_2 (Antigen) should be set to 10^6 for simulation with an inactivated vaccine, 0 with an mRNA vaccine, and 1 for an attenuated live virus vaccine.</li>\n<li>The initial condition of the state variable x_9 <span class=\"cc6\" data-native-text=\"true\"> (mRNA) should be set to 0 for simulation with an inactivated or attenuated live virus vaccine, and 10^6</span><span class=\"cc6\" data-native-text=\"true\"> for and mRNA vaccine.</span></li>\n</ul>\n<p><span class=\"cc6\" data-native-text=\"true\">For a more in depth explanation of these parameters and initial conditions, please refer to </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://www.medrxiv.org/content/10.1101/2023.10.05.23296578v1\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc9\" data-native-text=\"true\">the paper</span></a><span class=\"cc6\" data-native-text=\"true\">.</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.05.51.png\" alt=\"\" width=\"1266\" height=\"1226\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.05.51-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.05.51-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.05.51-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.06.39.png\" alt=\"\" width=\"1330\" height=\"1144\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.39-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.39-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.39-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.06.54.png\" alt=\"\" width=\"1330\" height=\"578\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.54-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.54-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.54-md.png 768w\"></figure>\n<h2>Extracting Model Information</h2>\n<p><span class=\"cc6\" data-native-text=\"true\">We can use tools from the </span><strong><span class=\"cc39\" data-native-text=\"true\">CompartmentalModelling</span></strong><span class=\"cc6\" data-native-text=\"true\"> paclet to extract useful information about the model. For instance, we can use </span><strong><span class=\"cc39\" data-native-text=\"true\">CompartmentalModelGraph</span></strong><span class=\"cc6\" data-native-text=\"true\"> from the CompartmentalModelling paclet to visualise the model’s structure:</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.10.06.png\" alt=\"\" width=\"1682\" height=\"840\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.10.06-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.10.06-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.10.06-md.png 768w\"></figure>\n<p><span class=\"cc6\" data-native-text=\"true\">The </span><span class=\"cc39\" data-native-text=\"true\">CompartmentalModelling</span><span class=\"cc6\" data-native-text=\"true\"> paclet contains convenient functions to streamline the process of building models. For instance, we can use </span><strong><span class=\"cc39\" data-native-text=\"true\">KineticCompartmentalModel</span></strong><span class=\"cc6\" data-native-text=\"true\"> to generate differential equations for from a list of component transitions (the reactions).</span></p>\n<p><em>Fetch the model data:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.16.18.png\" alt=\"\" width=\"476\" height=\"929\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.16.18-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.16.18-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.16.18-md.png 768w\"></figure>\n<p>These data are very useful for quickly building and simulating compartmental models.</p>\n<h2>Numerical Simulations</h2>\n<h3>Preparing Model ODEs</h3>\n<p><span class=\"cc8\" data-native-text=\"true\">Owing to details related to the original code implementation of the model, the authors provide a slightly modified system of ODEs describing the model. This system is reproduced below and numerically approximated using </span><span class=\"cc42\" data-native-text=\"true\">NDSolve</span><span class=\"cc8\" data-native-text=\"true\"> for different vaccine treatments:</span></p>\n<p><em>Reproduce the ODEs from the paper:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.17.43.png\" alt=\"\" width=\"1308\" height=\"484\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.17.43-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.17.43-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.17.43-md.png 768w\"></figure>\n<p>Let’s also get some replacement rules to easily convert between the variable names in plain English, and the symbols used in the paper for the model’s system of ODEs.</p>\n<p><em>Plain English variables &lt;--&gt; ODE variables:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.18.28.png\" alt=\"\" width=\"588\" height=\"57\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.18.28-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.18.28-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.18.28-md.png 768w\"></figure>\n<h3>Vaccine Treatment Simulations</h3>\n<p>In the paper, the authors model three cases:</p>\n<ol>\n<li>Inactivated Vaccine Simulation</li>\n<li>Attenuated Live Virus Vaccine</li>\n<li>mRNA Vaccine</li>\n</ol>\n<p><span class=\"cc8\" data-native-text=\"true\">These cases are solved numerically in the three following sections. The inactivated vaccine and mRNA vaccines each take two injections, one at one at </span></p>\n<div>\n<div class=\"lines\"><span class=\"pa ch cc17\" data-token-box-id=\"c2832\" data-token-text=\"t\">t</span><span class=\"pa char cc10\" data-token-box-id=\"c2833\" data-token-text=\"=\">=</span><span class=\"pa ch cc8\" data-token-box-id=\"c2834\" data-token-text=\"0\">0</span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">, the other at </span><span class=\"pa ch cc17\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2841\" data-token-text=\"t\">t</span><span class=\"pa char cc10\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2842\" data-token-text=\"=\">=</span><span class=\"pa ch cc8\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2843\" data-token-text=\"50\">50</span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">. The attenuated live-virus vaccine takes a single dose at </span><span class=\"pa ch cc17\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2850\" data-token-text=\"t\">t</span><span class=\"pa char cc10\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2851\" data-token-text=\"=\">=</span><span class=\"pa ch cc8\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2852\" data-token-text=\"0\">0</span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">. The injection dosage is of </span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">6^</span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">10</span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"> for all simulations.</span></div>\n<h3>1. Inactivated Vaccine Simulation</h3>\n<p>Model-specific parameters and initial conditions:</p>\n<ul>\n<li><span class=\"cc8\" data-native-text=\"true\">Replication rate of viral antigens: </span>k_<span class=\"pa char cc19\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2605\" data-token-text=\"14\">14</span><span class=\"pa char cc10\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2607\" data-token-text=\"=\">=</span><span class=\"pa ch cc8\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2608\" data-token-text=\"0\">0</span></li>\n<li><span class=\"cc8\" data-native-text=\"true\">Antigen = </span>x_<span class=\"pa char cc19\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2627\" data-token-text=\"2\">2</span><span class=\"pa char cc10\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2629\" data-token-text=\"[\">[</span><span class=\"pa ch cc8\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2630\" data-token-text=\"0\">0</span><span class=\"pa char cc10\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2631\" data-token-text=\"]\">]</span><span class=\"cc8\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> = </span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">10^6</span></li>\n<li><span class=\"cc8\" data-native-text=\"true\">mRNA = </span>x_9[<span class=\"pa ch cc8\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2664\" data-token-text=\"0\">0</span><span class=\"pa char cc10\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2665\" data-token-text=\"]\">]</span><span class=\"cc8\" data-native-text=\"true\"> = 0</span></li>\n</ul>\n<p><em>Define model parameters corresponding to the inactivated vaccine setup:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.21.55.png\" alt=\"\" width=\"1484\" height=\"186\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.21.55-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.21.55-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.21.55-md.png 768w\"></figure>\n<p><em>Define initial conditions of the system corresponding to the inactivated vaccine setup:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.22.21.png\" alt=\"\" width=\"1414\" height=\"632\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.21-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.21-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.21-md.png 768w\"></figure>\n<p><em>Construct the system of equations for NDSolve, with parameter values and initial conditions:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.22.40.png\" alt=\"\" width=\"599\" height=\"29\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.40-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.40-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.40-md.png 768w\"></figure>\n<p><em><span class=\"cc25\" data-native-text=\"true\">Solve numerically with NDSolve, from </span></em><span class=\"pa ch cc47\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2737\" data-token-text=\"t\">t</span><span class=\"pa char cc27\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2738\" data-token-text=\"=\">=</span><span class=\"pa ch cc25\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2739\" data-token-text=\"0\">0</span><em><span class=\"cc25\" data-native-text=\"true\"> to </span></em><span class=\"pa ch cc47\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2746\" data-token-text=\"t\">t</span><span class=\"pa char cc27\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2747\" data-token-text=\"=\">=</span><span class=\"pa ch cc25\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2748\" data-token-text=\"100\">100</span><em><span class=\"cc25\" data-native-text=\"true\">:</span></em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.23.23.png\" alt=\"\" width=\"485\" height=\"29\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.23-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.23-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.23-md.png 768w\"></figure>\n<p><em>Plot the solution:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.23.50.png\" alt=\"\" width=\"1448\" height=\"642\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.50-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.50-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.50-md.png 768w\"></figure>\n<h3>2. Attenuated Live Virus Vaccine</h3>\n<p>Model-specific parameters and initial conditions:</p>\n<ul>\n<li><span class=\"cc8\" data-native-text=\"true\">Replication rate of viral antigens: </span>k_<span class=\"pa char cc19\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2605\" data-token-text=\"14\">14</span><span class=\"pa char cc10\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2607\" data-token-text=\"=\">=</span><span class=\"pa ch cc8\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2608\" data-token-text=\"0\">0.3</span></li>\n<li><span class=\"cc8\" data-native-text=\"true\">Antigen = </span>x_<span class=\"pa char cc19\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2627\" data-token-text=\"2\">2</span><span class=\"pa char cc10\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2629\" data-token-text=\"[\">[</span><span class=\"pa ch cc8\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2630\" data-token-text=\"0\">0</span><span class=\"pa char cc10\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2631\" data-token-text=\"]\">]</span><span class=\"cc8\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> = 1</span></li>\n<li><span class=\"cc8\" data-native-text=\"true\">mRNA = </span>x_9[<span class=\"pa ch cc8\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2664\" data-token-text=\"0\">0</span><span class=\"pa char cc10\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2665\" data-token-text=\"]\">]</span><span class=\"cc8\" data-native-text=\"true\"> = 0</span></li>\n</ul>\n<p><em>Define model parameters corresponding to the inactivated vaccine setup:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.25.32.png\" alt=\"\" width=\"1484\" height=\"194\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.32-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.32-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.32-md.png 768w\"></figure>\n<p><em>Define initial conditions of the system corresponding to the inactivated vaccine setup:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.25.49.png\" alt=\"\" width=\"1402\" height=\"638\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.49-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.49-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.49-md.png 768w\"></figure>\n<p><em>Construct the system of equations for NDSolve, with parameter values and initial conditions:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.26.00.png\" alt=\"\" width=\"378\" height=\"35\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.00-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.00-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.00-md.png 768w\"></figure>\n<p><em><span class=\"cc25\" data-native-text=\"true\">Solve numerically with NDSolve, from </span></em><span class=\"pa ch cc47\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2737\" data-token-text=\"t\">t</span><span class=\"pa char cc27\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2738\" data-token-text=\"=\">=</span><span class=\"pa ch cc25\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2739\" data-token-text=\"0\">0</span><em><span class=\"cc25\" data-native-text=\"true\"> to </span></em><span class=\"pa ch cc47\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2746\" data-token-text=\"t\">t</span><span class=\"pa char cc27\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2747\" data-token-text=\"=\">=</span><span class=\"pa ch cc25\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-token-box-id=\"c2748\" data-token-text=\"100\">100</span><em><span class=\"cc25\" data-native-text=\"true\">:</span></em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.26.19.png\" alt=\"\" width=\"494\" height=\"38\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.19-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.19-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.19-md.png 768w\"></figure>\n<p><em>Plot the solution:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.26.44.png\" alt=\"\" width=\"1478\" height=\"646\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.44-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.44-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.44-md.png 768w\"></figure>\n<h3>3. mRNA Vaccine</h3>\n<p>Model-specific parameters and initial conditions:<br><br>Replication rate of viral antigens: k_14=0<br>Antigen = x_2[0] = 0<br>mRNA = x_9[0] = 10^6</p>\n<p><em>Define model parameters corresponding to the inactivated vaccine setup:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.30.46.png\" alt=\"\" width=\"1492\" height=\"206\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.30.46-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.30.46-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.30.46-md.png 768w\"></figure>\n<p><em>Define initial conditions of the system corresponding to the inactivated vaccine setup:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.31.19.png\" alt=\"\" width=\"1398\" height=\"646\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.19-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.19-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.19-md.png 768w\"></figure>\n<p><em>Construct the system of equations for NDSolve, with parameter values and initial conditions:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.31.32.png\" alt=\"\" width=\"649\" height=\"37\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.32-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.32-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.32-md.png 768w\"></figure>\n<p><em>Solve numerically with NDSolve, from t=0 to t=100:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.31.48.png\" alt=\"\" width=\"519\" height=\"37\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.48-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.48-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.48-md.png 768w\"></figure>\n<p><em>Plot the solution:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.32.06.png\" alt=\"\" width=\"1460\" height=\"646\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.32.06-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.32.06-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.32.06-md.png 768w\"></figure>\n<h2>Closing Notes</h2>\n<div id=\"cell-54b896b0-0f0b-4cac-9367-cb44dc59b1b4\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"cell-content\">\n<div>\n<div> </div>\n<div class=\"native-layout native-layout-simple\"><span class=\"cc8\" data-native-text=\"true\">Through the exploration of this dynamical immune response model, we have seen how mathematical modelling in the Wolfram Language, can be used to derive insights into complex biological systems.</span></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-952802b4-cfde-45ea-bf61-c9cfcec97f25\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><span class=\"cc8\" data-native-text=\"true\">If you are interested in this work, and would like to learn more, please make sure to give the </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://www.medrxiv.org/content/10.1101/2023.10.05.23296578v1\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc11\" data-native-text=\"true\">source paper </span></a><span class=\"cc8\" data-native-text=\"true\">a read! I primarily intend this post to demonstrate how one might conduct this form of modelling in the Wolfram Language. I also highly encourage you to try Bob Nachbar’s </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://resources.wolframcloud.com/PacletRepository/resources/RobertNachbar/CompartmentalModeling/\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc61\" data-native-text=\"true\">CompartmentalModelling</span></a><span class=\"cc8\" data-native-text=\"true\"> paclet. The </span><span class=\"cc42\" data-native-text=\"true\">CompartmentalModelling</span><span class=\"cc8\" data-native-text=\"true\"> paclet is not just for biologists, but could be a valuable tool for anyone dealing with interconnected systems that can be represented as compartments. </span></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>",
            "image": "https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.14.00.png",
            "author": {
                "name": "Phileas Dazeley-Gaist"
            },
            "tags": [
                   "Work at Wolfram",
                   "Wolfram Language",
                   "Programming",
                   "Network Science",
                   "Modelling",
                   "Mathematica"
            ],
            "date_published": "2024-05-02T15:44:47+02:00",
            "date_modified": "2025-10-10T17:45:38+02:00"
        },
        {
            "id": "https://phileasdg.github.io/lotka-volterra-models-in-the-wolfram-language/",
            "url": "https://phileasdg.github.io/lotka-volterra-models-in-the-wolfram-language/",
            "title": "Lotka-Volterra Models in the Wolfram Language",
            "summary": "Note: This post was originally a short technical article I shared on&hellip;",
            "content_html": "<p class=\"msg msg--info\"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forums. For an interactive experience with live demonstrations or to download this text and source source code as a Wolfram Notebook, please visit the original post <a href=\"https://community.wolfram.com/groups/-/m/t/3028599\">here</a>. For brevity and readability, I've omitted several code implementation sections which were present in the original article. If you're looking to reproduce a function from this article and need the source code, please head to the original post.</p>\n<h2>Introduction: A review of the Lotka-Volterra Model</h2>\n<h3>Overview</h3>\n<div id=\"cell-c3a94280-e8a4-4954-ac9d-109d26687d61\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\">The Lotka-Volterra model, proposed in the early 20th century by mathematicians Alfred J. Lotka (1880-1949) and Vito Volterra (1860-1940), is an influential framework widely used to explore population dynamics of closed ecological systems.</span></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-6a2d1478-3121-4d98-924f-9325cd35f2f4\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\"><span class=\"cc3\" data-native-text=\"true\">In general, the Lotka-Volterra model refers to the classic two-species construction by Lotka and Volterra, in which the respective instantaneous rates of population change of a predator and prey species are tied to the other species’ population size. In the two </span></span><span class=\"cc3\" data-native-text=\"true\">species case, the Lotka-Volterra model usually results in periodic population “boom and bust” cycles in which the predator population closely follows but lags behind the prey’s (Bacaër 2011).</span></div>\n</div>\n</div>\n</div>\n<div id=\"cell-45ba991c-2672-48ea-bd83-7c376c0fba06\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\">Lotka proposed the classic formulation of the model in 1910 as a model of autocatalytic chemical reactions (Lotka 1910). In 1920, he applied the model to a two species food chain involving an idealised plant species and grazing predator (Lotka 1920). In 1925, Volterra independently began studying predator-prey interactions and published a short discussion of the subject in 1926 (Bacaër 2011). While Volterra’s work on the subject focused strictly on modelling predator-prey interactions in fisheries (Volterra 1927), Lotka took a broader interest in exploring competitive interactions and studying the “energetics of evolution” (Lotka 1922). He argued that natural selection could be understood as a physical principle as general as the laws of thermodynamics (Kingsland 2015).</span></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-c2b48c5c-b6f1-4b04-be5c-3dedc320f043\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\">Lotka’s work is noteworthy beyond its contributions to the fields of theoretical population ecology, physical chemistry, and dynamical systems (non-exhaustive) for its interdisciplinarity. He envisioned and worked to create a new biological discipline, “physical biology”, which would apply physical principles and techniques to the study of biological systems composed of processes involving the exchange of matter or energy between system components (Kingsland, 2015). Lotka collected and published these ideas in </span><span class=\"cc14\" data-native-text=\"true\">Elements of Physical Biology </span><span class=\"cc3\" data-native-text=\"true\">(1925).</span></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-64e966f6-bdd6-4625-88b1-c3c0e5efbd49\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\">Lotka-Volterra models serve as critical conceptual tools for ecologists, lending remarkable insights into real-world ecological system dynamics. Its simplicity makes it an excellent choice to demonstrate key ideas about predator-prey interactions, including the influential concept of the prey-predator cycle, whereby prey abundance increases followed by a delayed increase in predators. Its principles have been refined and extended by many subsequent researchers and continue to hold relevance. The primary contribution of the Lotka-Volterra model to the field of ecology is the theoretical underpinning it provides for understanding interspecies interactions, (mainly predation and competition). This fundamental understanding has guided the development of more complex models for describing the dynamics of entire ecosystems.</span></div>\n<h3>How does it work?</h3>\n<div id=\"cell-f023857b-392c-44a9-ae6e-9bdbaf3b962e\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"cell-content\">\n<div>\n<div class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\">Consider two species, one which preys on the other (for example, the Canada lynx and snowshoe hare). Let </span><em><span class=\"cc14\" data-native-text=\"true\">x(t)</span></em><span class=\"cc3\" data-native-text=\"true\"> be the population density of the prey, and </span><em><span class=\"cc14\" data-native-text=\"true\">y(t)</span></em><span class=\"cc3\" data-native-text=\"true\"> be the population density of the predators at time </span><em><span class=\"cc14\" data-native-text=\"true\">t</span></em><span class=\"cc3\" data-native-text=\"true\">. To capture how the populations of each species will vary over time, we need two kinds of information:</span></div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-5239e989-3a09-491c-8b0c-4b1648af9769\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<ol>\n<li class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">The growth rates of the species population in the absence of the other species.</span></li>\n<li class=\"_3Dqn7hOe5vVS6Nh0S54gcV\">The effect of the presence of the other species on each species’ growth.</li>\n</ol>\n</div>\n</div>\n<div id=\"cell-bb246bdb-f5b8-461b-8235-c004afe4bf3f\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\">In the classic formulation by Alfred J. Lotka, (1920), these parameters are </span><span class=\"cc14\" data-native-text=\"true\"><em>a</em>, <em>b</em>, <em>c</em>,</span><span class=\"cc3\" data-native-text=\"true\"> and </span><em><span class=\"cc14\" data-native-text=\"true\">d</span></em><span class=\"cc3\" data-native-text=\"true\">, where:</span></div>\n</div>\n</div>\n</div>\n<div id=\"cell-a3ba13e8-e138-432e-ac6f-e82c06d31edb\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"HExNUSO6Shz5hgqMOEW9X\">\n<div class=\"cell-dingbat\">\n<ul>\n<li class=\"lines\"><em><span class=\"cc14\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">a</span></em><span class=\"cc3\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> is the intrinsic growth rate of the prey species</span></li>\n<li class=\"lines\"><em>b</em><span class=\"cc3\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> is the effect of the predators on the prey species growth rate; the rate at which predators kill prey</span></li>\n<li><em><span class=\"cc14\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">c</span></em><span class=\"cc3\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> is the death rate of the predator species when there are no prey</span></li>\n<li><em>d</em><span class=\"cc3\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> is the effect of the prey on the predator species growth rate; the rate at which the predator population grows from consuming prey</span></li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div id=\"cell-66e601fc-fea5-4394-9542-5575b3f4df4c\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\"> </div>\n<div class=\"cell-content\">\n<div class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\">Using these parameters, we can write the coupled system of ordinary differential equations:</span></div>\n</div>\n</div>\n</div>\n<div id=\"cell-4a78be8d-14d9-414a-be6b-8d0cff42114c\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"_3Dqn7hOe5vVS6Nh0S54gcV\">\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.03.23.png\" alt=\"\" width=\"198\" height=\"127\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.03.23-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.03.23-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.03.23-md.png 768w\"></figure>\n</div>\n<div> </div>\n</div>\n</div>\n<div id=\"cell-e07d02be-46c2-4e1e-b152-dc7aa7f24459\" class=\"cell\">\n<div class=\"cell-wrapper\">\n<div class=\"cell-content\">\n<div class=\"native-layout native-layout-simple\"><span class=\"cc3\" data-native-text=\"true\">We assume that each of these parameters is positive. The terms </span><em><span class=\"cc14\" data-native-text=\"true\">-b x y</span></em><span class=\"cc3\" data-native-text=\"true\"> and </span><em><span class=\"cc14\" data-native-text=\"true\">d x y</span></em><span class=\"cc3\" data-native-text=\"true\"> indicate that the larger prey and predator species are, the higher the mass/population/energy transfer from prey to predators will be.<br></span></div>\n<h3><em>Implementation: </em>In the Wolfram Language</h3>\n<p class=\"Text\">Setting up a Lotka-Volterra model in the Wolfram Language is very straightforward using <code><span class=\"InputInline\"><a href=\"http://reference.wolfram.com/mathematica/ref/NDSolve.html \"><span class=\"LinkInline\">NDSolve</span></a></span></code>, WL’s numerical differential equations solver.</p>\n<ul>\n<li class=\"ItemNumbered\">Since we know the model takes two initial conditions (species population sizes) and four parameters (<em>a</em>, <em>b</em>, <em>c</em>, <em>d</em>), we can write a helper function that takes in this information and returns the appropriate coupled equations:</li>\n</ul>\n<p class=\"CodeText\"><em>Set up the ODEs and initial conditions describing a two-species Lotka-Volterra model:</em></p>\n<figure class=\"post__image align-left\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.14.07.png\" alt=\"\" width=\"415\" height=\"264\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.14.07-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.14.07-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.14.07-md.png 768w\"></figure>\n<p><em>Example:</em></p>\n<figure class=\"post__image align-left\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.14.36.png\" alt=\"\" width=\"323\" height=\"116\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.14.36-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.14.36-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.14.36-md.png 768w\"></figure>\n<ul>\n<li class=\"ItemNumbered\">Now, we can simply call our helper function inside <span class=\"InputInline\"><span class=\"InputFormInline\">NDSolve</span></span>, specifying our initial conditions and parameters. Additionally, we supply a list of variables to solve for, and another containing the name and range of the independent variable, <em>t</em>.</li>\n</ul>\n<figure class=\"post__image align-left\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2023-10-10-at-14.28.14.png\" alt=\"\" width=\"1388\" height=\"198\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2023-10-10-at-14.28.14-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2023-10-10-at-14.28.14-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2023-10-10-at-14.28.14-md.png 768w\"></figure>\n<ul>\n<li>Finally, we can plot these results in the time domain and state space:</li>\n</ul>\n<p class=\"align-left\"><em>Time domain plot:</em></p>\n<figure class=\"post__image align-left\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.09.18.png\" alt=\"\" width=\"461\" height=\"298\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.09.18-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.09.18-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.09.18-md.png 768w\"></figure>\n<p><em>State space portrait: (I have iconised the options to make the code more readable, please visit the original community post to view the full code)</em></p>\n<figure class=\"post__image align-left\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.12.40.png\" alt=\"\" width=\"1452\" height=\"1238\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.12.40-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.12.40-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.12.40-md.png 768w\"></figure>\n<h2>Relationships and Food Webs</h2>\n<h3>Predation Relationships and Food Webs</h3>\n<p class=\"Text\">Suppose we would like to extend our model to three or more species. For a given <em>n</em>-species system, will need too keep track of the <strong>relationships</strong> between species, and their <strong>effects</strong> on one another. We will discuss two ways of storing this information: one to facilitate our conceptual understanding of model configurations, and the other to facilitate the process of building the model system of ODEs. We will discuss the first of these ways here.</p>\n<p class=\"Text\">Notice that as the number of species n in our model grows, so does the number of possible relationships between species (at a rate of 2^<em>n</em>, or 2^(<em>n</em>-1) if we assume the absence of cannibalism in the community). The number of possible combinations of relationships also grows without bounds (at a rate of 2^(<em>n</em>^2), or 2^((<em>n</em>-1)^2)without cannibalism). A set of predation relationships between species is known as a food web.</p>\n<p class=\"Text\">In a food web, predation relationships are usually represented as arrows from prey to predator species, representing transfer of energy up the web’s component food chains.</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.15.55.png\" alt=\"\" width=\"234\" height=\"278\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.15.55-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.15.55-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.15.55-md.png 768w\"></figure>\n<p><span class=\"cc3\" data-native-text=\"true\">Since food webs are graphs, we can express them directly in the Wolfram Language using </span><span class=\"cc44\" data-native-text=\"true\">Graph</span><span class=\"cc3\" data-native-text=\"true\"> objects (see documentation: </span><code><a href=\"https://reference.wolfram.com/language/ref/Graph.html\"><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">Graph</span></a></code><span class=\"cc3\" data-native-text=\"true\">). Not all food web configurations will be ecologically meaningful, and some will be analogous to one-another, but expressing them like this helps to get a strong qualitative impression of the relationships they depict (Are we modelling a really simple web, or is it very complicated? How tangled is it? How loopy? How close together are the species? Do they form clusters? And so on). We can also answer questions about the food web parameter spaces. For instance: what structurally distinct categories of 3-species food web are there?</span></p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.17.56.png\" alt=\"\" width=\"481\" height=\"577\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.17.56-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.17.56-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.17.56-md.png 768w\"></figure>\n<h3>Aside: What species relationships are possible in an <em>n</em>-species system?</h3>\n<p>We can write a function to generate the possible predation configurations for a species in an n-species food web.</p>\n<p><em>Predation configurations for a species in an n-species food web:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.18.42.png\" alt=\"\" width=\"1568\" height=\"514\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.18.42-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.18.42-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.18.42-md.png 768w\"></figure>\n<p>In a 3-species food web, the predation relationship configurations for a species N1 are:</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-15.18.48.png\" alt=\"\" width=\"276\" height=\"414\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-15.18.48-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-15.18.48-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-15.18.48-md.png 768w\"></figure>\n<p>We can sample possible food web configurations randomly, but this will rarely yield realistic food webs for most contexts. Instead, we might restrict configurations to a subset of forms that fit our criteria, or we might simply look to real world systems for examples.</p>\n<p><em>Random valid 3-species food webs (with cannibalism):</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.19.19.png\" alt=\"\" width=\"1498\" height=\"282\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.19.19-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.19.19-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.19.19-md.png 768w\"></figure>\n<p><em>Random valid 3-species food webs (without cannibalism):</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.19.48.png\" alt=\"\" width=\"1526\" height=\"298\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.19.48-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.19.48-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.19.48-md.png 768w\"></figure>\n<h3>Species to Species Effects Representation: The Community Matrix</h3>\n<p>Whereas graphs are great at helping us intuit the nature of interactions in a community, we typically express interactions in n-species Lotka-Volterra models using a matrix of interaction coefficients called an <em>interaction matrix</em>. A perk of this strategy is that it allows us to write the generalised Lotka-Volterra model in a condensed form using linear algebra. We will discuss this condensed form shortly. When the matrix stores the effects of species on other species growth rates, we call this matrix a <em>community matrix</em>.</p>\n<p>Community matrices are a key concept in quantitative ecology and are used in many competition and predation models. A community matrix A is a square matrix where each element represents the interaction strength between pairs of species in an ecological community. Each cell <em>A[i,j]</em> represents the effect of the average species <em>j</em> individual on species <em>i</em>’s population growth rate (Novak et al. 2016). The principal diagonal of the matrix captures the species self-interactions, which we usually assume to be negative, to capture the effect of interspecific competition. This constrains species growth in the absence of prey, imposing implicit instantaneous carrying capacities of the system for different species.</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.21.29.png\" alt=\"\" width=\"354\" height=\"120\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.21.29-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.21.29-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.21.29-md.png 768w\"></figure>\n<p class=\"Text\">Note that values in an interaction matrix don’t necessarily correspond to predation relationships. If both <em>A[i,j]</em> and <em>A[j,i]</em> are negative, then the two species are considered to be in direct competition with one another as they negatively affect each other’s population. If <em>A[i,j]</em> is positive but <em>A[i,j]</em> is negative then species <em>i</em> is a predator or parasite of species <em>j</em>, since <em>i</em>’s population grows at <em>j</em>’s expense (Positive values for <em>A[i,j] </em>and <em>A[j,i] </em>would be considered mutualism, but we won’t go into that).</p>\n<p class=\"Text\">To translate between community matrices and food webs, I have implemented some simple tools which you can find definitions for in the original version of this post.</p>\n<h2>Generalised Lotka-Volterra: How Does it Work?</h2>\n<p>We can model competition and predation systems with more than two species using the generalised form of the Lotka-Volterra model, which we write: </p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.24.26.png\" alt=\"\" width=\"181\" height=\"94\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.24.26-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.24.26-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.24.26-md.png 768w\"></figure>\n<p>where</p>\n<ul>\n<li><em>X</em> is a vector of population sizes or densities.</li>\n<li>The vector <em>f</em> is given by <em>f</em>=<em>r</em>+<em>A</em><em>X</em>, where <em>r</em> is a vector of intrinsic growth rates, and <em>A </em>is the community matrix or interaction matrix of the system.</li>\n</ul>\n</div>\n<div> </div>\n<div class=\"cell-content\">We will define the intrinsic growth rates slightly differently from our approach for the two-species model, as we assume that each species has a positive intrinsic growth rate. We account for the negative effect of a species' intraspecific competition in the absence of food (on its intrinsic growth rates) in the diagonal of the community matrix.<br>\n<h2>Three Species Lotka-Volterra in the Wolfram Language</h2>\n<p>First, let's define a function to generate ODEs for an n-species Lotka-Volterra model:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-13.23.34.png\" alt=\"\" width=\"2102\" height=\"886\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.23.34-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.23.34-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-13.23.34-md.png 768w\"></figure>\n<p class=\"Text\">We can use <code><span class=\"InputInline\"><span class=\"InputFormInline\">GeneralizedLotkaVolterraODEs</span></span></code> to generate the system of ODEs for the given initial parameters:</p>\n<ul>\n<li class=\"Item\"><em>vars</em> - a list of variable names (optional),</li>\n<li class=\"Item\"><em>init</em> - a list of initial population sizes</li>\n<li class=\"Item\"><em>r</em> - a list of species intrinsic growth rates</li>\n<li class=\"Item\"><em>interactionMatrix</em> - a matrix describing community interactions (in our examples, a community matrix)</li>\n</ul>\n<p class=\"CodeText\"><em>Generate a system of ODEs for a Generalised Lotka-Volterra model from provided parameters:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-16.20.24.png\" alt=\"\" width=\"582\" height=\"310\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.20.24-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.20.24-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.20.24-md.png 768w\"></figure>\n<p>Using <code><span class=\"InputInline\"><span class=\"InputFormInline\">CommunityMatrixGraph</span></span></code> (see definition in original post), we can construct a weighted graph from the community matrix to get an idea of the relationships that define the system at a glance.</p>\n<p><em>Visualise the community interactions described by the community matrix:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-16.22.53.png\" alt=\"\" width=\"1278\" height=\"526\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.22.53-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.22.53-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.22.53-md.png 768w\"></figure>\n<p>And <code><span class=\"InputInline\"><span class=\"InputFormInline\">NDSolve</span></span></code> to numerically approximate the population trajectories of the model.</p>\n<p><em>Numerical solutions to the model ODEs:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-16.23.38.png\" alt=\"\" width=\"1774\" height=\"390\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.23.38-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.23.38-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.23.38-md.png 768w\"></figure>\n<p>We can then plot the solutions in the time domain and state space:</p>\n<p><em>Time domain plot:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-16.24.12.png\" alt=\"\" width=\"1564\" height=\"638\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.24.12-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.24.12-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.24.12-md.png 768w\"></figure>\n<p><em>State space portrait (now in 3D!):</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-16.24.34.png\" alt=\"\" width=\"472\" height=\"469\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.24.34-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.24.34-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.24.34-md.png 768w\"></figure>\n<h2>Closing Notes: Four species and more</h2>\n<p class=\"Text\">The generalised model we have discussed in this short text extends beyond three species systems. In fact, the tools we have developed will allow us to model any finite n-species closed-food web, that is, any system that we can express using a finite number of species initial population sizes, intrinsic growth rates, and interactions. It should be noted that just because we can specify a model does not always mean we can accurately solve for its behaviour: we are restricted by the limits of numerical approximation and our available computational power)</p>\n<p class=\"Text\">Still, we can easily model four species webs. Let’s prepare two four species models. We’ll define some weighted webs describing the various interaction effects of our system:</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-16.25.03.png\" alt=\"\" width=\"380\" height=\"318\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.25.03-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.25.03-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.25.03-md.png 768w\"></figure>\n<p>We can construct the community matrix describing either of these using the <code><span class=\"InputInline\"><span class=\"InputFormInline\">CommunityMatrix</span></span></code> function defined in the original version of this post. For example, take the first row of interaction webs from the above dataset:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2023-10-10-at-15.20.16.png\" alt=\"\" width=\"403\" height=\"136\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2023-10-10-at-15.20.16-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2023-10-10-at-15.20.16-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2023-10-10-at-15.20.16-md.png 768w\"></figure>\n<p><em>Time domain plot:</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-16.25.51.png\" alt=\"\" width=\"1932\" height=\"1216\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.25.51-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.25.51-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.25.51-md.png 768w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/32/Screenshot-2024-05-01-at-16.25.31.png\" alt=\"\" width=\"1892\" height=\"938\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.25.31-xs.png 300w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.25.31-sm.png 480w ,https://phileasdg.github.io/media/posts/32/responsive/Screenshot-2024-05-01-at-16.25.31-md.png 768w\"></figure>\n<p>To interact with this graphical user interface, head to the original version of this post.</p>\n<p class=\"Text\"><strong>Note:</strong> What happened to the state-space plot? Well, we’ve run out of spatial dimensions to express the behaviour of the system, and in the interest of keeping this post short, we’ll leave things there for now.</p>\n<p class=\"Text\">Consider what we have achieved in this short text. If you have read this far, I hope to have inspired you to think of how you might answer your own ecological questions in the Wolfram Language. If your questions expand on the subject of this post, I hope the tools I have developed within will help jumpstart your exploration! And please, don’t hesitate to reach out to me with any questions you may have about this work.</p>\n<h2 class=\"Section\">Sources Cited</h2>\n<p class=\"Item\">Allesina, Stefano. 2 Generalized Lotka-Volterra | A Tour of the Generalized Lotka-Volterra Model. Accessed 5 October 2023. <a href=\"https://stefanoallesina.github.io/Sao_Paulo_School/intro.html\"><span class=\"HyperlinkInline\">https://stefanoallesina.github.io/Sao_Paulo_School/intro.html</span></a>.</p>\n<p class=\"Item\">———. 2 Generalized Lotka-Volterra | A Tour of the Generalized Lotka-Volterra Model. Accessed 5 October 2023. <a href=\"https://stefanoallesina.github.io/Sao_Paulo_School/intro.html\"><span class=\"HyperlinkInline\">https://stefanoallesina.github.io/Sao_Paulo_School/intro.html</span></a>.</p>\n<p class=\"Item\">Bacaër, Nicolas. ‘Lotka, Volterra and the Predator–Prey System (1920–1926)’. In A Short History of Mathematical Population Dynamics, edited by Nicolas Bacaër, 71–76. London: Springer, 2011. <a href=\"https://doi.org/10.1007/978-0-85729-115-8_13\"><span class=\"HyperlinkInline\">https://doi.org/10.1007/978-0-85729-115-8_13</span></a>.</p>\n<p class=\"Item\">Baigent, Steve. ‘Lotka-Volterra Dynamics - An Introduction.’, 2010.</p>\n<p class=\"Item\">Hsu, Sze-Bi, Shigui Ruan, and Ting-Hui Yang. ‘Analysis of Three Species Lotka–Volterra Food Web Models with Omnivory’. Journal of Mathematical Analysis and Applications 426, no. 2 (15 June 2015): 659–87. <a href=\"https://doi.org/10.1016/j.jmaa.2015.01.035\"><span class=\"HyperlinkInline\">https://doi.org/10.1016/j.jmaa.2015.01.035</span></a>.</p>\n<p class=\"Item\">Kingsland, Sharon. ‘Alfred J. Lotka and the Origins of Theoretical Population Ecology’. Proceedings of the National Academy of Sciences of the United States of America 112, no. 31 (4 August 2015): 9493–95. <a href=\"https://doi.org/10.1073/pnas.1512317112\"><span class=\"HyperlinkInline\">https://doi.org/10.1073/pnas.1512317112</span></a>.</p>\n<p class=\"Item\">Lee, Benjamin. ‘Determination of the Parameters in Lotka-Volterra Equations from Population Measurements---Algorithms and Numerical Experiments’. SIAM Undergraduate Research Online 14 (1 January 2021). <a href=\"https://doi.org/10.1137/20S1383161\"><span class=\"HyperlinkInline\">https://doi.org/10.1137/20S1383161</span></a>.</p>\n<p class=\"Item\">Lotka, Alfred J. ‘Analytical Note on Certain Rhythmic Relations in Organic Systems’. Proceedings of the National Academy of Sciences of the United States of America 6, no. 7 (July 1920): 410–15.</p>\n<p class=\"Item\">———. ‘Contribution to the Theory of Periodic Reactions’. The Journal of Physical Chemistry 14, no. 3 (1 March 1910): 271–74. <a href=\"https://doi.org/10.1021/j150111a004\"><span class=\"HyperlinkInline\">https://doi.org/10.1021/j150111a004</span></a>.</p>\n<p class=\"Item\">———. ‘Natural Selection as a Physical Principle*’. Proceedings of the National Academy of Sciences 8, no. 6 (June 1922): 151–54. <a href=\"https://doi.org/10.1073/pnas.8.6.151\"><span class=\"HyperlinkInline\">https://doi.org/10.1073/pnas.8.6.151</span></a>.</p>\n<p class=\"Item\">Novak, Mark, Justin D. Yeakel, Andrew E. Noble, Daniel F. Doak, Mark Emmerson, James A. Estes, Ute Jacob, M. Timothy Tinker, and J. Timothy Wootton. ‘Characterizing Species Interactions to Understand Press Perturbations: What Is the Community Matrix?’ Annual Review of Ecology, Evolution, and Systematics 47, no. 1 (2016): 409–32. <a href=\"https://doi.org/10.1146/annurev-ecolsys-032416-010215\"><span class=\"HyperlinkInline\">https://doi.org/10.1146/annurev-ecolsys-032416-010215</span></a>.</p>\n<p class=\"Item\">Volterra, Vito. Variazioni e fluttuazioni del numero d’individui in specie animali conviventi, &amp;c. Memoria / R. comitato talassografico italiano, 1927.</p>\n<h2 class=\"Section\">Further Readings</h2>\n<p class=\"Item\">‘Lotka-Volterra Equations -- from Wolfram MathWorld’. Accessed 5 October 2023. <a href=\"https://mathworld.wolfram.com/Lotka-VolterraEquations.html\"><span class=\"HyperlinkInline\">https://mathworld.wolfram.com/Lotka-VolterraEquations.html</span></a>.</p>\n<p class=\"Item\">‘Lotka-Volterra Model - an Overview | ScienceDirect Topics’. Accessed 5 October 2023. <a href=\"https://www.sciencedirect.com/topics/earth-and-planetary-sciences/lotka-volterra-model\"><span class=\"HyperlinkInline\">https://www.sciencedirect.com/topics/earth-and-planetary-sciences/lotka-volterra-model</span></a>.</p>\n<p class=\"Item\">A Short History of Mathematical Population Dynamics by Nicolas Bacaër, n.d.</p>\n<p class=\"Item\">Essington, Timothy E. Introduction to Quantitative Ecology: Mathematical and Statistical Modelling for Beginners. Oxford, United Kingdom: Oxford University Press, 2021.</p>\n<p class=\"Item\">Kot, Mark. Elements of Mathematical Ecology. 1st edition. Cambridge: Cambridge University Press, 2001.</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>",
            "image": "https://phileasdg.github.io/media/posts/32/Screenshot-2023-10-11-at-00.12.50.png",
            "author": {
                "name": "Phileas Dazeley-Gaist"
            },
            "tags": [
                   "Work at Wolfram",
                   "Wolfram Language",
                   "Programming",
                   "Network Science",
                   "Modelling",
                   "Mathematica",
                   "Ecology"
            ],
            "date_published": "2023-10-10T20:21:31+02:00",
            "date_modified": "2025-10-10T17:45:57+02:00"
        },
        {
            "id": "https://phileasdg.github.io/remote-sensing-for-the-wolfram-language/",
            "url": "https://phileasdg.github.io/remote-sensing-for-the-wolfram-language/",
            "title": "Remote Sensing for the Wolfram Language",
            "summary": "Some Context This summer, I was fortunate to attend the Wolfram Summer&hellip;",
            "content_html": "<h2>Some Context</h2>\n<p>This summer, I was fortunate to attend the Wolfram Summer School at Bentley University in Waltham MA. It was a fast-paced, intense, challenging and exciting experience, and I am grateful to all who contributed to making it such a motivating and worthwhile three weeks. </p>\n<p>The Wolfram Summer School is an educational program hosted by Wolfram Research, the company behind Wolfram Alpha, Mathematica, and the Wolfram Language. It brings together students once a year to explore cutting-edge computational topics, problem-solving techniques, and hands-on projects using Wolfram tech. Students engage in collaborative learning, work on their projects with industry experts, and develop practical skills in computational thinking and programming. </p>\n<p>At the heart of the program for each student is their summer school project. Students at the Wolfram Summer School choose (or are sometimes assigned) a project to work on in meetings with Stephen Wolfram and their summer school mentors. For my project, I decided to build as versatile and robust a remote sensing tool as I could for the Wolfram Language. </p>\n<p>My project progressed quickly throughout the program with the help and guidance of my project mentor, <a href=\"https://christopherwolfram.com/\" target=\"_blank\" rel=\"noopener\">Christopher Wolfram</a>, whose support was crucial to my success. At the end of the summer school, I delivered a presentation on my work, as well as a <a href=\"https://community.wolfram.com/groups/-/m/t/2959942\">post on the Wolfram Community forum</a>, and a <a href=\"https://resources.wolframcloud.com/PacletRepository/resources/PhileasDazeleyGaist/RemoteSensing/\">Wolfram Language paclet: RemoteSensing</a>. </p>\n<p>You can also view other WSS projects <a href=\"https://www.wolframcloud.com/obj/microsites/summerschool/projects.html\">here</a>.</p>\n<h2>The RemoteSensing Paclet</h2>\n<p><strong>Just a heads up: </strong>If you decide to try my paclet, be aware that it is and will likely continue to be a bit of a <em>work-in-progress</em>. I have found it to be quite robust, but you may encounter bugs, as well as service outages from the NASA GIBS and AppEEARS APIs. If you encounter issues with my paclet, including bugs or unclear documentation, please do not hesitate to contact me so that I may address them!</p>\n<p><strong>What is the RemoteSensing Paclet? </strong><span class=\"cc6\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">The </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://resources.wolframcloud.com/PacletRepository/resources/PhileasDazeleyGaist/RemoteSensing/\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\" style=\"font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"><span class=\"cc8\" data-native-text=\"true\">RemoteSensing paclet</span></a><span class=\"cc6\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> contains various functions that allow you make requests to the GIBS and A</span><span class=\"cc7\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">ρρ</span><span class=\"cc6\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">EEARS APIs for geographic products from various US federal agencies, and work with the returned data in the Wolfram Language. The RemoteSensing GIBS functions can be used with </span><span class=\"cc28\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">GeoImage</span><span class=\"cc6\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> and </span><span class=\"cc28\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">GeoGraphics</span><span class=\"cc6\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> through the </span><span class=\"cc28\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">GeoServer</span><span class=\"cc6\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\"> option, while the A</span><span class=\"cc7\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">ρρ</span><span class=\"cc6\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\" data-native-text=\"true\">EEARS functions can be used to request scientific grade geographic data product samples.</span></p>\n<h3>Installation</h3>\n<p>To install the RemoteSensing paclet to your version of Wolfram Language, you'll need to run the following lines of code:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/28/Screenshot-2023-07-21-at-18.46.45.png\" alt=\"\" width=\"1290\" height=\"318\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-18.46.45-xs.png 300w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-18.46.45-sm.png 480w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-18.46.45-md.png 768w\"></figure>\n<p>The second line is not strictly necessary, but it will help you to make sure the paclet installed correctly, and you have the latest version (1.0.3 as of Jul 21 2023, when I am writing this blog post). </p>\n<h3>Example Usage</h3>\n<p>Once you have the paclet installed and imported into your active kernel session, it's ready to use! So let's see some simple examples of what that can look like.</p>\n<p>Please note: Admittedly, this short blog post leaves out a fairly large number of things you can do with the RemoteSensing paclet. If you'd like to know more about what is possible with it (including making timelapse animations with NASA imagery), I strongly suggest you take a look at my <a href=\"https://community.wolfram.com/groups/-/m/t/2959942\">Wolfram Community post</a> about RemoteSensing, and the <a href=\"https://resources.wolframcloud.com/PacletRepository/resources/PhileasDazeleyGaist/RemoteSensing/\">RemoteSensing paclet repository page</a>.</p>\n<h4>GIBS</h4>\n<p><span class=\"cc4\" data-native-text=\"true\">The NASA GIBS (Global Imagery Browse Services) API is a web service provided by NASA used to access and retrieve satellite imagery and related data. The API provides an interface to access a vast collection of global Earth science data through WMTS (Web Map Tile Service).</span><br><span class=\"cc4\" data-native-text=\"true\">​</span><span class=\"cc4\" data-native-text=\"true\">​</span><br><span class=\"cc4\" data-native-text=\"true\">GIBS provides raster tiles, which can be useful for visualisation and data exploration, but should be avoided for serious research, as it does not provide access to the raw layer data. Its advantages are that is is fast, pretty robust, and very flexible.</span></p>\n<p>To request GIBS data using the RemoteSensing paclet, you'll make use of the following functions:</p>\n<ol>\n<li><code>GIBSData</code> which retrieves information about available GIBS layers.</li>\n<li><code style=\"font-weight: var(--font-weight-normal);\">GIBSGeoServer</code> which builds a <code>GeoServer</code> request template for a layer.</li>\n</ol>\n<p>Here's an example showing how you might use them: </p>\n<p>Find a layer of interest:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/28/Screenshot-2023-07-21-at-20.21.34.png\" alt=\"\" width=\"1352\" height=\"198\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.21.34-xs.png 300w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.21.34-sm.png 480w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.21.34-md.png 768w\"></figure>\n<p>Consult information about the layer:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/28/Screenshot-2023-07-21-at-20.22.02.png\" alt=\"\" width=\"519\" height=\"187\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.22.02-xs.png 300w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.22.02-sm.png 480w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.22.02-md.png 768w\"></figure>\n<p>Visualise layer using either <code>GeoGraphics</code> or <code>GeoImage</code>:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/28/Screenshot-2023-07-21-at-20.23.39.png\" alt=\"\" width=\"1376\" height=\"384\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.23.39-xs.png 300w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.23.39-sm.png 480w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.23.39-md.png 768w\"></figure>\n<p>Customise your visualisation as you might with any other <code>GeoGraphics</code> or <code>GeoImage</code> plot:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/28/Screenshot-2023-07-21-at-20.24.07.png\" alt=\"\" width=\"1316\" height=\"584\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.24.07-xs.png 300w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.24.07-sm.png 480w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-20.24.07-md.png 768w\"></figure>\n<p>And there you go! You've made a visualisation using a NASA GIBS WMTS product.</p>\n<h4><span class=\"cc6\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit;\" data-native-text=\"true\">A</span><span class=\"cc7\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit;\" data-native-text=\"true\">ρρ</span><span class=\"cc6\" style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit;\" data-native-text=\"true\">EEARS</span></h4>\n<p><span class=\"cc4\" data-native-text=\"true\">A</span><span class=\"cc5\" data-native-text=\"true\">ρρ</span><span class=\"cc4\" data-native-text=\"true\">EEARS is a geographic data access service provided by NASA. </span><span class=\"cc4\" data-native-text=\"true\">The </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://appeears.earthdatacloud.nasa.gov/\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc6\" data-native-text=\"true\">A</span><span class=\"cc7\" data-native-text=\"true\">ρρ</span><span class=\"cc6\" data-native-text=\"true\">EEARS website</span></a><span class=\"cc4\" data-native-text=\"true\"> describes it like so: “The Application for Extracting and Exploring Analysis Ready Samples (A</span><span class=\"cc5\" data-native-text=\"true\">ρρ</span><span class=\"cc4\" data-native-text=\"true\">EEARS) offers a simple and efficient way to access and transform geospatial data from a variety of federal data archives. A</span><span class=\"cc5\" data-native-text=\"true\">ρρ</span><span class=\"cc4\" data-native-text=\"true\">EEARS enables users to subset geospatial datasets using spatial, temporal, and band/layer parameters.”</span><br><span class=\"cc4\" data-native-text=\"true\">​</span><br><span class=\"cc4\" data-native-text=\"true\">A<span class=\"cc5\" data-native-text=\"true\">ρρ</span>EEARS requires you to be signed in on </span><a class=\"GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq\" href=\"https://www.earthdata.nasa.gov/\" target=\"_blank\" data-testid=\"ButtonBoxView\" rel=\"noopener\"><span class=\"cc6\" data-native-text=\"true\">NASA EarthData</span></a><span class=\"cc4\" data-native-text=\"true\">. Fortunately, it’s quite easy (and most importantly, free) to register an account, and the RemoteSensing paclet provides tools to log you in programmatically.</span><br><span class=\"cc4\" data-native-text=\"true\">​</span><br><span class=\"cc4\" data-native-text=\"true\">A</span><span class=\"cc5\" data-native-text=\"true\">ρρ</span><span class=\"cc4\" data-native-text=\"true\">EEARS allows you to access the real recorded data values for any available remote sensing product it offers. This makes it an appropriate tool to use if you are in need of accurate data for analysis or other scientific research. However, it is not so good for data exploration, as it can be fairly slow depending on the scale of the task and the availability of the API, and it will often return large numbers of heavy files. Use A</span><span class=\"cc5\" data-native-text=\"true\">ρρ</span><span class=\"cc4\" data-native-text=\"true\">EEARS if you already know what you want, and you need precise and accurate data.</span></p>\n<p>To request <span class=\"cc4\" data-native-text=\"true\">A</span><span class=\"cc5\" data-native-text=\"true\">ρρ</span><span class=\"cc4\" data-native-text=\"true\">EEARS</span> data using the RemoteSensing paclet, you'll make use of the following functions:</p>\n<ol>\n<li><code>AppEEARSData</code> which retrieves information about available <span class=\"cc4\" data-native-text=\"true\">A</span><span class=\"cc5\" data-native-text=\"true\">ρρ</span><span class=\"cc4\" data-native-text=\"true\">EEARS</span> products and layers.</li>\n<li><code style=\"font-weight: var(--font-weight-normal);\">AppEEARSImages</code> which makes a request to <span class=\"cc4\" data-native-text=\"true\">A</span><span class=\"cc5\" data-native-text=\"true\">ρρ</span><span class=\"cc4\" data-native-text=\"true\">EEARS and returns the resulting data when it completes.</span></li>\n</ol>\n<p>Now, the <span class=\"cc4\" data-native-text=\"true\">A</span><span class=\"cc5\" data-native-text=\"true\">ρρ</span><span class=\"cc4\" data-native-text=\"true\">EEARS workflow is a little different because depending on your task, you might prefer to make an A<span class=\"cc5\" data-native-text=\"true\">ρρ</span>EEARS request and work with it asynchronously. This is a little more involved, and although I will not show examples of it here, you can find some in my <a href=\"https://community.wolfram.com/groups/-/m/t/2959942\">community post</a>, and the <a href=\"https://resources.wolframcloud.com/PacletRepository/resources/PhileasDazeleyGaist/RemoteSensing/\">paclet documentation</a>.</span></p>\n<p>Get a list of available A<span class=\"cc5\" data-native-text=\"true\">ρρ</span>EEARS products with <code>AppEEARSData</code>:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/28/Screenshot-2023-07-21-at-21.29.03.png\" alt=\"\" width=\"1538\" height=\"114\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.29.03-xs.png 300w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.29.03-sm.png 480w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.29.03-md.png 768w\"></figure>\n<p>Get information about a product:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/28/Screenshot-2023-07-21-at-21.28.21.png\" alt=\"\" width=\"625\" height=\"452\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.28.21-xs.png 300w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.28.21-sm.png 480w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.28.21-md.png 768w\"></figure>\n<p>The above dataset contains the names of available <span class=\"cc4\" data-native-text=\"true\">A<span class=\"cc5\" data-native-text=\"true\">ρρ</span>EEARS</span> layers for the MYDO9GA product. Now, to request information about a specific layer, you might do this:</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/28/Screenshot-2023-07-21-at-21.27.33.png\" alt=\"\" width=\"617\" height=\"565\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.27.33-xs.png 300w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.27.33-sm.png 480w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.27.33-md.png 768w\"></figure>\n<p>And you might make a request for <span class=\"cc4\" data-native-text=\"true\">A<span class=\"cc5\" data-native-text=\"true\">ρρ</span>EEARS</span> imagery using <code style=\"font-weight: var(--font-weight-normal);\">AppEEARSImages</code> <span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">like this (note that this might take some time to process)</span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">:</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://phileasdg.github.io/media/posts/28/Screenshot-2023-07-21-at-21.27.00.png\" alt=\"\" width=\"580\" height=\"607\" sizes=\"(max-width: 48em) 100vw, 100vw\" srcset=\"https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.27.00-xs.png 300w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.27.00-sm.png 480w ,https://phileasdg.github.io/media/posts/28/responsive/Screenshot-2023-07-21-at-21.27.00-md.png 768w\"></figure>\n<h2>Closing thoughts</h2>\n<p>If you've read this far, I hope this blog post has inspired you to try <a href=\"https://resources.wolframcloud.com/PacletRepository/resources/PhileasDazeleyGaist/RemoteSensing/\">my paclet</a> for yourself. Just take a chance to mess around with it! I am actively working to maintain and improve it, and I am always excited to receive <a href=\"https://phileasdg.github.io/inquiries/\">feedback</a> about my work! If you find bugs or have suggestions for its improvement, please don't hesitate to be in touch with me! I look forward to your notes! </p>",
            "image": "https://phileasdg.github.io/media/posts/28/BlogHeader-2.png",
            "author": {
                "name": "Phileas Dazeley-Gaist"
            },
            "tags": [
                   "Work at Wolfram",
                   "Wolfram Language",
                   "Programming",
                   "Mathematica",
                   "GIS",
                   "Environmental Science"
            ],
            "date_published": "2023-07-12T05:58:37+02:00",
            "date_modified": "2024-07-28T10:01:15+02:00"
        }
    ]
}
