<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>Phileas Dazeley-Gaist</title>
    <link href="https://phileasdg.github.io/feed.xml" rel="self" />
    <link href="https://phileasdg.github.io" />
    <updated>2026-01-17T15:12:55-05:00</updated>
    <author>
        <name>Phileas Dazeley-Gaist</name>
    </author>
    <id>https://phileasdg.github.io</id>

    <entry>
        <title>Patchwork with Coexisting Cellular Automata</title>
        <author>
            <name>Phileas Dazeley-Gaist</name>
        </author>
        <link href="https://phileasdg.github.io/patchwork-with-coexisting-cellular-automata/"/>
        <id>https://phileasdg.github.io/patchwork-with-coexisting-cellular-automata/</id>
        <media:content url="https://phileasdg.github.io/media/posts/53/banner-2.png" medium="image" />
            <category term="Wolfram Language"/>
            <category term="Programming"/>
            <category term="Modelling"/>
            <category term="Complex Systems"/>
            <category term="Cellular Automata"/>
            <category term="Art"/>

        <updated>2026-01-17T10:53:32-05:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://phileasdg.github.io/media/posts/53/banner-2.png" alt="" />
                    Note: This post was originally a short technical article I shared on&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://phileasdg.github.io/media/posts/53/banner-2.png" class="type:primaryImage" alt="" /></p>
                <p class="msg msg--info"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forum. For an interactive experience with live code or to download this text alongside the source code, please visit the original post <a href="https://community.wolfram.com/groups/-/m/t/3608683?p_p_auth=C3EsWlzT">here</a>. </p>
<h2>Introduction</h2>
<p>At the 2025 Wolfram Summer School, while advising on a project about collaborative decision-making using cellular automata (CAs), I spent some time thinking up different possible setups to get CA rules to interact with each other and perform "negotiations". We considered several setups, including using CA state cells to represent a distribution of opinions in a society, and tried various schemes in an attempt to evolve rules that would reliably yield "consensus" states.</p>
<p>One approach that I did not have time to dive into but that showed promise was to represent agents as rules confined to specific, strictly different regions in space, but able to interact with each other where their boundaries touch or are close to one another. Setups like this will be the subject of this short essay.</p>
<p>Here's a teaser of what we're working toward: Programs that operate on a cellular automaton state arrays by applying a list of cellular automata rules to a list of non-overlapping regions of the state, such that each defined region is subject to its own dynamics, determined both by the region's assigned rule and the dynamics near the region boundary.</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/cellsetup.gif" alt="" width="559" height="406"></figure>
<h2>Cellular automata with custom boundary conditions</h2>
<p>We'll work our way up to CAs operating in parallel on non-overlapping regions of space. But first, it'll be helpful to review some of the basics. </p>
<h3>One-dimensional CAs</h3>
<h4>Natively supported CA boundary conditions</h4>
<p>In Wolfram Language, cellular automata default to having periodic boundary conditions.</p>
<p><em>Elementary cellular automaton trajectory with periodic boundary conditions:<br></em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-11.31.52.png" alt="" width="225" height="226" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.31.52-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.31.52-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.31.52-md.png 768w"></figure>
<p>Notice the ripple cascade that wraps around horizontal space as it leaves to the right and simultaneously enters to the left.</p>
<p>The natively supported alternative to periodic boundary conditions in the CellularAutomaton function is to have CAs running on an infinite canvas.</p>
<p><em>Elementary cellular automaton trajectory on an infinite canvas:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-11.33.15.png" alt="" width="225" height="226" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.33.15-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.33.15-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.33.15-md.png 768w"></figure>
<p>Here, the width of the state array is not fixed. In this case, the ripple cascade simply propagates outwards forever, uninterrupted.</p>
<p>The system we are envisioning requires that we implement custom boundary conditions, which there is no built in support for at the moment as far as I can tell. So how can we get there?</p>
<h4>Confining CAs to regions in space</h4>
<p>To confine a rule to a spatial region within a CA state, the simplest general approach I can think of is to apply the rule to the full state, but discard all changes to the state outside the rule's assigned region using a region mask. For example:</p>
<p><em>Trajectory of a rule 30 CA confined to a small region of the simulation space:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-11.34.19.png" alt="" width="225" height="227" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.34.19-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.34.19-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.34.19-md.png 768w"></figure>
<p>In the plot above, the green region represents the spatial domain of the automaton rule. Changes made to the state by the rule will only take effect inside the green region. </p>
<p>Proceeding this way means that although the green automaton is unable to make changes to cells outside the green region, green region cells near the border still "sense", and are affected by the state of cells on the other side of the border. If a green-region cell's neighbourhood contains cells from different regions, those cell states are used to determine the new cell state just as they would usually be. What this achieves is making the automaton region boundaries porous by default. The dynamics in the green region are affected by the local dynamics outside of the green region.</p>
<p>In the present example, the background is held constant and uniform. But there's not reason it has to be. If the background were heterogenous and dynamic, our setup would work just as well, though the dynamics in the green region would  be different as the state evolution would be subject to different kinds of interference from local background activity. We'll return to this point later.</p>
<p>Another important clarification is that while in the simulations above, the chosen rule is confined to a region with a constant spatial boundary, the simulation itself is still operating in a periodic space. This distinction is essential because it means that cells on the periphery of the state array are still considered adjacent to cells on their opposite sides. In the example above, the left and right sides of the state array are still glued together. If a rule's assigned region were to span from one end of the state to the other, it would be possible for event cascades to wrap around.</p>
<p><em>Trajectory of a rule 30 CA confined to a region that wraps around the periodic boundaries of the simulation space:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-11.35.45.png" alt="" width="225" height="227" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.35.45-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.35.45-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.35.45-md.png 768w"></figure>
<h4>Removing spatial periodicity</h4>
<p>To also get rid of the periodic boundary conditions of the space itself, my suggestion is a bit hacky but functional: Pad any starting CA state with enough zeros in all directions to prevent periodic interaction at the edges of the state array, compute the next step, and trim the resulting array so as to recover the original dimensions. Repeat as needed. Padding by the automaton neighbourhood  range is easy and guaranteed to be enough (the minimum required padding depends on the neighbourhood used by automata in the simulation, so I won't discuss it here). </p>
<p><em>Cellular automaton trajectory with a rule 30 CA confined to a visually identical region as in the previous example, but that does not wrap around the periodic boundaries of the simulation space:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-11.36.30.png" alt="" width="225" height="226" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.36.30-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.36.30-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.36.30-md.png 768w"></figure>
<p>Now, on the left and right sides of the state array, the background is effectively taken to be all zeros, so the rightmost cascade can never wrap around to the left, and the simulation space is fixed. In this specific case, the change also causes both green regions to start with the same initial conditions. As the neighbours to the left of the leftmost cell of each green region at t=0 are now considered to be zero, the initial conditions cause two cascades instead of one.</p>
<p>We chose to have uniform and constant zero boundary conditions for the entire simulation space, but as before, we could have done otherwise. Here is an example in which these boundary conditions are made random and dynamic.</p>
<p><em>Rule 30 CA trajectory confined to a region subject to random and dynamic boundary conditions:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-11.37.05.png" alt="" width="225" height="226" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.37.05-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.37.05-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.37.05-md.png 768w"></figure>
<p>Here, the states of the cells that make up the boundary change at random, affecting the dynamics of the green automaton, although the boundary itself does not move around. The boundary is fixed in space, but not fixed in state.</p>
<h3>Two-dimensional CAs</h3>
<p>Now that we've established some techniques for confining 1D cellular automata to specific regions, the natural next step is to apply these ideas to 2D CAs. Good news! The techniques we just discussed for 1D CAs work just as well in 2D, and even in higher dimensions.</p>
<p>Here's a setup in two dimensions that confines a totalistic 9-neighbour CA to a square region of the simulation space.</p>
<p><em>Dynamics of a totalistic 9-neighbor CA confined to a square region of the simulation space:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/squaresetup.gif" alt="" width="300" height="300"></figure>
<p>Just as before:</p>
<ul>
<li>The green region represents the spatial domain of the automaton rule. </li>
<li>The boundary is porous, so nearby activity outside the green region can affect green region dynamics.</li>
<li>The boundary conditions for the whole simulation space are still periodic by default, but can be fixed or controlled using the masking techniques I described for 1D CAs.</li>
</ul>
<p>Since the green region is determined by a binary mask array, we can easily try almost any setup you can think of painting out on a canvas. In the next few examples, I use a region with an inner isolated part with constant zero boundary conditions, and an outer part that connects every edge of the simulation window. The inner part will be undisturbed by any changes to the global, simulation space boundary conditions, so its dynamics can be thought of as a control in our experiments.</p>
<p>Here's a setup where the green region allows the dynamics to wrap around along each axis.</p>
<p><em>Totalistic 9-neighbor CA dynamics constrained to a region with an isolated central component subject to fixed zero boundary conditions, and a surrounding component subject to the periodic boundary conditions of the simulation space:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/crosssetupperiodic.gif" alt="" width="300" height="300"></figure>
<p>You can think of the space as wrapping around a torus like this:</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-11.45.55.png" alt="" width="225" height="205" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.45.55-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.45.55-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.45.55-md.png 768w"></figure>
<p>Here's a setup with the same green region specification, but with constant zero boundary conditions applied to the simulation space.</p>
<p><em>Totalistic 9-neighbor CA dynamics constrained to a region with an isolated central component subject to fixed zero boundary conditions, and a surrounding component also subject to fixed boundary conditions:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/crosssetupconstantzero-2.gif" alt="" width="300" height="300"></figure>
<p>Setting constant zero boundary conditions turns the boundaries of the simulation window into smooth, solid, impenetrable walls, preventing the dynamics of the green CA from wrapping around.</p>
<p>Finally, here's an example in which these boundary conditions are made random and dynamic.</p>
<p><em>Totalistic 9-neighbor CA dynamics constrained to a region with an isolated central component subject to fixed zero boundary conditions, and a surrounding component subject to random dynamic boundary conditions:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/crosssetupdynamicrandom.gif" alt="" width="301" height="301"></figure>
<p>In this last case, the dynamics in the outer part appear quite random.</p>
<h3>Three dimensions and above</h3>
<p>Just to show that it's possible, here's a complicated 3D example using a state generated by another 3D CA as the automaton region mask.</p>
<p><em>Dynamics of a 3D CA confined to a complex 3D region:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/3Dsetup.gif" alt="" width="300" height="326"></figure>
<p>And here's a simulation of the process in six dimensions, just for fun, although there's no longer a simple way to visualize its output, so all I'll show you is this preview of the final state array: </p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-11.52.45.png" alt="" width="1224" height="126" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.52.45-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.52.45-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.52.45-md.png 768w"></figure>
<h3>Bonus: miscellaneous interesting examples</h3>
<h4>Mazes</h4>
<p><em>First, generate a maze to use as a mask:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-11.53.16.png" alt="" width="225" height="229" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.53.16-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.53.16-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.53.16-md.png 768w"></figure>
<p><em>Compute the trajectory of a 9-neighbour 2D totalistic CA confined by the mask:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/mazesetup.gif" alt="" width="300" height="300"></figure>
<h4>Other complex shapes</h4>
<p><em>Define an organic shape shape to use as a mask:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-11.55.53.png" alt="" width="225" height="234" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.55.53-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.55.53-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-11.55.53-md.png 768w"></figure>
<p><em>Compute the trajectory of a 9-neighbour 2D totalistic CA confined by the mask:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/flowersetup.gif" alt="" width="300" height="308"></figure>
<h3>Review</h3>
<p>In this section, we explored techniques for confining cellular automata to specific spatial regions within a larger CA system. In summary:</p>
<ul>
<li>The CellularAutomaton function supports two default boundary conditions, periodic and infinite.</li>
<li>To confine a CA rule to a specific spatial region, we can apply the rule to the full state, but discard all changes outside the rule's assigned region using a region mask. </li>
<li>To remove the periodic boundary conditions of the space itself, we can pad the initial state with enough zeros in all directions to prevent periodic interaction at the edges, compute the next step, and trim the resulting array back to the original dimensions. This effectively simulates constant zero boundary conditions. </li>
<li>By controlling the padding values we can set different kinds of global boundary conditions. Padding with ones will simulate uniform and constant one boundary conditions. Padding with zeros and ones in different places will result in non-uniform boundary conditions. In general, boundary conditions must be defined with valid cell states: zero or one for two-state CAs, and zero through <em>k-1</em> for <em>k</em> state CAs.</li>
<li>We can also make the boundary conditions of the simulation space dynamic and heterogeneous, for example, by defining a global boundary mask that frames the simulation window, and setting cells within the boundary it defines to random states at every step of the simulation. Any CA whose spatial domain is close enough to the global boundary mask will see its dynamics affected by the random global boundary conditions.</li>
<li>These techniques can be applied to 1D and 2D CAs, but also to CAs in higher dimensional spaces. </li>
</ul>
<h2>Coexisting Cellular Automata: <br>Running CAs in parallel in separate regions of space</h2>
<h3>How does it work?</h3>
<p>We can use the tools developed above to perform simulations in which several CA rules operate in parallel on non-overlapping regions of the simulation space. I'll refer to simulations like these as Coexisting CAs, and since I'm going to want to experiment with Coexisting CAs a lot, I'll define a <em>CoexistingCellularAutomata</em> function to automate the process of setting up and running these simulations. The full function definition can be found in the <em>Code Initialisation</em> section at the end of the <a href="https://community.wolfram.com/groups/-/m/t/3608683?p_p_auth=A7Xz7iqu">Wolfram Community version of this article</a>.</p>
<p>The core steps of the process are: </p>
<ol>
<li>Define a list of CA rules and an initial state for the entire simulation space.</li>
<li>Create an array that specifies the spatial domain for each CA rule, where each cell in the array corresponds to the index of the rule that should be applied in that region.</li>
<li>Generate binary masks from the spatial domains array to isolate the regions where each rule should be applied.</li>
<li>Define boundary conditions for the overall simulation space, which can be constant or dynamic.</li>
<li>Apply the CA rules to their respective domains, clip the results to the domain masks, sum the resulting state arrays, and apply the global boundary conditions.</li>
</ol>
<h3>Computing a single step of a Coexisting CA simulation</h3>
<p>This next code snippet demonstrates the process I settled on in my final implementation to compute a single Coexisting CA simulation step. I've included comments to describe the process alongside the code, and calls to Echo and EchoFunction to show key variables generated or used in the throughout its execution.</p>
<figure class="post__image align-left"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.02.24.png" alt="" width="600" height="605" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.02.24-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.02.24-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.02.24-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.03.30.png" alt="" width="600" height="496" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.03.30-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.03.30-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.03.30-md.png 768w"></figure>
<h3>Performing a full Coexisting CA simulation</h3>
<p>The CoexistingCellularAutomata function makes simulations of interacting CAs quite easy to set up and perform. Let me show you.</p>
<p>I'll start by defining my simulation parameters. For this example, I'll pick 10 rules at random. Each rule domain will be assigned its own colour.</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.04.25.png" alt="" width="272" height="98" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.04.25-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.04.25-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.04.25-md.png 768w"></figure>
<p><em>Pick some 2 colour range 9-neighbour totalistic CA rules at random:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.05.09.png" alt="" width="609" height="117" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.05.09-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.05.09-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.05.09-md.png 768w"></figure>
<p>I'll set constant zero initial conditions across the initial state.</p>
<p><em>Define an initial array representing the state at t=0:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.05.51.png" alt="" width="396" height="101" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.05.51-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.05.51-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.05.51-md.png 768w"></figure>
<p>The spatial domains of each CA rule in the simulation must be specified using a single array of integer values corresponding to indices of the supplied rules in the rule list, or zero, meaning "no rules apply here". </p>
<p>We can arbitrarily partition the simulation space and assign whichever parts we choose to whichever rules we like. Here, I've used a helper function called <em>generateVoronoiCASpatialDomains</em> (defined in the <em>Code Initialisation</em> section of the <a href="https://community.wolfram.com/groups/-/m/t/3608683?p_p_auth=A7Xz7iqu">Wolfram Community version of this essay</a>) to generate the rule domain definitions array.</p>
<p><em>Define the spatial domains of each rule in the simulation space:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.07.05.png" alt="" width="529" height="52" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.07.05-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.07.05-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.07.05-md.png 768w"></figure>
<p><em>Preview the domain masks:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.07.31.png" alt="" width="575" height="168" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.07.31-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.07.31-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.07.31-md.png 768w"></figure>
<p>To perform a simulation, simply supply the list of rules, domain mask, initial state, and number of steps to the CoexistingCellularAutomata function.</p>
<p><em>Perform a simulation using CoexistingCellularAutomata:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.08.45.png" alt="" width="405" height="205" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.08.45-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.08.45-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.08.45-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.09.03.png" alt="" width="680" height="372" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.09.03-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.09.03-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.09.03-md.png 768w"></figure>
<p>The result is a list of arrays representing the sequence of Coexisting CA states, each of which we can plot to make the frames of an animation of the full simulation trajectory.</p>
<p><em>Animate the resulting simulation of interacting CAs, using the masks to colour the frames:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.09.50.png" alt="" width="586" height="172" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.09.50-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.09.50-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.09.50-md.png 768w"></figure>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/voronoisetup-2.gif" alt="" width="650" height="473"></figure>
<h3>Using images as Coexisting CA domain Masks</h3>
<p>The CoexistingCellularAutomata function works with arbitrary valid rule domain definitions. Any array of positive or zero integer values is a valid rule domain mask. This means we can use posterized images as rule domain specifications.</p>
<p>For this next example, I posterized a webcam selfie so as to only have pixel values of 0,1, or 2 and used the resulting image as the domain mask specification in CoexistingCellularAutomata. In the simulation, these values respectively correspond to neutral territory, the domain of the first rule, and the domain of the second rule. I picked two totalistic 9-neighbour 2D CA rules to use at random:</p>
<p><em>Define a mask to use in the simulation:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.15.08.png" alt="" width="651" height="180" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.15.08-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.15.08-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.15.08-md.png 768w"></figure>
<figure class="post__image"><em><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.15.31.png" alt="" width="302" height="192" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.15.31-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.15.31-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.15.31-md.png 768w"></figure></em></p>
<p><em>Set up and run a 20 step simulation with the chosen rules, rule domains defined by the image mask, and an initial condition array made of all zeros:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/picturesetup.gif" alt="" width="671" height="366"></figure>
<h2>Global boundary conditions of Coexisting CA simulations</h2>
<p>By default, CoexistingCellularAutomata assumes periodic boundary conditions on the simulation space, as in this trajectory of rule 10 and rule 90, where the leftmost cells of the array interact with the rightmost cells:</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.29.51.png" alt="" width="251" height="212" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.29.51-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.29.51-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.29.51-md.png 768w"></figure>
<p>As a convenience to the end user, CoexistingCellularAutomata also supports specifying global boundary conditions using the <em>"GlobalMaskFunction"</em> and <em>"GlobalMaskValueFunction"</em> options. As their names suggest, these options are designed to receive function arguments. These should be functions of the state array at any given time, though they can also be made to ignore the state array input. </p>
<p>The <em>"GlobalMaskFunction"</em> option defines the boundary of the simulation by returning a binary mask where 1s represent cells that can be affected by the chosen CA rules, and 0s represent cells that cannot. The specified function may also return a 0, signalling that no special global boundary conditions should be added. The <em>"GlobalMaskValueFunction"</em> defines the values inside the boundary region, and can return a constant cell state value, or an array of valid cell states. When these functions return arrays, the arrays must have dimensions as the state array. </p>
<p>To add constant zero boundary conditions on the left and right ends of the state arrays in the previous simulation, only minimal changes to the code are needed. By adding </p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.30.42.png" alt="" width="492" height="42" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.30.42-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.30.42-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.30.42-md.png 768w"></figure>
<p>and </p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.31.08.png" alt="" width="283" height="31" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.31.08-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.31.08-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.31.08-md.png 768w"></figure>
<p>to the CoexistingCellularAutomata function call, we restrict the rule domains to all cells other than those near the border, and set the excluded border cells to be equal to 0 throughout the simulation:</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.31.40.png" alt="" width="250" height="214" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.31.40-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.31.40-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.31.40-md.png 768w"></figure>
<p>Because <em>"GlobalMaskFunction"</em> and <em>"GlobalMaskValueFunction"</em> expect functions, and these functions are computed for every step of a Coexisting CA simulation, it's also quite easy to set dynamic boundary conditions. If instead, we had specified the options</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.32.30.png" alt="" width="508" height="34" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.32.30-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.32.30-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.32.30-md.png 768w"></figure>
<p>and </p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.32.50.png" alt="" width="446" height="33" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.32.50-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.32.50-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.32.50-md.png 768w"></figure>
<p>we would get random dynamic boundary conditions on the boundaries of the simulation space:</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/53/Screenshot-2026-01-17-at-12.33.11.png" alt="" width="250" height="207" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.33.11-xs.png 300w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.33.11-sm.png 480w ,https://phileasdg.github.io/media/posts/53/responsive/Screenshot-2026-01-17-at-12.33.11-md.png 768w"></figure>
<h2>Closing thoughts</h2>
<p>There are many directions this work could go. It's easy to imagine how the setups we've explored here could become the basis form a kind of toy model of artificial life in which the organisms are wandering cellular automata whose spatial domain boundary conditions themselves are subject to environmental and competitive pressures. </p>
<p>Another direction might be to modify the setups explored in this essay to allow multiple CAs to occupy the same spatial domains, and compete for dominance over these overlapping regions. This would require careful planning, as there are many possibilities for how such overlapping claims could be handled, and all will inevitably come with their own advantages and tradeoffs.</p>
<p>What would you do next? If you find this work interesting, and you'd like to discuss it, please feel free to reach out. I'm excited to continue exploring this topic and to see what can come of it.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Mapping Global Land Cover with European Space Agency Data</title>
        <author>
            <name>Phileas Dazeley-Gaist</name>
        </author>
        <link href="https://phileasdg.github.io/mapping-global-land-cover-with-european-space-agency-data/"/>
        <id>https://phileasdg.github.io/mapping-global-land-cover-with-european-space-agency-data/</id>
        <media:content url="https://phileasdg.github.io/media/posts/52/banner.png" medium="image" />
            <category term="Wolfram Language"/>
            <category term="Programming"/>
            <category term="Geography &amp; GIS"/>
            <category term="Environmental Science"/>
            <category term="Ecology"/>

        <updated>2026-01-10T11:01:14-05:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://phileasdg.github.io/media/posts/52/banner.png" alt="" />
                    Note: This post was originally a short technical article I shared on&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://phileasdg.github.io/media/posts/52/banner.png" class="type:primaryImage" alt="" /></p>
                <p class="msg msg--info"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forum. For an interactive experience with live code or to download this text alongside the source code, please visit the original post <a href="https://community.wolfram.com/groups/-/m/t/3582661">here</a>. </p>
<h2>Introduction: The ESA WorldCover dataset</h2>
<p>The <a href="https://esa-worldcover.org/en">European Space Agency's WorldCover</a> is a freely accessible dataset providing global land cover classification at 10-meter resolution derived from Sentinel-1 and Sentinel-2 satellite imagery. Released in 2020 and updated in 2021, the ESA reports that the updated dataset achieves an overall accuracy of 76.7% in identifying land cover types, including forests, grasslands, croplands, urban areas, and water bodies across the entire Earth's surface.</p>
<p>The high-resolution imagery WorldCover offers is especially valuable for environmental monitoring, urban planning, and understanding how human activity impacts and encroaches upon wild landscapes. WorldCover's 10-meter resolution can capture fine-grained details such as the difference a small forest patch and an adjacent agricultural field, or between building clusters within a neighborhood. The ESA distributes WorldCover imagery through several access points, including through two WMTS services (one for the 2020 product, and another for the 2021 version). You can find a list of these access points at<a href="https://esa-worldcover.org/en/data-access"> this link</a>.</p>
<p>ESA WorldCover classifies land cover using the following eleven land cover classes:</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.02.55.png" alt="" width="546" height="70" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.02.55-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.02.55-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.02.55-md.png 768w"></figure>
<p>In Wolfram Language (WL), it's fairly straightforward to access ESA WorldCover data through <a href="https://reference.wolfram.com/language/ref/GeoGraphics.html">GeoGraphics</a> using the <a href="https://reference.wolfram.com/language/ref/GeoServer.html">GeoServer</a> option. This way, we can visualize land cover for any region on Earth, from small scale features like countryside human settlements to entire continents, and compare it to other geographic data to uncover patterns in land use and other anthropogenic environmental impacts.</p>
<p>This short piece will demonstrate how to connect to ESA WorldCover to make custom geographic visualisations in WL, and illustrate the flexibility of the Wolfram environment for this kind of data exploration by visualizing the land cover around the twenty largest US cities by population size, and around the 63 US national parks. The code to generate the former set of maps will be about five lines long, and about twenty lines long for the latter.</p>
<h2>Connecting to ESA WorldCover with GeoGraphics</h2>
<p>First, let's define the GeoServer options to access the WorldCover datasets.</p>
<p><em>GeoServer specification for ESA WorldCover 2020:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.05.11.png" alt="" width="1330" height="224" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.05.11-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.05.11-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.05.11-md.png 768w"></figure>
<p><em>GeoServer specification for ESA WorldCover 2021:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.05.31.png" alt="" width="1314" height="220" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.05.31-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.05.31-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.05.31-md.png 768w"></figure>
<p>While we're at it, let's define a legend with which to label our maps.</p>
<p><em>Define a WorldCover legend: </em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.06.01.png" alt="" width="1278" height="678" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.06.01-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.06.01-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.06.01-md.png 768w"></figure>
<p>We now have all the pieces needed to make WorldCover visualizations. To make a land cover map, simply call specify the region you'd like to plot and the GeoServer specification to use inside GeoGraphics. </p>
<p><em>Map global land cover:</em></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.06.44.png" alt="" width="553" height="242" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.06.44-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.06.44-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.06.44-md.png 768w"></figure>
<p>I've specified the <a href="https://reference.wolfram.com/language/ref/GeoZoomLevel.html">GeoZoomLevel</a> option manually in this example because the default setting results in imagery just below the resolution I want. This is a side-effect of the way the ESA WorldCover data services are set up. Let's come back to that later. For now, we'll keep specifying the zoom level manually.</p>
<p>To add the legend we defined above to the plot, you can use <a href="https://reference.wolfram.com/language/ref/Labeled.html">Labeled</a>. The main advantage of using Labeled over <a href="https://reference.wolfram.com/language/ref/Legended.html">Legended</a> is that you can control where the legend goes with the third argument. If the example below had resulted in a wide map, for instance, we might have instead chosen to add the legend below the map using <a href="https://reference.wolfram.com/language/ref/Below.html">Below</a> as the third argument to <a href="https://reference.wolfram.com/language/ref/Labeled.html">Labeled</a> instead of <a href="https://reference.wolfram.com/language/ref/Right.html">Right</a>.</p>
<p><em>Map the land cover in Illinois:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.09.06.png" alt="" width="586" height="569" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.09.06-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.09.06-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.09.06-md.png 768w"></figure>
<p>We can easily compare both dataset versions by plotting the same map twice, once with each GeoServer specification.</p>
<p><em>Compare imagery from WorldCover 2020 and WorldCover 2021 over the same region:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.09.48.png" alt="" width="1448" height="774" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.09.48-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.09.48-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.09.48-md.png 768w"></figure>
<p>By lightly modifying the previous example, we can make a side-by-side comparison of ESA WorldCover land cover classification with another map of the same region: </p>
<p><em>Map the land cover around London: </em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.11.04.png" alt="" width="1818" height="1140" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.11.04-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.11.04-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.11.04-md.png 768w"></figure>
<p>Since the WorldCover dataset has global coverage, it can be used to visualise land cover for remote areas.</p>
<p><em>Map the land cover on Kerguelen:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.11.45.png" alt="" width="617" height="498" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.11.45-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.11.45-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.11.45-md.png 768w"></figure>
<p>To adjust the automatic GeoZoomLevel setting I've opted to generate the map once with automatic settings, retrieving the chosen GeoZoomLevel from the result and adding a constant (I chose 2) to the result to get the adjusted setting to use in the final map. Then I recompute the final map with the adjusted GeoZoomLevel.</p>
<p><em>Automatically set the zoom level to be a little higher than by default:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.12.29.png" alt="" width="692" height="498" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.12.29-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.12.29-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.12.29-md.png 768w"></figure>
<p>In the following sections, I'll apply the connection to this dataset to automatically survey the land cover around the largest US cities by population, and all 63 US national parks.</p>
<h2>Land cover around major US cities</h2>
<p>We can apply this workflow to quickly visualize any set of locations. Let's start with the largest cities in the US. </p>
<p><em>List the largest US cities by population:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.13.09.png" alt="" width="698" height="172" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.13.09-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.13.09-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.13.09-md.png 768w"></figure>
<p>Plotting the ESA land cover for these cities yields important morphological visual contrasts. For example, Phoenix and Denver exemplify contiguous expansion into open terrain and are surrounded by arid shrubland and high plains grassland, respectively. In contrast, New York, San Jose and Seattle have sharp boundaries where development is strictly confined by valley topography or water bodies, and in Charlotte the built environment is heavily interspersed with dense tree canopy.</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.13.36.png" alt="" width="1350" height="434" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.13.36-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.13.36-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.13.36-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.23.04.png" alt="" width="1740" height="1384" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.23.04-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.23.04-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.23.04-md.png 768w"></figure>
<p><em>Map the land cover around any of the twenty largest US cities by population:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.34.00.png" alt="" width="555" height="132" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.34.00-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.34.00-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.34.00-md.png 768w"></figure>
<div class="gallery-wrapper"><div class="gallery"  data-is-empty="false" data-translation="Add images" data-columns="3">
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Austin.png" data-size="668x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Austin-thumbnail.png" alt="" width="668" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Charlotte.png" data-size="652x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Charlotte-thumbnail.png" alt="" width="652" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Chicago.png" data-size="680x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Chicago-thumbnail.png" alt="" width="680" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Columbus.png" data-size="720x783"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Columbus-thumbnail.png" alt="" width="720" height="783"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Dallas.png" data-size="720x691"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Dallas-thumbnail.png" alt="" width="720" height="691"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Denver.png" data-size="720x588"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Denver-thumbnail.png" alt="" width="720" height="588"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Fort-Worth.png" data-size="720x790"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Fort-Worth-thumbnail.png" alt="" width="720" height="790"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Houston.png" data-size="720x628"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Houston-thumbnail.png" alt="" width="720" height="628"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Indianapolis.png" data-size="720x744"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Indianapolis-thumbnail.png" alt="" width="720" height="744"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Jacksonville.png" data-size="720x586"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Jacksonville-thumbnail.png" alt="" width="720" height="586"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Los-Angeles.png" data-size="558x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Los-Angeles-thumbnail.png" alt="" width="558" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/New-York-City.png" data-size="720x786"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/New-York-City-thumbnail.png" alt="" width="720" height="786"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Philadelphia.png" data-size="720x821"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Philadelphia-thumbnail.png" alt="" width="720" height="821"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Phoenix.png" data-size="440x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Phoenix-thumbnail.png" alt="" width="440" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/San-Antonio.png" data-size="720x736"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/San-Antonio-thumbnail.png" alt="" width="720" height="736"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/San-Diego.png" data-size="488x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/San-Diego-thumbnail.png" alt="" width="488" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/San-Francisco.png" data-size="720x416"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/San-Francisco-thumbnail.png" alt="" width="720" height="416"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/San-Jose.png" data-size="720x718"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/San-Jose-thumbnail.png" alt="" width="720" height="718"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Seattle.png" data-size="531x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Seattle-thumbnail.png" alt="" width="531" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Washington.png" data-size="666x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Washington-thumbnail.png" alt="" width="666" height="864"></a></figure>
</div></div>
<h2>Land cover around US National Parks</h2>
<p>Let's also try this for US national parks. In the last example, we used entities from the Wolfram Knowledgebase to define the geographic footprints of US cities to be plotted. We'll need to to something similar for national but since the knowledgebase does not have built-in entities for every park yet, we'll have to supplement the list with some custom-defined regions as well.</p>
<p><em>Define an Association representing US national parks:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.30.39.png" alt="" width="1564" height="1320" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.30.39-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.30.39-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.30.39-md.png 768w"></figure>
<p>Applying this workflow again to US National Parks, there are important contrasts in the landscape compositions. For instance, Denali and the Everglades have unique dominant cover types: permanent snow and grassland, and herbaceous wetland and mangroves, respectively, that stand apart from the arid shrubland and bare rock of Arches. Other contrasts are defined by topography and hydrography, such as the fragmented coastal forests of Acadia or the steep gradients of the Black Canyon. An outlier, Indiana Dunes is sharply bounded by adjacent urban and agricultural land.</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.30.58.png" alt="" width="1550" height="414" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.30.58-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.30.58-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.30.58-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.31.19.png" alt="" width="1810" height="1334" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.31.19-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.31.19-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.31.19-md.png 768w"></figure>
<p><em>Map the land cover of any US national park:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.39.04.png" alt="" width="618" height="168" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.39.04-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.39.04-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.39.04-md.png 768w"></figure>
<div class="gallery-wrapper"><div class="gallery"  data-is-empty="false" data-translation="Add images" data-columns="3">
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Acadia-National-Park.png" data-size="720x715"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Acadia-National-Park-thumbnail.png" alt="" width="720" height="715"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/American-Samoa.png" data-size="720x385"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/American-Samoa-thumbnail.png" alt="" width="720" height="385"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Arches-National-Park.png" data-size="632x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Arches-National-Park-thumbnail.png" alt="" width="632" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Badlands-National-Park.png" data-size="720x753"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Badlands-National-Park-thumbnail.png" alt="" width="720" height="753"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Big-Bend-National-Park.png" data-size="720x662"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Big-Bend-National-Park-thumbnail.png" alt="" width="720" height="662"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Biscayne-National-Park.png" data-size="516x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Biscayne-National-Park-thumbnail.png" alt="" width="516" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Black-Canyon-of-the-Gunnison-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Black-Canyon-of-the-Gunnison-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Bryce-Canyon-National-Park.png" data-size="495x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Bryce-Canyon-National-Park-thumbnail.png" alt="" width="495" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Canyonlands-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Canyonlands-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Capitol-Reef-National-Park.png" data-size="397x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Capitol-Reef-National-Park-thumbnail.png" alt="" width="397" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Carlsbad-Caverns-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Carlsbad-Caverns-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Channel-Islands-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Channel-Islands-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Congaree-National-Park.png" data-size="720x389"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Congaree-National-Park-thumbnail.png" alt="" width="720" height="389"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Crater-Lake-National-Park.png" data-size="720x753"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Crater-Lake-National-Park-thumbnail.png" alt="" width="720" height="753"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Cuyahoga-Valley-National-Park.png" data-size="351x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Cuyahoga-Valley-National-Park-thumbnail.png" alt="" width="351" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Death-Valley-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Death-Valley-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Denali-National-Park-and-Preserve.png" data-size="720x720"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Denali-National-Park-and-Preserve-thumbnail.png" alt="" width="720" height="720"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Dry-Tortugas-National-Park.png" data-size="720x358"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Dry-Tortugas-National-Park-thumbnail.png" alt="" width="720" height="358"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Everglades-National-Park.png" data-size="720x761"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Everglades-National-Park-thumbnail.png" alt="" width="720" height="761"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Gates-of-the-Arctic-National-Park-and-Preserve.png" data-size="720x821"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Gates-of-the-Arctic-National-Park-and-Preserve-thumbnail.png" alt="" width="720" height="821"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Gateway-Arch-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Gateway-Arch-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Glacier-Bay-National-Park-and-Preserve.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Glacier-Bay-National-Park-and-Preserve-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Glacier-National-Park.png" data-size="720x706"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Glacier-National-Park-thumbnail.png" alt="" width="720" height="706"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Grand-Canyon-National-Park.png" data-size="720x445"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Grand-Canyon-National-Park-thumbnail.png" alt="" width="720" height="445"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Grand-Teton-National-Park.png" data-size="583x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Grand-Teton-National-Park-thumbnail.png" alt="" width="583" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Great-Basin-National-Park.png" data-size="593x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Great-Basin-National-Park-thumbnail.png" alt="" width="593" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Great-Sand-Dunes-National-Park-and-Preserve.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Great-Sand-Dunes-National-Park-and-Preserve-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Great-Smoky-Mountains-National-Park.png" data-size="720x409"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Great-Smoky-Mountains-National-Park-thumbnail.png" alt="" width="720" height="409"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Guadalupe-Mountains-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Guadalupe-Mountains-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Haleakala-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Haleakala-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Hawaii-Volcanoes-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Hawaii-Volcanoes-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Hot-Springs-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Hot-Springs-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Indiana-Dunes-National-Lakeshore.png" data-size="720x429"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Indiana-Dunes-National-Lakeshore-thumbnail.png" alt="" width="720" height="429"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Isle-Royale-National-Park.png" data-size="720x501"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Isle-Royale-National-Park-thumbnail.png" alt="" width="720" height="501"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Joshua-Tree-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Joshua-Tree-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Katmai-National-Park-and-Preserve.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Katmai-National-Park-and-Preserve-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Kenai-Fjords-National-Park.png" data-size="720x753"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Kenai-Fjords-National-Park-thumbnail.png" alt="" width="720" height="753"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Kings-Canyon-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Kings-Canyon-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Kobuk-Valley-National-Park.png" data-size="720x808"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Kobuk-Valley-National-Park-thumbnail.png" alt="" width="720" height="808"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Lake-Clark-National-Park-and-Preserve.png" data-size="720x753"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Lake-Clark-National-Park-and-Preserve-thumbnail.png" alt="" width="720" height="753"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Lassen-Volcanic-National-Park.png" data-size="720x753"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Lassen-Volcanic-National-Park-thumbnail.png" alt="" width="720" height="753"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Mammoth-Cave-National-Park.png" data-size="720x672"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Mammoth-Cave-National-Park-thumbnail.png" alt="" width="720" height="672"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Mesa-Verde-National-Park.png" data-size="720x844"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Mesa-Verde-National-Park-thumbnail.png" alt="" width="720" height="844"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Mount-Rainier-National-Park.png" data-size="720x753"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Mount-Rainier-National-Park-thumbnail.png" alt="" width="720" height="753"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/New-River-Gorge-National-Park-and-Preserve.png" data-size="477x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/New-River-Gorge-National-Park-and-Preserve-thumbnail.png" alt="" width="477" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/North-Cascades-National-Park.png" data-size="720x754"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/North-Cascades-National-Park-thumbnail.png" alt="" width="720" height="754"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Olympic-National-Park.png" data-size="720x623"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Olympic-National-Park-thumbnail.png" alt="" width="720" height="623"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Petrified-Forest-National-Park.png" data-size="687x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Petrified-Forest-National-Park-thumbnail.png" alt="" width="687" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Pinnacles-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Pinnacles-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Redwood-National-and-State-Parks.png" data-size="376x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Redwood-National-and-State-Parks-thumbnail.png" alt="" width="376" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Rocky-Mountain-National-Park.png" data-size="720x753"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Rocky-Mountain-National-Park-thumbnail.png" alt="" width="720" height="753"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Saguaro-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Saguaro-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Sequoia-National-Park.png" data-size="720x564"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Sequoia-National-Park-thumbnail.png" alt="" width="720" height="564"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Shenandoah-National-Park.png" data-size="530x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Shenandoah-National-Park-thumbnail.png" alt="" width="530" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Theodore-Roosevelt-National-Park.png" data-size="720x753"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Theodore-Roosevelt-National-Park-thumbnail.png" alt="" width="720" height="753"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/United-States-Virgin-Islands.png" data-size="520x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/United-States-Virgin-Islands-thumbnail.png" alt="" width="520" height="864"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Voyageurs-National-Park.png" data-size="720x754"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Voyageurs-National-Park-thumbnail.png" alt="" width="720" height="754"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/White-Sands-National-Park.png" data-size="720x577"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/White-Sands-National-Park-thumbnail.png" alt="" width="720" height="577"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Wind-Cave-National-Park.png" data-size="720x753"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Wind-Cave-National-Park-thumbnail.png" alt="" width="720" height="753"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Wrangell-St.-Elias-National-Park-and-Preserve.png" data-size="720x688"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Wrangell-St.-Elias-National-Park-and-Preserve-thumbnail.png" alt="" width="720" height="688"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Yellowstone-National-Park.png" data-size="720x769"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Yellowstone-National-Park-thumbnail.png" alt="" width="720" height="769"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Yosemite-National-Park.png" data-size="720x752"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Yosemite-National-Park-thumbnail.png" alt="" width="720" height="752"></a></figure>
<figure class="gallery__item"><a href="https://phileasdg.github.io/media/posts/52/gallery/Zion-National-Park.png" data-size="671x864"><img loading="lazy" src="https://phileasdg.github.io/media/posts/52/gallery/Zion-National-Park-thumbnail.png" alt="" width="671" height="864"></a></figure>
</div></div>
<h2>Connecting to NASA remote sensing services</h2>
<p>The ESA WorldCover dataset is a great resource for understanding land cover patterns, and luckily for us, we live in a world in which there are many more. Many remote sensing services are available as map tile servers (WMTS), and two of my favourite providers of high quality free remote sensing imagery datasets of this kind, often with global and sometimes even near real time coverage, are Copernicus Marine and NASA GIBS (Global Imagery Browse Services). You can access NASA GIBS remote sensing imagery using the RemoteSensing paclet, which I've previously written about <a href="https://community.wolfram.com/groups/-/m/t/2959942">here</a>. </p>
<p>Suppose our reason for consulting ESA LandCover is that we'd like to better understand human environmental impacts globally. In that case, another dataset I'd recommend consulting is the Anthropogenic Biomes (or "Anthromes") map by Ellis &amp; Ramankutty (2008), which classifies Earth's terrestrial surface by the degree and type of human settlements.</p>
<p>The anthropogenic biomes dataset puts human activity at the center of ecological classification, and that makes it an especially compelling tool to study the Anthropocene. It's also conveniently available through NASA GIBS via the RemoteSensing paclet, among over a thousand other remote sensing datasets. Here's how you can install and use this tool yourself:</p>
<p><em>Run this code to install the paclet:</em></p>
<p><code>PacletInstall["PhileasDazeleyGaist`RemoteSensing`"]</code></p>
<p><em>Once the paclet is installed, it can be loaded like this:</em></p>
<p><code>Needs["PhileasDazeleyGaist`RemoteSensing`"]</code></p>
<p><em>Use the RemoteSensing paclet to fetch a map of anthropogenic biomes of the world (Ellis &amp; Ramankutty, 2008):</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/52/Screenshot-2026-01-10-at-11.46.15.png" alt="" width="1252" height="1000" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.46.15-xs.png 300w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.46.15-sm.png 480w ,https://phileasdg.github.io/media/posts/52/responsive/Screenshot-2026-01-10-at-11.46.15-md.png 768w"></figure>
<h2>Sources Cited</h2>
<p>WorldCover 2020 v100: Zanaga, D., Van De Kerchove, R., De Keersmaecker, W., Souverijns, N., Brockmann, C., Quast, R., Wevers, J., Grosu, A., Paccini, A., Vergnaud, S., Cartus, O., Santoro, M., Fritz, S., Georgieva, I., Lesiv, M., Carter, S., Herold, M., Li, Linlin, Tsendbazar, N.E., Ramoino, F., Arino, O., 2021. ESA WorldCover 10 m 2020 v100. <a href="https://doi.org/10.5281/zenodo.5571936">https://doi.org/10.5281/zenodo.5571936 </a><br>Ellis, Erle C., and Navin Ramankutty. 2008. Putting People in the Map: Anthropogenic Biomes of the World. https://doi.org/10.1890/070062.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Computational Plant Ecology: Interactive Spatial Network Analysis of a College Garden</title>
        <author>
            <name>Phileas Dazeley-Gaist</name>
        </author>
        <link href="https://phileasdg.github.io/computational-plant-ecology-interactive-spatial-network-analysis-of-a-college-garden/"/>
        <id>https://phileasdg.github.io/computational-plant-ecology-interactive-spatial-network-analysis-of-a-college-garden/</id>
        <media:content url="https://phileasdg.github.io/media/posts/49/banner.png" medium="image" />
            <category term="Wolfram Language"/>
            <category term="Network Science"/>
            <category term="Modelling"/>
            <category term="Geography &amp; GIS"/>
            <category term="Environmental Science"/>
            <category term="Ecology"/>
            <category term="Complex Systems"/>

        <updated>2025-08-22T20:06:57-04:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://phileasdg.github.io/media/posts/49/banner.png" alt="" />
                    Note: This post was originally a short technical article I shared on&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://phileasdg.github.io/media/posts/49/banner.png" class="type:primaryImage" alt="" /></p>
                <p><strong>Note:</strong> This post was originally a short technical article I shared on the Wolfram Community forum. For an interactive experience with live code or to download this text alongside the source code, please visit the original post <a href="https://community.wolfram.com/groups/-/m/t/3535315">here</a>. </p><h2 id="introduction">Introduction</h2>
<p>About a year ago, a student at College of the Atlantic reached out to me for advice on a capstone project. She was interested in using Wolfram Language to make an interactive map of the college’s Sunken Garden, and exhibiting it as a kind of art installation. To help get her get started, I traced a <a href="https://www.coa.edu/live/files/841-appendix-1-sunken-garden-brochure-pdf">map of the garden</a> using the image Coordinates tool in a Wolfram Notebook and made two data representations of the garden: a point cloud of plant locations by species and a network of the garden’s paths.</p><p>Although her project ended up taking a different direction, the idea stuck with me. After stumbling upon the files recently I was inspired to see if I could build the representations I had made into a fully interactive map. Over the weekend, I dusted off this old notebook and got to work figuring out:</p><ol>
<li><p>What interesting things can be said about the garden data?</p></li>
<li><p>What kind of interactions and interfaces to the data would feel compelling to a general audience interested in the Sunken Garden.</p></li>
<li><p>How to package and deploy this experience as a website.</p></li>
</ol>
<p>This post is a short reflection on that process, and how I used Wolfram to prototype and design the final website, which you can visit <a href="https://phileasdg.github.io/coa-sunken-garden/">here</a>, or read along to discover bit by bit.</p><h2 id="sketching-a-digital-garden">Sketching a digital garden</h2>
<p>The first step was to import a copy of the <a href="https://www.coa.edu/live/files/841-appendix-1-sunken-garden-brochure-pdf">map from the brochure</a>:</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/49/0ockt0ex1876r.png" alt="" width="200" height="undefined" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/0ockt0ex1876r-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0ockt0ex1876r-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0ockt0ex1876r-md.png 768w"></figure><p>I traced the map image twice: once for plant label coordinates, and once for a rough sample of points along the garden path using the image Coordinates tool described in <a href="https://reference.wolfram.com/language/workflow/GetCoordinatesFromAnImage.html">this tutorial</a> (and I later found <a href="https://mathematica.stackexchange.com/questions/214497/making-a-graph-or-network-interactively-over-an-image">this one too</a>). It was a surprisingly meditative experience. I grouped points corresponding to the same species together, and constructed a network representation of the garden path based on my path point sample. I was left with a dataset of plant positions, and a path network.</p><p>Here’s a preview of the plant positions data:</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/1mp0w9zxnu82m.png" alt="" width="250" height="undefined" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1mp0w9zxnu82m-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1mp0w9zxnu82m-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1mp0w9zxnu82m-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/Screenshot-2025-09-13-at-20.43.44.png" alt="Image description" width="300" height="undefined" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.43.44-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.43.44-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.43.44-md.png 768w"></figure><p>Here’s the original map with digital labels:</p><pre><code class="language-wl">In[]:= With[
   {cf = ColorData[91], plantLabels = Normal[plantPositions]}, 
   {colors = cf /@ Range[Length[#]] &amp;@Keys[plantLabels]}, 
   Labeled[HighlightImage[garden, Thread[{colors, Values[plantLabels]}]],SwatchLegend[##, LegendLayout -&gt; {&quot;Column&quot;, 2}] &amp; @@ {colors, Keys[plantLabels]}, Right] 
  ]
</code></pre>
<figure class="post__image"><img src="https://phileasdg.github.io/media/posts/49/1vekqgrzks5j4.png" alt="" width="1492" height="1224" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1vekqgrzks5j4-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1vekqgrzks5j4-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1vekqgrzks5j4-md.png 768w"></figure><p>And here’s the network representation of the path:</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/1kzout3gawhly.png" alt="" width="329" height="216" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1kzout3gawhly-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1kzout3gawhly-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1kzout3gawhly-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/0s66s0ibad5d5.png" alt="" width="562" height="864" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/0s66s0ibad5d5-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0s66s0ibad5d5-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0s66s0ibad5d5-md.png 768w"></figure><h2 id="investigating-the-structure-of-the-digital-garden">Investigating the structure of the digital garden</h2>
<p>Now that I have these computational representations of the garden, I can use them to answer pretty cool conceptual questions about the data. For example:</p><ul>
<li><p>On a long random walk through the garden, where am I likely to spend most of my time?</p></li>
<li><p>To what extent can I simplify the path network without losing the essence of the path’s design and overall pattern? </p></li>
<li><p>What communities do the garden plants form with their neighbors at different scales?</p></li>
</ul>
<h3 id="wandering-about-the-garden">Wandering about the garden</h3>
<h4 id="taking-random-walks">Taking random walks</h4>
<p>If I were to walk the garden path randomly or according to some method, I might like to know where I’m most likely to end up after some time. It turns out that this sort of thing is quite easy to simulate assuming that my heuristics for deciding where to go can be well approximated by deterministic or probabilistic rules (and they usually can).</p><p>For example, if I walked the path completely at random, I could describe my walk as an algorithm: “Before I take my next step, I’ll choose a random direction along the path.” It turns out that when we aimlessly wander along garden paths, this specific algorithm does not capture what we do well as it results in a high probability of backtracking. In practice, when wandering about a garden, we are much more likely to follow the direction we started with than we are to backtrack. A better algorithmic approximation would be to say that we walk randomly but only allow ourselves to backtrack when we’ve reached a dead end. </p><p>Here’s a simulation of such a random walk on the garden path network:</p><pre><code class="language-wl">In[]:= ListAnimate[
   With[{n = 100}, Map[
     HighlightGraph[gardenPath, Style[Last[#], StandardGreen], VertexSize -&gt; .5] &amp;, 
     NestList[
      Apply[{#2, RandomChoice[
           With[{possibleNextSteps = VertexOutComponent[gardenPath, #2, {1}]}, 
            If[
             VertexDegree[gardenPath, #2] &gt; 1, 
             Complement[VertexOutComponent[gardenPath, #2, {1}], {#1}],
             possibleNextSteps]]]} &amp;, #] &amp;, 
      {Null, 1}, n]]], 
   AnimationRunning -&gt; False, AnimationTimeIndex -&gt; 5, DefaultDuration -&gt; 10]
</code></pre>
<figure class="post__image"><img src="https://phileasdg.github.io/media/posts/49/randomwalk.gif" alt="" width="569" height="864"></figure><p>Okay, so if I were to randomly wander around the garden for a long time, never backtracking, what locations along the path am I likely to spend most of my time in? </p><p>To estimate an answer to this question, we can take a sample of simulated random non-backtracking walks through the garden, and tally the number of visits to each location. We should make the additional assumption that the walks start at one of the garden entrances, chosen at random. Here’s what that looks like with the tallies represented as the sizes of the nodes on the garden path network:</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/1rxncra20r6yl.png" alt="" width="2358" height="1488" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1rxncra20r6yl-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1rxncra20r6yl-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1rxncra20r6yl-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/1ni29au7ly1tt.png" alt="" width="1255" height="948" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1ni29au7ly1tt-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1ni29au7ly1tt-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1ni29au7ly1tt-md.png 768w"></figure><p>Of course, this is an approximation and the results are biased by the specific choices involved in my translation of the continuous real-world path into a discrete network representation. That said, it’s a reasonable approximation, and one that matches my personal experience of leisurely strolling through the garden with no clear direction.</p><h4 id="a-short-statistical-tangent">A short statistical tangent</h4>
<p>Across trajectories, the distribution of path-location visit frequencies looks like this:</p><pre><code class="language-wl">In[]:= Histogram[
   Flatten[Map[Values@*Normal@*Counts, walks]], 
   ChartStyle -&gt; Lighter[StandardBlue, .5]]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/1ndgnsonoyh3f.png" alt="" width="720" height="427" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1ndgnsonoyh3f-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1ndgnsonoyh3f-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1ndgnsonoyh3f-md.png 768w"></figure><p>Here’s a model distribution that fits the observed histogram well:</p><pre><code class="language-wl">In[]:= dist = FindDistribution[Flatten[Map[Values@*Normal@*Counts, walks]]]
</code></pre>
<pre><code class="language-wl">Out[]= MixtureDistribution[{0.798666, 0.201334}, {BenfordDistribution[6], BinomialDistribution[124, 0.0535239]}]
</code></pre>
<p>It can be represented as a piecewise function:</p><pre><code class="language-wl">In[]:= TraditionalForm[PDF[dist, x]]
</code></pre>
<p>Likewise, I can generate histograms of visit frequencies for specific locations in the garden:</p><pre><code class="language-wl">In[]:= Dataset[Dataset[KeySort@DeleteMissing[Normal[Transpose[Dataset[Map[Counts, walks]]]], \[Infinity]]][All, Histogram[#, ChartStyle -&gt; Lighter[StandardBlue, .5]] &amp;], MaxItems -&gt; 4]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/08x6b11a9yb4b.png" alt="" width="362" height="720" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/08x6b11a9yb4b-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/08x6b11a9yb4b-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/08x6b11a9yb4b-md.png 768w"></figure><p>And I can estimate fit distributions to the histograms for each location:</p><pre><code class="language-wl">In[]:= Dataset[Dataset[KeySort@DeleteMissing[Normal[Transpose[Dataset[Map[Counts, walks]]]], \[Infinity]]][All, FindDistribution], MaxItems -&gt; 4]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/Screenshot-2025-09-13-at-20.49.05.png" alt="Image description" width="2086" height="284" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.05-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.05-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.05-md.png 768w"></figure><p>Since these distributions are not normal, we can use the median as our measure of central tendency:</p><pre><code class="language-wl">In[]:= Dataset[Dataset[KeySort@Map[Values, GroupBy[Flatten[Map[Normal@*Counts, walks]], First]]][All, Median], MaxItems -&gt; 4]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/Screenshot-2025-09-13-at-20.49.35.png" alt="Image description" width="250" height="undefined" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.35-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.35-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.49.35-md.png 768w"></figure><h3 id="the-skeleton-of-the-garden-path">The skeleton of the garden path</h3>
<p>That statistical dive in the last section was helpful for getting a sense of the network’s structure, but it also made me curious about something else: what happens if we start stripping it down to its bones? We have this detailed representation of every path junction and connection, but how much of that complexity is actually doing any work? </p><p>How much can I simplify the network without damaging the pattern? This is pretty subjective, as we don’t all agree on what might qualify as a destructive act, or what ought to be preserved in the first place. I’ve chosen to consider distances along the path to be unimportant, but the cycles on the path to be fundamental. </p><p>There are 21 cycles in the network. Each cycle is made up of a set of edges on the network, and for every cycle, the edge cycle matrix provides the list of these edges.</p><pre><code class="language-wl">In[]:= With[{m = EdgeCycleMatrix[gardenPath]}, 
   ArrayPlot[m, FrameTicks -&gt; True, PlotLegends -&gt; Automatic, ImageSize -&gt; Medium, PlotLabel -&gt; Text[Style[&quot;Edge cycle matrix of the garden path network:&quot;, 14]]] 
  ]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/122y8z9xg3lkd.png" alt="" width="793" height="266" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/122y8z9xg3lkd-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/122y8z9xg3lkd-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/122y8z9xg3lkd-md.png 768w"></figure><p>Up to this point I’ve presented the garden path network with its vertices in positions that match their locations on the garden map, but I can use other layouts. Here it is laid out using a spring embedding method:</p><pre><code class="language-wl">In[]:= Graph[EdgeList[gardenPath]]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/0gbdnpkehdzsx.png" alt="" width="720" height="298" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/0gbdnpkehdzsx-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0gbdnpkehdzsx-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0gbdnpkehdzsx-md.png 768w"></figure><p>The network looks different, but as far as I’m concerned, it’s the same. The patterns that matter to me (the cycles) are preserved. So how might I simplify the network as much as possible while still preserving all the cycles? </p><p>Notice that if distances along the path aren’t important, we can replace any node that has exactly two neighbors with a new edge that goes directly between its neighbors. Essentially, anywhere that we find a connected to exactly two other nodes, we can remove it and directly connect its neighboring nodes. This operation is a form of path pruning that simplifies the network into a kind of ****skeleton representation. The resulting network retains all loop structures but loses path length information. </p><p>To apply this simplification to the network, we must be able to perform two tasks: identifying nodes on the network that have exactly two neighbors, and replacing any such node with an edge between its two neighbors. I’ve implemented this functionality below:</p><pre><code class="language-wl">In[]:= ClearAll[selectTwoNeighborNodes]
 selectTwoNeighborNodes[g_Graph] := Keys[Select[AssociationThread[VertexList[g] -&gt; VertexDegree[g]], # == 2 &amp;]]
</code></pre>
<pre><code class="language-wl">In[]:= ClearAll[deletePassThroughNodes]
 deletePassThroughNodes[g_Graph] := First[NestWhile[{#, First[selectTwoNeighborNodes[#]], Length[selectTwoNeighborNodes[#]]} &amp;@EdgeAdd[VertexDelete[#[[1]], #[[2]]], (UndirectedEdge @@ VertexOutComponent[#[[1]], #[[2]], {1}])] &amp;, {g, First[selectTwoNeighborNodes[g]], Length[selectTwoNeighborNodes[g]]}, TrueQ[Last[#] &gt; 1] &amp;, 1]] /; MemberQ[VertexDegree[g], 2]
</code></pre>
<p>Here’s the simplified path network with a geographic layout:</p><pre><code class="language-wl">In[]:= deletePassThroughNodes[gardenPath]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/1e5ofbtjscfec.png" alt="" width="573" height="864" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1e5ofbtjscfec-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1e5ofbtjscfec-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1e5ofbtjscfec-md.png 768w"></figure><p>And here it is with a spring layout:</p><pre><code class="language-wl">In[]:= Graph[EdgeList[deletePassThroughNodes[gardenPath]]]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/0fjxv0l1wnb10.png" alt="" width="720" height="261" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/0fjxv0l1wnb10-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0fjxv0l1wnb10-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0fjxv0l1wnb10-md.png 768w"></figure><h3 id="spatial-network-community-analysis-of-the-sunken-garden-plants">Spatial network community analysis of the Sunken Garden plants</h3>
<p>Let’s shift from the paths to the plants themselves. Here’s a breakdown of the Sunken Garden’s plant community make-up (the human-designed component):</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/49/1v0p13ny7tbkc.png" alt="" width="2539" height="369" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1v0p13ny7tbkc-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1v0p13ny7tbkc-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1v0p13ny7tbkc-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/0966puyqeqwz7.png" alt="" width="500" height="undefined" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/0966puyqeqwz7-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0966puyqeqwz7-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0966puyqeqwz7-md.png 768w"></figure><p>We’ve been thinking about how people might move through the space, but the plants have spatial relationships of their own: clusters and neighborhoods that form based on proximity, growing conditions, etc. Can we detect these plant communities computationally? How do they change depending on the scale at which we search for them? </p><p>To answer these questions, we need to know how strongly plants interact with each other as a function of their distances from one another. This will vary from plant to plant and between plant pairs as individual plants may prefer to interact with some species above others. Since we don’t have this information readily available but still have the intuition that the degree of interaction between plants is somewhat a function of the distance between them, I’m going to make an obviously wrong assumption that will still turn out to be instructive: That the amount of interaction between any two plants decreases linearly as a function of mutual distance, and that the slope and y intercept are the same across plants. </p><p>Botanists, suspend your disbelief! But you’re right to ask: why should we decide to make this assumption, especially if we expect it to be inaccurate? The answer is that although it flattens the world and its complexity somewhat, it’s about to allow us to tease out some other interesting properties of the network of plants in the garden.</p><p>Let’s imagine that our assumption is true: That the amount of interaction that happens between any two plants is described by the same linear function of the distance between the plants. In that case, to model the network of interactions between plants at a spatial scale $r$, we can simply imagine disks of radius $r$ centered at every plant and take note of which nodes fall inside what disks. Wherever a plant finds itself in a disk, we assess that the plant is close enough to its neighbor at the center of the disk for them to interact in some way. When two plants interact at a designated scale, we draw a link between them, building a model spatial network of the Sunken Garden’s plant interactions.</p><p>Here’s an interactive demonstration of the process:</p><pre><code class="language-wl">In[]:= Manipulate[
   Show[
    garden, 
    With[
     {g = NearestNeighborGraph[#, {All, N[172/10]*radius}] &amp;@Flatten[Values[Normal[plantPositions]], 1]}, 
     With[
      {labelRules = ((Thread[Keys[#1] -&gt; Callout @@@ #1] &amp;)[Flatten[Thread /@ Reverse /@ Normal[Normal[plantPositions]]]])},
      {edges = EdgeList[g] /. labelRules}, 
      Graph[Values[labelRules], edges, VertexCoordinates -&gt; Thread[Values[Association[labelRules]] -&gt; GraphEmbedding[g]], EdgeStyle -&gt; Thick] 
     ] 
    ]], {{radius, 5}, 0, 10}, SaveDefinitions -&gt; True]
</code></pre>
<figure class="post__image"><img src="https://phileasdg.github.io/media/posts/49/1rs758hzqi6w9.gif" alt="" width="500" height="undefined"></figure><p>Since we can now estimate spatial networks of plant interactions based on distance, we can also apply community detection methods to these networks to make estimates of where interactions concentrate in the network at different scales:</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/0ydgmlj7ow2fk.png" alt="" width="2014" height="726" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/0ydgmlj7ow2fk-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0ydgmlj7ow2fk-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0ydgmlj7ow2fk-md.png 768w"></figure><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/49/1betucekiu8z2.gif" alt="" width="500" height="undefined"></figure><p>This spatial network analysis reveals how the Sunken Garden’s plant communities might emerge at different interaction scales. For radii under approximately 1.75 feet, there are no detected communities, as no plants are within that distance of one another. At radii between two and three feet, we see tightly clustered micro-communities. For radii between four and five feet, we find medium-sized communities that overlap meaningfully with the intentional design and pattern of the garden. At this scale, the garden path seems to contribute to delineating the community structure. As we increase the interaction radius to six to ten feet, these smaller communities merge. For a radius of ten feet, there are four detected communities, two of which cover the majority of the garden:</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/0zb92jxye00nb.png" alt="" width="500" height="undefined" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/0zb92jxye00nb-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0zb92jxye00nb-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0zb92jxye00nb-md.png 768w"></figure><p>The modularity-based community detection shows that even under our simplified assumption of uniform distance-based interactions, the garden shows clear spatial clustering that changes meaningfully with scale. At intermediate scales, the communities appear to align with the garden’s major design elements—the central beds, perimeter plantings, and transitional zones.</p><p>Of course, our linear distance model is a deliberate oversimplification. In reality, plant interactions depend on species compatibility, root systems, light requirements, soil preferences, and many other factors that vary between species pairs. Some plants are natural companions that thrive in close proximity, while others compete aggressively or have allelopathic effects on their neighbors.</p><p>Despite these limitations, the spatial community analysis shows how computational methods can reveal organizational patterns in designed landscapes that might not be immediately apparent. The scale-dependent nature of the detected communities suggests that the Sunken Garden operates as a multi-layered spatial system. The alignment of intermediate-scale communities with major design elements reflects the fact that the garden’s layout creates natural zones of interaction.</p><h3 id="plant-data-analysis">Plant data analysis</h3>
<p>I reached out to some contacts at the college for information about the garden plants that I could add to the garden website. [<strong>Name</strong>], the current Sunken Garden curator shared a species information booklet he wrote with me, the Edible Plant List of the Sunken Garden, which contained all sorts of helpful information about the plants. I used OCR alongside a mix of methods to extract the data from the booklet, and convert them to a JSON dataset, which I’ve reproduced here:</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/49/0krwxhsw9rjxb.png" alt="" width="831" height="39" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/0krwxhsw9rjxb-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0krwxhsw9rjxb-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0krwxhsw9rjxb-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/Screenshot-2025-09-13-at-20.50.42.png" alt="Image description" width="1882" height="636" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.50.42-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.50.42-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/Screenshot-2025-09-13-at-20.50.42-md.png 768w"></figure><p>The dataset contains detailed information about 56 plant species in the Sunken Garden, including their Latin names, families, growing requirements, physical characteristics, and seasonal information.</p><p>The data reveal clear patterns in plant selection. Most species are adaptable to varying light conditions:</p><pre><code class="language-wl">In[]:= Dataset[ReverseSort@KeyMap[First, Normal[Counts[Values[Dataset[ConstructColumns[plantData, &quot;sun&quot;]]]]]]]
</code></pre>
<table>
<thead>
<tr>
<th>Full sun to partial shade</th>
<th>Partial shade to full shade</th>
<th>Full sun</th>
<th>Partial shade</th>
</tr>
</thead>
<tbody><tr>
<td>32</td>
<td>13</td>
<td>8</td>
<td>3</td>
</tr>
</tbody></table>
<p>The tally of plant water requirements show a similar preference for adaptable species:</p><pre><code class="language-wl">In[]:= Dataset[ReverseSort@KeyMap[First, Normal[Counts[Values[Dataset[ConstructColumns[plantData, &quot;water&quot;]]]]]]]
</code></pre>
<table>
<thead>
<tr>
<th>Medium</th>
<th>Medium to wet</th>
<th>Dry to medium</th>
<th>Low</th>
</tr>
</thead>
<tbody><tr>
<td>38</td>
<td>11</td>
<td>6</td>
<td>1</td>
</tr>
</tbody></table>
<p>Plant heights cluster around smaller values, with almost all species under 10 feet, and most 5 feet or under:</p><pre><code class="language-wl">In[]:= Histogram[Flatten[Normal[Values[Dataset[ConstructColumns[plantData, {
         &quot;height&quot; -&gt; Function[Around[Mean[#], Mean[#] - Last[#]] &amp;@ToExpression[
             &quot;{&quot; &lt;&gt; StringReplace[#&quot;height&quot;, {&quot; to &quot; -&gt; &quot;,&quot;, &quot; feet&quot; | &quot;foot&quot; -&gt; &quot;&quot;}] &lt;&gt; &quot;}&quot;]]}]]]]], 
   PlotRange -&gt; Full, ChartStyle -&gt; Lighter[StandardBlue]]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/02ft24cmj2pt4.png" alt="" width="720" height="449" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/02ft24cmj2pt4-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/02ft24cmj2pt4-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/02ft24cmj2pt4-md.png 768w"></figure><p>Spread values show a similar pattern, with most plants staying compact:</p><pre><code class="language-wl">In[]:= Histogram[Flatten[Normal[Values[Dataset[ConstructColumns[plantData, {
         &quot;spread&quot; -&gt; Function[Around[Mean[#], Mean[#] - Last[#]] &amp;@ToExpression[
             &quot;{&quot; &lt;&gt; StringReplace[#&quot;spread&quot;, {&quot; to &quot; -&gt; &quot;,&quot;, &quot; feet&quot; | &quot;foot&quot; -&gt; &quot;&quot;}] &lt;&gt; &quot;}&quot;]]}]]]]], 
   PlotRange -&gt; Full, ChartStyle -&gt; Lighter[StandardBlue]]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/1n0e1h3g3zydg.png" alt="" width="720" height="449" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1n0e1h3g3zydg-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1n0e1h3g3zydg-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1n0e1h3g3zydg-md.png 768w"></figure><p>Height and spread scatter plot with a LOESS fit:</p><pre><code class="language-wl">In[]:= ListFitPlot[Normal[Values[Dataset[ConstructColumns[plantData, {
        &quot;height&quot; -&gt; Function[Around[Mean[#], Mean[#] - Last[#]] &amp;@ToExpression[
            &quot;{&quot; &lt;&gt; StringReplace[#&quot;height&quot;, {&quot; to &quot; -&gt; &quot;,&quot;, &quot; feet&quot; | &quot;foot&quot; -&gt; &quot;&quot;}] &lt;&gt; &quot;}&quot;]], 
        &quot;spread&quot; -&gt; Function[Around[Mean[#], Mean[#] - Last[#]] &amp;@ToExpression[
            &quot;{&quot; &lt;&gt; StringReplace[#&quot;spread&quot;, {&quot; to &quot; -&gt; &quot;,&quot;, &quot; feet&quot; | &quot;foot&quot; -&gt; &quot;&quot;}] &lt;&gt; &quot;}&quot;]]}]]]], 
   PlotRange -&gt; Full, PlotFit -&gt; &quot;Local&quot;, PlotFitElements -&gt; &quot;BandCurves&quot;]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/0ifdxwc5akzzx.png" alt="" width="720" height="458" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/0ifdxwc5akzzx-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/0ifdxwc5akzzx-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/0ifdxwc5akzzx-md.png 768w"></figure><p>The plant data analysis confirms that the Sunken Garden prioritizes adaptable, compact species that do well in variable conditions.</p><h2 id="packaging-and-deploying-a-website">Packaging and deploying a website</h2>
<p>The primary goal was always to create an accessible digital companion for garden visitors. The website allows people to click on plant locations for detailed species information, click on path nodes to see what plants are within short and medium distance radii of that spot, and toggle between different organizational views (by species, growing requirements, bloom time, and other characteristics).</p><p>The computational analyses presented here emerged from my curiosity about the underlying spatial patterns in this designed landscape. While some insights, like meaningful plant interaction distances, influenced minor interface details, the mathematical investigations are primarily an addendum for visitors interested in exploring the garden through a computational lens. </p><p>Here’s the sunken garden website directory tree:</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/49/1mjnn1jubt0kw.png" alt="" width="1995" height="40" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1mjnn1jubt0kw-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1mjnn1jubt0kw-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1mjnn1jubt0kw-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/1vhdd4pplaj9f.png" alt="" width="1355" height="965" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1vhdd4pplaj9f-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1vhdd4pplaj9f-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1vhdd4pplaj9f-md.png 768w"></figure><p>The website uses a straightforward structure with JSON data files containing the computational representations developed through the Wolfram analysis. The network visualizations use the force-graph library, while most of the implementation work went into defining the logic for different information modals and user interactions. I deployed the site using GitHub Pages for free hosting.</p><h2 id="parting-thoughts">Parting thoughts</h2>
<p>Gardens occupy a middle ground between artificial and natural systems. They blend human intention with processes that operate beyond conscious control. This hybrid status makes them revealing subjects for computational analysis because they illuminate how spatial patterns emerge independent of design intentions.</p><p>When the distance-based community detection occasionally aligns with garden design elements, it raises interesting questions about the relationship between our analytical frameworks and spatial reality. The patterns emerge from specific modeling choices - the distance thresholds we select, the assumption that all plants interact uniformly, the particular community detection algorithm we apply. Yet the occasional alignment with actual design elements suggests these simplified models can still capture meaningful aspects of spatial organization.</p><p>The computational approach offers a way to think systematically about spatial relationships, even when our assumptions are deliberately oversimplified. Gardens provide a useful testing ground for these methods precisely because we can compare analytical results against known design intentions and see where the models succeed or fall short.</p><p>You can explore the interactive map <a href="https://phileasdg.github.io/coa-sunken-garden/">here</a>.</p><h2 id="appendix-code-initializations">Appendix: Code Initializations</h2>
<h3 id="project-variables">Project variables</h3>
<figure class="post__image"><img src="https://phileasdg.github.io/media/posts/49/1phbx87cq593e.png" alt="" width="266" height="216" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/1phbx87cq593e-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/1phbx87cq593e-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/1phbx87cq593e-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/19f9obkqzl49e.png" alt="" width="394" height="40" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/19f9obkqzl49e-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/19f9obkqzl49e-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/19f9obkqzl49e-md.png 768w"></figure><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/49/17sc7czxhzxy4.png" alt="" width="314" height="216" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/17sc7czxhzxy4-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/17sc7czxhzxy4-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/17sc7czxhzxy4-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/49/01wokmrx0usvg.png" alt="" width="765" height="38" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/49/responsive/01wokmrx0usvg-xs.png 300w ,https://phileasdg.github.io/media/posts/49/responsive/01wokmrx0usvg-sm.png 480w ,https://phileasdg.github.io/media/posts/49/responsive/01wokmrx0usvg-md.png 768w"></figure><pre><code class="language-wl">In[]:= walks = With[{
         (*Walk trajectory samples:*) walks = 2000, 
         (*Steps per walk:*) steps = 200, 
         (*Garden entrances:*) startNodes = {1, 6, 64, 69}}, 
        
        Table[Map[Last, NestList[
           Apply[{#2, RandomChoice[
                With[{possibleNextSteps = VertexOutComponent[gardenPath, #2, {1}]}, 
                 If[
                  VertexDegree[gardenPath, #2] &gt; 1, 
                  Complement[VertexOutComponent[gardenPath, #2, {1}], {#1}],
                  possibleNextSteps]]]} &amp;, #] &amp;, 
           {Null, RandomChoice[startNodes]}, steps]], walks] 
        ];
</code></pre>
<pre><code class="language-wl">In[]:= dist = FindDistribution[Flatten[Map[Values@*Normal@*Counts, walks]]];
</code></pre>
<pre><code class="language-wl">In[]:= ClearAll[selectTwoNeighborNodes]
 selectTwoNeighborNodes[g_Graph] := Keys[Select[AssociationThread[VertexList[g] -&gt; VertexDegree[g]], # == 2 &amp;]]
</code></pre>
<pre><code class="language-wl">In[]:= ClearAll[deletePassThroughNodes]
 deletePassThroughNodes[g_Graph] := First[NestWhile[
         {#, First[selectTwoNeighborNodes[#]], Length[selectTwoNeighborNodes[#]]} &amp;@EdgeAdd[VertexDelete[#[[1]], #[[2]]], (UndirectedEdge @@ VertexOutComponent[#[[1]], #[[2]], {1}])] &amp;, 
         {g, First[selectTwoNeighborNodes[g]], Length[selectTwoNeighborNodes[g]]}, TrueQ[Last[#] &gt; 1] &amp;, 1]] /; MemberQ[VertexDegree[g], 2]
</code></pre>
<h3 id="misc-tools">Misc tools</h3>
<h4 id="drawing-blobs">Drawing blobs</h4>
<p>Define a function to draw blobs:</p><pre><code class="language-wl">In[]:= ClearAll[iBlobs]
 iBlobs[style_, pts_, size_] := Block[{epts}, 
       epts = Flatten[Tuples[CoordinateBounds[#, size]] &amp; /@ pts, 1]; 
       {style, FilledCurve@BSplineCurve[
              MeshPrimitives[ConvexHullMesh[epts], 1][[All, 1, 1]], 
              SplineClosed -&gt; True, SplineDegree -&gt; 2]}]
</code></pre>

            ]]>
        </content>
    </entry>
    <entry>
        <title>Terrestrial Ecoregions of the World: Computational Insights Into Global Biodiversity</title>
        <author>
            <name>Phileas Dazeley-Gaist</name>
        </author>
        <link href="https://phileasdg.github.io/terrestrial-ecoregions-of-the-world-computational-insights-into-global-biodiversity/"/>
        <id>https://phileasdg.github.io/terrestrial-ecoregions-of-the-world-computational-insights-into-global-biodiversity/</id>
        <media:content url="https://phileasdg.github.io/media/posts/47/Ecoregions_BannerImage-2.png" medium="image" />
            <category term="Wolfram Language"/>
            <category term="Programming"/>
            <category term="Geography &amp; GIS"/>
            <category term="Environmental Science"/>
            <category term="Ecology"/>
            <category term="Complex Systems"/>

        <updated>2025-08-15T22:21:47-04:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://phileasdg.github.io/media/posts/47/Ecoregions_BannerImage-2.png" alt="" />
                    Note: This post was originally a short technical article I shared on&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://phileasdg.github.io/media/posts/47/Ecoregions_BannerImage-2.png" class="type:primaryImage" alt="" /></p>
                <p><strong>Note:</strong> This post was originally a short technical article I shared on the Wolfram Community forum. For an interactive experience with live code or to download this text alongside the source code, please visit the original post <a href="https://community.wolfram.com/groups/-/m/t/3445374">here</a>. </p><h2 id="introduction">Introduction</h2>
<p>Ecoregions are distinct ecological zones with specific environmental conditions (climate, topography, soil composition…), habitats, and species. Each ecoregion contains characteristic species and ecological communities that are adapted to the region’s environment.</p><p>The Ecoregions2017©Resolve map is a revised version of the widely used 2001 map of terrestrial ecoregions of the world, originally developed by <a href="https://doi.org/10.1641/0006-3568(2001)051%5B0933:TEOTWA%5D2.0.CO;2">Olson et al</a>. The new map breaks up the Earth’s land into 846 distinct terrestrial ecoregions nested within 14 terrestrial <a href="https://en.wikipedia.org/wiki/Biome">biomes</a>. An interactive version of the map is available online <a href="https://ecoregions.appspot.com/">here</a>, and the work is discussed in the following article in BioScience: <a href="https://academic.oup.com/bioscience/article/67/6/534/3102935?login=false">An Ecoregion-Based Approach to Protecting Half the Terrestrial Realm</a> <a href="https://academic.oup.com/bioscience/article/67/6/534/3102935?login=false">(Dinerstein et al. 2017)</a>.</p><p>Terrestrial biomes of the world according to Dinerstein and Olson (also used in the <a href="https://www.worldwildlife.org/publications/global-200">WWF Global 200 classification</a>) already have computational representations in Wolfram Language. Here’s how one might represent them on a map:</p><p><em>Define a list of biomes:</em></p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/47/0svwohkmtobvo.png" alt="" width="2522" height="108" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/0svwohkmtobvo-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0svwohkmtobvo-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0svwohkmtobvo-md.png 768w"></figure><p><em>Produce a map of major world biomes:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/0ufjsmh9hw8yp.png" alt="" width="1262" height="168" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/0ufjsmh9hw8yp-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0ufjsmh9hw8yp-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0ufjsmh9hw8yp-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/13376kglpv3ht.png" alt="" width="1152" height="576" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/13376kglpv3ht-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/13376kglpv3ht-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/13376kglpv3ht-md.png 768w"></figure><p>The Ecoregions2017©Resolve data provide a more detailed ecological classification compared to the broader biome categories. While biomes represent large ecological zones based on similar climate conditions and dominant vegetation types, ecoregions offer finer granularity by incorporating specific environmental conditions, habitats, and species unique to each region.</p><p>Applications for the Ecoregions2017©Resolve include:</p><ul>
<li>Depicting the global distributions of species and ecological communities</li>
<li>Modeling ecological impacts of climate change</li>
<li>Assisting in the development of conservation strategies</li>
<li>Reporting progress toward international conservation targets such as the <a href="https://www.cbd.int/sp/targets">Aichi targets established by the Convention on Biological Diversity</a>.</li>
</ul>
<p>In this short article, I’ll construct a dataset of Ecoregions2017©Resolve data, demonstrate how to create ecoregion maps, apply data science techniques to filter and summarize the data, and make use of the <a href="https://resources.wolframcloud.com/FunctionRepository/resources/INaturalistSearch/">INaturalistSearch</a> function to search for species observations within ecoregions.</p><h2 id="setup">Setup</h2>
<p>The Ecoregions2017©Resolve data are available <a href="https://storage.googleapis.com/teow2016/Ecoregions2017.zip">here</a>, licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a>. Let’s load them in.</p><p>With the zip file downloaded from this page unzipped and copied to my chosen project directory, the data are ready to import.</p><p><em>Import the ecoregion shapefile data:</em></p><pre><code class="language-wl">In[]:= freshwaterEcoregionsShapefileData = Association[Import[(*Path to the shapefile:*)FileNameJoin[{NotebookDirectory[], &quot;2017 Ecoregions&quot;, &quot;Ecoregions2017&quot;, &quot;Ecoregions2017.shp&quot;}], &quot;Data&quot;]];
</code></pre>
<p>In addition to the data found in the shapefile, the online interactive map also includes links to informative ecoregion descriptions hosted on <a href="http://www.oneearth.org">www.oneearth.org</a>. Let’s incorporate these links into our dataset.</p><p><em>Define an association of ecoregion OneEarth pages:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/1imj3zkxicqz0.png" alt="" width="327" height="41" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/1imj3zkxicqz0-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1imj3zkxicqz0-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1imj3zkxicqz0-md.png 768w"></figure><p><em>Wrangle the data to produce a nice tabular dataset:</em></p><pre><code class="language-wl">In[]:= ecoregionsTab = Tabular[Join[
       (*LabeledData columns:*) ## &amp; @@ KeyValueMap[Dataset[Map[Association, Thread[#1 -&gt; #2]]] &amp;, Association[freshwaterEcoregionsShapefileData[&quot;LabeledData&quot;]]],
       (*Geometry column:*) Dataset[Map[&lt;|&quot;Geometry&quot; -&gt; #|&gt; &amp;, freshwaterEcoregionsShapefileData[&quot;Geometry&quot;]]], 2]] // 
     (*Clean up the data and create new columns:*) 
      TransformColumns[#, {
        (*Interpret color data:*) 
         &quot;COLOR&quot; -&gt; (RGBColor[#&quot;COLOR&quot;] &amp;), &quot;COLOR_BIO&quot; -&gt; (RGBColor[#&quot;COLOR_BIO&quot;] &amp;), &quot;COLOR_NNH&quot; -&gt; (RGBColor[#&quot;COLOR_NNH&quot;] &amp;), 
        (*Ecoregion OneEarth page column:*) 
         &quot;OneEarthPage&quot; -&gt; Function[If[KeyMemberQ[ecoregionPages, #&quot;ECO_NAME&quot;], ecoregionPages[#&quot;ECO_NAME&quot;], Missing[&quot;Not available&quot;]]], 
        (*GeoBounds regions column:*) 
         &quot;GeoBoundsRegion&quot; -&gt; Function[GeoBoundsRegion[GeoBounds[#Geometry]]]}] &amp; //(*Update column names:*)RenameColumns[#, {&quot;ObjectID&quot;, &quot;EcoregionName&quot;, &quot;BiomeNumber&quot;, &quot;BiomeName&quot;, &quot;Realm&quot;, &quot;EcoBiome&quot;, &quot;ProtectionStatusID&quot;, &quot;EcoregionID&quot;, &quot;ShapeLength&quot;, &quot;ShapeArea&quot;, &quot;ProtectionStatus&quot;, &quot;EcoregionColor&quot;, &quot;BiomeColor&quot;, &quot;ProtectionStatusColor&quot;, &quot;License&quot;}] &amp;;
</code></pre>
<p>To avoid having to recompute this, I’ll save it to a parquet file and reload the data:</p><p><em>Define the save path :</em></p><pre><code class="language-wl">In[]:= ecoregionsTabPath = FileNameJoin[{NotebookDirectory[], &quot;2017 Ecoregions&quot;, &quot;ecoregions2017.parquet&quot;}];
</code></pre>
<p><em>Save the dataset :</em></p><pre><code class="language-wl">In[]:= Export[ecoregionsTabPath, ecoregionsTab];
</code></pre>
<p><em>Load the data from the file, casting ID columns as machine integers:</em></p><pre><code class="language-wl">In[]:= ecoregionsTab = CastColumns[Import[ecoregionsTabPath], {&quot;ObjectID&quot; -&gt; &quot;MachineInteger&quot;, &quot;BiomeNumber&quot; -&gt; &quot;MachineInteger&quot;, &quot;ProtectionStatusID&quot; -&gt; &quot;MachineInteger&quot;, &quot;EcoregionID&quot; -&gt; &quot;MachineInteger&quot;}]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/01pn8ye1s90is.png" alt="" width="1788" height="595" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/01pn8ye1s90is-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/01pn8ye1s90is-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/01pn8ye1s90is-md.png 768w"></figure><p><em>Inspect the structure of the dataset:</em></p><pre><code class="language-wl">In[]:= TabularStructure[ecoregionsTab]
</code></pre>
<table>
<thead>
<tr>
<th>ColumnKey</th>
<th>ColumnType</th>
<th>NonMissingCount</th>
<th>MissingCount</th>
<th>ByteCount</th>
</tr>
</thead>
<tbody><tr>
<td>ObjectID</td>
<td>Integer64</td>
<td>847</td>
<td>0</td>
<td>7016</td>
</tr>
<tr>
<td>EcoregionName</td>
<td>String</td>
<td>847</td>
<td>0</td>
<td>32271</td>
</tr>
<tr>
<td>BiomeNumber</td>
<td>Integer64</td>
<td>847</td>
<td>0</td>
<td>7016</td>
</tr>
<tr>
<td>BiomeName</td>
<td>String</td>
<td>847</td>
<td>0</td>
<td>37478</td>
</tr>
<tr>
<td>Realm</td>
<td>String</td>
<td>847</td>
<td>0</td>
<td>15195</td>
</tr>
<tr>
<td>EcoBiome</td>
<td>String</td>
<td>847</td>
<td>0</td>
<td>10411</td>
</tr>
<tr>
<td>ProtectionStatusID</td>
<td>Integer64</td>
<td>847</td>
<td>0</td>
<td>7016</td>
</tr>
<tr>
<td>EcoregionID</td>
<td>Integer64</td>
<td>847</td>
<td>0</td>
<td>7016</td>
</tr>
<tr>
<td>ShapeLength</td>
<td>Real64</td>
<td>847</td>
<td>0</td>
<td>7008</td>
</tr>
<tr>
<td>ShapeArea</td>
<td>Real64</td>
<td>847</td>
<td>0</td>
<td>7008</td>
</tr>
<tr>
<td>ProtectionStatus</td>
<td>String</td>
<td>847</td>
<td>0</td>
<td>26600</td>
</tr>
<tr>
<td>EcoregionColor</td>
<td>InertExpression</td>
<td>847</td>
<td>0</td>
<td>102016</td>
</tr>
<tr>
<td>BiomeColor</td>
<td>InertExpression</td>
<td>847</td>
<td>0</td>
<td>102016</td>
</tr>
<tr>
<td>ProtectionStatusColor</td>
<td>InertExpression</td>
<td>847</td>
<td>0</td>
<td>102016</td>
</tr>
<tr>
<td>License</td>
<td>String</td>
<td>847</td>
<td>0</td>
<td>14647</td>
</tr>
<tr>
<td>Geometry</td>
<td>InertExpression</td>
<td>847</td>
<td>0</td>
<td>1471945560</td>
</tr>
<tr>
<td>OneEarthPage</td>
<td>String</td>
<td>844</td>
<td>3</td>
<td>63549</td>
</tr>
<tr>
<td>GeoBoundsRegion</td>
<td>InertExpression</td>
<td>847</td>
<td>0</td>
<td>244312</td>
</tr>
</tbody></table>
<h2 id="exploration">Exploration</h2>
<h3 id="visualizing-terrestrial-ecoregions">Visualizing Terrestrial Ecoregions</h3>
<h4 id="producing-ecoregion-maps">Producing ecoregion maps</h4>
<p>For a start, let’s suppose we’d like to plot the footprint of a specific ecoregion. Here’s one approach:</p><p><em>Extract and plot ecoregion geometry selected from a row in which the “EcoregionName” column matches a provided name:</em></p><pre><code class="language-wl">In[]:= ecoregionsTab // Select[#, Function[#&quot;EcoregionName&quot; == &quot;Irrawaddy moist deciduous forests&quot;]] &amp; // First[Normal[Dataset[#][All, &quot;Geometry&quot;]]] &amp; // GeoGraphics // Rasterize
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/0cg3z0mxchqmk.png" alt="" width="438" height="840" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/0cg3z0mxchqmk-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0cg3z0mxchqmk-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0cg3z0mxchqmk-md.png 768w"></figure><p>In case you’re unfamiliar with the notation, “//“ (called <a href="https://reference.wolfram.com/language/ref/Postfix">PostFix</a>) can be read as “and then”, and is one of the ways one can chain together function calls in Wolfram Language. For new WL users coming form scientific backgrounds, this is quite similar to pipes in Python and R.</p><p>We may also like to plot several ecoregion footprints. This time, let’s assume we’re matching to a list of ecoregion IDs.</p><p><em>Extract and plot ecoregion geometry from rows where the “EcoregionID” column matches one of the IDs in the provided list:</em></p><pre><code class="language-wl">In[]:= ecoregionsTab // Select[#, Function[MemberQ[{649, 695, 812, 815}, #&quot;EcoregionID&quot;]]] &amp; // Normal[Dataset[#][All, 
       (*Extract geometry and ecoregion colors, and add tooltips to the footprints:*) {#EcoregionColor, Tooltip[#Geometry, #EcoregionName]} &amp;]] &amp; // Legended[
     (*Plot the map:*) GeoGraphics[{GeoStyling[Opacity[.6]], #}], 
     (*Construct the legend:*) SwatchLegend[## &amp; @@ {#1, #2[[All, 2]]} &amp; @@ Transpose[#]]] &amp; // Rasterize
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/08u4lj1xmvw3p.png" alt="" width="1112" height="840" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/08u4lj1xmvw3p-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/08u4lj1xmvw3p-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/08u4lj1xmvw3p-md.png 768w"></figure><p>Note that in order to share this article online, I’ve had to rasterize these plots, which disables the tooltips. To enable the tooltips in this notebook, simply download it and delete calls to <a href="https://reference.wolfram.com/language/ref/Rasterize">Rasterize</a>.</p><p>To make a world map of terrestrial ecoregions, we simply include all ecoregions in the plot.</p><p><em>Make a world Ecoregions map:</em></p><pre><code class="language-wl">In[]:= Rasterize[GeoGraphics[{GeoStyling[Opacity[1]], Values[Normal[Dataset[ConstructColumns[ecoregionsTab, {&quot;EcoregionColor&quot;, &quot;Geometry&quot;}]]]]}, GeoProjection -&gt; &quot;Mercator&quot;, GeoBackground -&gt; White], ImageSize -&gt; Full]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/0h58k9z8lkdxs.png" alt="" width="1359" height="1359" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/0h58k9z8lkdxs-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0h58k9z8lkdxs-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0h58k9z8lkdxs-md.png 768w"></figure><h4 id="grouping-and-plotting-ecoregions-programmatically">Grouping and plotting ecoregions programmatically</h4>
<p>You’re likely to want to select many ecoregions at a time according to logical or mathematical criteria. Here are a few examples to get you started:</p><p><em>Find and plot the 3 largest ecoregions:</em></p><pre><code class="language-wl">In[]:= Take[ReverseSortBy[ecoregionsTab, #&quot;ShapeArea&quot; &amp;], {2, 4}] // ConstructColumns[#, {&quot;EcoregionName&quot;, &quot;Geometry&quot;}] &amp; // MapApply[GeoGraphics[#2, PlotLabel -&gt; #1] &amp;, FromTabular[#, &quot;Matrix&quot;]] &amp;
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/0jqvkdooppmyi.png" alt="" width="1137" height="288" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/0jqvkdooppmyi-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0jqvkdooppmyi-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0jqvkdooppmyi-md.png 768w"></figure><p><em>Find and plot all ecoregions within a particular biome:</em></p><pre><code class="language-wl">In[]:= Select[ecoregionsTab, Function[#BiomeName == &quot;Deserts &amp; Xeric Shrublands&quot;]] // Normal[Dataset[#][All, 
       (*Extract geometry and ecoregion colors, and add tooltips to the footprints:*) {#EcoregionColor, Tooltip[#Geometry, #EcoregionName]} &amp;]] &amp; // GeoGraphics[{GeoStyling[Opacity[.6]], #}, ImageSize -&gt; Large] &amp; // Rasterize
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/0jw1vmd4pjcrj.png" alt="" width="1152" height="576" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/0jw1vmd4pjcrj-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0jw1vmd4pjcrj-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0jw1vmd4pjcrj-md.png 768w"></figure><p><em>Find and plot all ecoregions within a particular realm:</em></p><pre><code class="language-wl">In[]:= Select[ecoregionsTab, Function[#Realm == &quot;Indomalayan&quot;]] // Normal[Dataset[#][All, 
       (*Extract geometry and ecoregion colors, and add tooltips to the footprints:*) {#EcoregionColor, Tooltip[#Geometry, #EcoregionName]} &amp;]] &amp; // GeoGraphics[{GeoStyling[Opacity[.6]], #}, ImageSize -&gt; Large] &amp; // Rasterize
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/19q26rrj2pve0.png" alt="" width="1152" height="673" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/19q26rrj2pve0-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/19q26rrj2pve0-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/19q26rrj2pve0-md.png 768w"></figure><p><em>Find and plot all ecoregions whose names contain the word “forest”:</em></p><pre><code class="language-wl">In[]:= Select[ecoregionsTab, Function[StringContainsQ[ToLowerCase[#EcoregionName], &quot;forest&quot;]]] // Normal[Dataset[#][All, 
       (*Extract geometry and ecoregion colors, and add tooltips to the footprints:*) {#EcoregionColor, Tooltip[#Geometry, #EcoregionName]} &amp;]] &amp; // GeoGraphics[{GeoStyling[Opacity[.6]], #}, ImageSize -&gt; Large, GeoCenter -&gt; {0, 0}] &amp; // Rasterize
</code></pre>
<figure class="post__image"><img src="https://phileasdg.github.io/media/posts/47/1jt8yiqx0ov1y.png" alt="" width="1152" height="576" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/1jt8yiqx0ov1y-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1jt8yiqx0ov1y-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1jt8yiqx0ov1y-md.png 768w"></figure><p><em>Plot protection status of neotropic tropical and subtropical moist broadleaf forests:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/1r87ybh8686m1.png" alt="" width="2789" height="212" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/1r87ybh8686m1-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1r87ybh8686m1-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1r87ybh8686m1-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/0jl3eszfxz97s.png" alt="" width="1307" height="738" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/0jl3eszfxz97s-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0jl3eszfxz97s-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0jl3eszfxz97s-md.png 768w"></figure><h4 id="bonus-ecoregion2017-geoservers"><em>Bonus: Ecoregion2017 GeoServers</em></h4>
<p>For larger maps, assuming you’d like to include every ecoregion in your map’s geographic range, you may elect to connect to one of the Ecoregions2017 GeoServer services for your plotting. This is generally faster.</p><p><em>Construct a dataset of Ecoregions2017 GeoServers:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/060qitwoevl7m.png" alt="" width="1365" height="85" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/060qitwoevl7m-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/060qitwoevl7m-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/060qitwoevl7m-md.png 768w"></figure><p><em>Create world maps for each GeoServer:</em></p><pre><code class="language-wl">In[]:= Dataset[GeoGraphics[&quot;World&quot;, GeoServer -&gt; #, GeoZoomLevel -&gt; 1] &amp; /@ ecoGeoServers]
</code></pre>
<figure class="post__image"><img src="https://phileasdg.github.io/media/posts/47/1jgp7saxb9n8n.png" alt="" width="1399" height="1360" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/1jgp7saxb9n8n-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1jgp7saxb9n8n-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1jgp7saxb9n8n-md.png 768w"></figure><p><em>Define the Legends for each map type:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/1pt735is35rm6.png" alt="" width="507" height="41" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/1pt735is35rm6-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1pt735is35rm6-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1pt735is35rm6-md.png 768w"></figure><h4 id="fetching-ecoregion-images">Fetching ecoregion images</h4>
<p>The ecoregion descriptions hosted on <a href="http://www.oneearth.org">www.oneearth.org</a> contain illustrative of ecoregion landscapes and emblematic wildlife. Let’s define a function to fetch these images programmatically:</p><p><em>Define a function to collect ecoregion images:</em></p><pre><code class="language-wl">In[]:= ClearAll[ecoregionImages] 
  (*OneEarth page URL input:*)
 ecoregionImages[ecoregionOneEarthPage_URL] := Dataset[Join[
     (*Import ecoregion page header images (typically landscapes):*) 
      Cases[
       Import[ecoregionOneEarthPage, &quot;XMLObject&quot;], XMLElement[&quot;img&quot;, {&quot;src&quot; -&gt; url_, &quot;alt&quot; -&gt; description_, &quot;data-image&quot; -&gt; &quot;data-image&quot;, &quot;v-imageloaded&quot; -&gt; &quot;v-imageloaded&quot;}, _] :&gt; &lt;|&quot;Image&quot; -&gt; Import[url], &quot;ImageDescription&quot; -&gt; description|&gt;, {17}], 
     (*Import ecoregion page body images (typically animals or landscapes):*) 
      Cases[
       Import[ecoregionOneEarthPage, &quot;XMLObject&quot;], XMLElement[&quot;figure&quot;, {}, {XMLElement[&quot;img&quot;, {&quot;src&quot; -&gt; url_}, {}], XMLElement[&quot;figcaption&quot;, {}, {XMLElement[&quot;span&quot;, {&quot;class&quot; -&gt; &quot;caption&quot;}, {}], XMLElement[&quot;p&quot;, {}, {description_}], &quot; &quot;}]}] :&gt; &lt;|&quot;Image&quot; -&gt; Import[url], &quot;ImageDescription&quot; -&gt; description|&gt;, \[Infinity]] 
     ]] 
   
  (*Ecoregion name input:*)
 ecoregionImages[ecoregionName_String] := ecoregionImages[URL[First[Values[Normal[First[
          ConstructColumns[Select[ecoregionsTab, Function[#EcoregionName == ecoregionName]], &quot;OneEarthPage&quot;]]]]]]] 
   
  (*ID input:*)
 ecoregionImages[ecoregionID_Integer] := ecoregionImages[URL[First[Values[Normal[First[
         ConstructColumns[Select[ecoregionsTab, Function[#EcoregionID == ecoregionID]], &quot;OneEarthPage&quot;]]]]]]]
</code></pre>
<p><em>Fetch images for a specified ecoregion, along with their descriptions:</em></p><pre><code class="language-wl">In[]:= ecoregionImages[&quot;Myanmar coastal rain forests&quot;]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/0apewhueieqfw.png" alt="" width="1359" height="507" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/0apewhueieqfw-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0apewhueieqfw-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0apewhueieqfw-md.png 768w"></figure><h3 id="searching-for-inaturalist-species-observations-within-ecoregions">Searching for iNaturalist Species Observations Within Ecoregions</h3>
<p>Finally, here’s an example showing one way you might use the ecoregions data explored in this text in combination with other Wolfram Language ecology functionality. </p><p>iNaturalist is a citizen science project and online community of naturalists, biologists, and ordinary people who record and share observations of plants, animals, and other life forms. Users can upload photos and sounds, identify species, and contribute to a global biodiversity database.</p><p>Observations shared to the iNaturalist platform can be retrieved using the <a href="https://resources.wolframcloud.com/FunctionRepository/resources/INaturalistSearch/">INaturalistSearch</a> function from the Wolfram Function Repository. Let’s use this function to fetch species observations from an specified ecoregion.</p><p><em>Define the region in which to search for observations:</em></p><pre><code class="language-wl">In[]:= region = GeoGroup[Normal[First[Select[ecoregionsTab, Function[#&quot;EcoregionName&quot; == &quot;Puerto Rican moist forests&quot;]]]][&quot;Geometry&quot;]];
</code></pre>
<p><em>Plot this region on a map:</em></p><pre><code class="language-wl">In[]:= GeoGraphics[region] // Rasterize
</code></pre>
<figure class="post__image"><img src="https://phileasdg.github.io/media/posts/47/090jv8xpyxzy7.png" alt="" width="840" height="369" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/090jv8xpyxzy7-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/090jv8xpyxzy7-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/090jv8xpyxzy7-md.png 768w"></figure><p><em>Fetch observations made within this region and within a specified date range (here, set to the last 10 days at time of computation):</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/1uroqt2g1edge.png" alt="" width="2339" height="103" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/1uroqt2g1edge-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/1uroqt2g1edge-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/1uroqt2g1edge-md.png 768w"></figure><p><em>Extract the positions and species names from the resulting dataset, and plot them on a map:</em></p><pre><code class="language-wl">In[]:= GeoListPlot[Flatten[FromTabular[ConstructColumns[observations, &quot;LabeledPosition&quot; -&gt; Function[Labeled[#&quot;GeoPosition&quot;, #&quot;TaxonName&quot;]]], &quot;Matrix&quot;]], ImageSize -&gt; 850] // Rasterize
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/47/0tp97ku72duyh.png" alt="" width="1173" height="515" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/47/responsive/0tp97ku72duyh-xs.png 300w ,https://phileasdg.github.io/media/posts/47/responsive/0tp97ku72duyh-sm.png 480w ,https://phileasdg.github.io/media/posts/47/responsive/0tp97ku72duyh-md.png 768w"></figure><h2 id="conclusion">Conclusion</h2>
<p>The Ecoregions2017©Resolve dataset lets us explore the incredible variety of ecosystems around the globe. By breaking down Earth’s landscapes into distinct ecological zones, it gives us a fresh perspective on Earth’s diverse habitats and the species that inhabit them. Whether you’re interested in research, conservation, or simply appreciating the beauty and complexity of life on Earth, this dataset offers a clear and engaging way to use computation to explore questions  about ecology, biodiversity, and environmental science.</p><h2 id="cite-this-work">Cite this work</h2>
<p><a href="https://community.wolfram.com/groups/-/m/t/3445374">Terrestrial ecoregions of the world: computational insights into global biodiversity</a>
by <a href="https://community.wolfram.com/web/phileasdg">Phileas Dazeley-Gaist</a>
Wolfram Community, STAFF PICKS, April 17, 2025
<a href="https://community.wolfram.com/groups/-/m/t/3445374">https://community.wolfram.com/groups/-/m/t/3445374</a></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Trading Places: a Network Analysis of Global Commerce</title>
        <author>
            <name>Phileas Dazeley-Gaist</name>
        </author>
        <link href="https://phileasdg.github.io/trading-places-a-network-analysis-of-global-commerce/"/>
        <id>https://phileasdg.github.io/trading-places-a-network-analysis-of-global-commerce/</id>
        <media:content url="https://phileasdg.github.io/media/posts/46/world_trade_banner.png" medium="image" />
            <category term="Work at Wolfram"/>
            <category term="Wolfram Language"/>
            <category term="Programming"/>
            <category term="Network Science"/>
            <category term="Modelling"/>
            <category term="Geography &amp; GIS"/>
            <category term="Economics"/>
            <category term="Complex Systems"/>

        <updated>2025-08-15T22:20:01-04:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://phileasdg.github.io/media/posts/46/world_trade_banner.png" alt="" />
                    Note: This post was originally a short technical article I shared on&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://phileasdg.github.io/media/posts/46/world_trade_banner.png" class="type:primaryImage" alt="" /></p>
                <p><strong>Note:</strong> This post was originally a short technical article I shared on the Wolfram Community forum. For an interactive experience with live code or to download this text alongside the source code, please visit the original post <a href="https://community.wolfram.com/groups/-/m/t/3416904">here</a>. </p><h2 id="introduction">Introduction</h2>
<p>The global trade network is the backbone of international commerce, linking countries through a complex web of import and export relationships. Not only does it characterise the flow of goods and services, but it also shapes economic strategies and geopolitical landscapes. </p><p>While the true global trade network is incredibly complex, with millions of individual transactions occurring daily across countless products and services, we can still build meaningful representations that capture important aspects of global commerce ties. In this article, I’ll use Wolfram Knowledgebase country data from <a href="https://www.cia.gov/the-world-factbook/">The World Factbook</a> to define graphs of major import and export relationships on the global stage. </p><p>By constructing network representations of international trade, we can visualize and quantify the connections between nations, revealing patterns that might otherwise remain hidden in tables of statistics. Which countries serve as central hubs in global commerce? How do smaller economies interact with larger ones? Where do we see asymmetric dependencies? And how do natural trading communities form? In this short article, I’ll explore these questions through a series of visualizations and analyses.</p><h2 id="setup-building-a-dataset-of-international-commercial-relationships">Setup: Building a Dataset of International Commercial Relationships</h2>
<p>The first thing we need to do is gather data on import and export relationships between countries. We can get this information from the Wolfram Knowledgebase.</p><p>Let’s start by creating a list of all countries: </p><p> <figure class="post__image"><img src="https://phileasdg.github.io/media/posts/46/0mhu7w08drqns.png" alt="countries" width="914" height="49" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/0mhu7w08drqns-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0mhu7w08drqns-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0mhu7w08drqns-md.png 768w"></figure></p><p>We’re going to extract values associated with country entities above. Manually, we might access one such value like this:</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/1axwz1yc3p4za.png" alt="" width="424" height="47" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1axwz1yc3p4za-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1axwz1yc3p4za-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1axwz1yc3p4za-md.png 768w"></figure><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/46/0rhtbmil6fzi4.png" alt="" width="1084" height="48" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/0rhtbmil6fzi4-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0rhtbmil6fzi4-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0rhtbmil6fzi4-md.png 768w"></figure><p>We can also ask Wolfram Language to check the source of entity property data like so: </p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/096za5tfkwtq2.png" alt="" width="606" height="47" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/096za5tfkwtq2-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/096za5tfkwtq2-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/096za5tfkwtq2-md.png 768w"></figure><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/46/1hbx1q5bewf0p-2.png" alt="" width="276" height="48" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1hbx1q5bewf0p-2-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1hbx1q5bewf0p-2-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1hbx1q5bewf0p-2-md.png 768w"></figure><p>Now, let’s create a dataset of import and export information for these countries. We’ll extract key trade properties and remove entries with missing data.</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/0ob3dcrtldzxu.png" alt="" width="2243" height="278" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/0ob3dcrtldzxu-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0ob3dcrtldzxu-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0ob3dcrtldzxu-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/0ovu7bhsqczea.png" alt="dataset preview" width="1452" height="546" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/0ovu7bhsqczea-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0ovu7bhsqczea-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0ovu7bhsqczea-md.png 768w"></figure><p>Since these are tabular data, we can represent them in a <a href="https://reference.wolfram.com/language/ref/Tabular">Tabular</a> object (introduced in Wolfram Language 14.2). The Tabular representation makes it possible to apply <a href="https://reference.wolfram.com/language/guide/TabularProcessing">standard data science pipeline </a>techniques including filtering, aggregation, transformation, and visualisation to our data easily.</p><p>The dataset we’ve built contains international trade information for countries around the world, with data sourced from <a href="https://www.cia.gov/the-world-factbook/">The World Factbook</a>. Each column represents a key aspect of a country’s trade profile: </p><ul>
<li><em>ImportCommodities:</em> Major goods and product categories that each country primarily imports from international markets. These represent key dependencies on foreign products.</li>
<li><em>ExportCommodities:</em> Major goods and product categories that each country primarily sells to international markets. These represent the country’s key commercial outputs.</li>
<li><em>ImportPartners:</em> Major countries from which each nation sources its imports. These represent the primary international suppliers for each country.</li>
<li><em>ExportPartners:</em> Major countries to which each nation sells its exports. These represent the primary international customers for each country.</li>
<li><em>ImportPartnersFractions:</em> The approximate percentage of total imports that come from each major import partner. This quantifies the relative importance of each supplier country.</li>
<li><em>ExportPartnersFractions:</em> The approximate percentage of total exports that go to each major export partner. This quantifies the relative importance of each customer country.</li>
</ul>
<p>Not only do these data provide a coarse sense of who trades with whom, but also what they trade and how significant those relationships are in percentage terms.</p><h2 id="construction-and-analysis-of-network-representations-of-global-commerce">Construction and Analysis of Network Representations of Global Commerce</h2>
<p>Global commerce naturally lends itself to network analysis, where countries represent nodes (vertices) and trade relationships form the connections (edges) between them. Using our dataset, we can construct several different graph representations that reveal different aspects of international trade patterns. </p><h3 id="unweighted-international-trade-network-representations">Unweighted international trade network representations</h3>
<p>The simplest representations we can construct from our dataset are unweighted directed graphs where an edge from country A to country B indicates that B is a major trading partner of A. We can create two complementary networks:</p><ul>
<li><strong>Import Network:</strong> In these networks, an edge from country A to country B means that country A imports goods from country B. The direction of the edge follows the flow of money (A pays B for goods).</li>
<li><strong>Export Network</strong>: Here, an edge from country A to country B means that country A exports goods to country B. The direction follows the flow of goods.</li>
</ul>
<p>Let’s construct and visualise these graphs.</p><p>*Construct the global major import partner graph: *</p><pre><code class="language-wl">In[]:= globalImportRelationships = Graph[Normal[Dataset[internationalCommerceData][All, Keys][Keys]], 
    Flatten[FromTabular[ConstructColumns[internationalCommerceData, 
       &quot;Edges&quot; -&gt; (Thread[#Entity -&gt; #ImportPartners] &amp;)], &quot;Matrix&quot;]], ImageSize -&gt; Small]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/1m3tks5pkbkxu.png" alt="" width="360" height="305" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1m3tks5pkbkxu-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1m3tks5pkbkxu-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1m3tks5pkbkxu-md.png 768w"></figure><p><em>Construct the global major export partner graph:</em></p><pre><code class="language-wl">In[]:= globalExportRelationships = Graph[
    Normal[Dataset[internationalCommerceData][All, Keys][Keys]], 
    Flatten[FromTabular[ConstructColumns[internationalCommerceData, 
       &quot;Edges&quot; -&gt; (Thread[#Entity -&gt; #ExportPartners] &amp;)], &quot;Matrix&quot;]], ImageSize -&gt; Small]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/1g9a5cg22b41i.png" alt="" width="360" height="367" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1g9a5cg22b41i-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1g9a5cg22b41i-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1g9a5cg22b41i-md.png 768w"></figure><p>These networks are quite tangled, so it will help to represent them geographically.</p><p><em>Visualise these graphs on maps:</em></p><pre><code class="language-wl">In[]:= Row[Rasterize[#, ImageSize -&gt; Large, RasterSize -&gt; 1500] &amp; /@ {
     GeoGraphPlot[globalImportRelationships, 
      EdgeStyle -&gt; Thin, VertexSize -&gt; Small, 
      GeoProjection -&gt; &quot;LambertAzimuthal&quot;, ImageSize -&gt; 600, PlotRangePadding -&gt; .1, 
      PlotLabel -&gt; Style[&quot;Global Major Import Partner Network&quot;, 15], 
      GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}], 
     GeoGraphPlot[globalExportRelationships, 
      EdgeStyle -&gt; Thin, VertexSize -&gt; Small, 
      GeoProjection -&gt; &quot;LambertAzimuthal&quot;, ImageSize -&gt; 600, PlotRangePadding -&gt; .1, 
      PlotLabel -&gt; Style[&quot;Global Major Export Partner Network&quot;, 15], 
      GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}] 
    }]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/GlobalMajorImportPartnerNetwork.png" alt="" width="1500" height="1543" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorImportPartnerNetwork-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorImportPartnerNetwork-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorImportPartnerNetwork-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/GlobalMajorExportPartnerNetwork.png" alt="" width="1500" height="1543" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorExportPartnerNetwork-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorExportPartnerNetwork-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalMajorExportPartnerNetwork-md.png 768w"></figure><h3 id="analysis-of-discrepancies-between-import-and-export-networks">Analysis of discrepancies between import and export networks</h3>
<p>While both networks are very visually similar, because they take different perspectives, the import and export graphs paint slightly different pictures of global trade. One source of discrepancies between the networks is asymmetries in trade relationships: The fact that country A features in the list of major partners to country B does not always entail that B features in the list of major partners of A. To better understand these asymmetries, we can study which relationships appear in one network but not the other.</p><ul>
<li><strong>Two-way major partnerships:</strong> If an edge A  B is found in both graphs, it means that B is a major provider of goods to A (relative to A’s total imports) and A is a major exporter to B (relative to A’s total exports). This suggests A is economically dependent on its import and export relationships with B, as they make up significant portions of A’s total imports and exports.</li>
<li><strong>Import dependencies:</strong> If a A  B exists in the import network but not in the export network, it means B is a major source of imports to A, but is not a major export destination for A’s goods. This suggests A depends on B’s goods, but B is not a significant market for A.</li>
<li><strong>Export dependencies:</strong> Conversely, if  A  B exists in the export network but not in the import network, it means B is a major destination for A’s exports, but not one of A’s major import sources. ****This suggests A depends on B as a market for its goods, but not on imports from B.</li>
</ul>
<p>Let’s examine which countries most frequently appear in these “one-way” relationships:</p><p>The charts below show the 20 countries which most frequently appear as the “source” country (country A) in these asymmetric import and export relationships. The left chart ranks countries by the number of major trade partners with whom they have major import dependencies. The right chart ranks countries by the number of major trade partners with whom they have major export dependencies.</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/46/0qssf2f86q1zq.png" alt="" width="1386" height="539" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/0qssf2f86q1zq-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0qssf2f86q1zq-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0qssf2f86q1zq-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/Top20CountryOneWayImportDependencies.png" alt="" width="1086" height="577" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayImportDependencies-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayImportDependencies-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayImportDependencies-md.png 768w"></figure>
<figure class="post__image"><img src="https://phileasdg.github.io/media/posts/46/Top20CountryOneWayExportDependencies.png" alt="" width="1000" height="580" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayExportDependencies-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayExportDependencies-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryOneWayExportDependencies-md.png 768w"></figure><p>Notably, smaller economies like Vanuatu, Samoa, and Guinea appear frequently in these one-way relationships, suggesting they may have significant dependencies on specific trading partners that don’t reciprocally depend on them.</p><p>These next charts reveal which countries most frequently appear as the “destination” country (country B) in asymmetric relationships. The left chart shows countries that are most frequently considered important import sources, but not major export destinations for their partners goods. The right chart shows countries that are most frequently considered important export destinations, but not major import sources:</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/1sv1x08hlj4a0.png" alt="" width="1383" height="539" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1sv1x08hlj4a0-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1sv1x08hlj4a0-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1sv1x08hlj4a0-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/Top20CountryCriticalImportSources.png" alt="" width="1000" height="596" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalImportSources-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalImportSources-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalImportSources-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/Top20CountryCriticalExportMarkets.png" alt="" width="1000" height="626" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalExportMarkets-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalExportMarkets-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/Top20CountryCriticalExportMarkets-md.png 768w"></figure><p>China dominates as a critical import source for numerous countries that don’t reciprocally consider China a major export destination. Meanwhile, the United Kingdom and United States serve as vital export markets for many nations that don’t rely heavily on them for imports. These patterns highlight the uneven dependencies in global trade - smaller economies often have one-way trade relationships with economic powerhouses, while major economies maintain more balanced bilateral trade relationships with their key partners. This asymmetry creates potential vulnerabilities where countries depend economically on partners who don’t equally depend on them.</p><h3 id="country-centrality-in-global-commerce">Country Centrality in Global Commerce</h3>
<p>Network centrality measures help us identify which countries play pivotal roles in the global trade network. Different centrality metrics capture different aspects of a country’s importance in international trade.</p><p>Betweenness centrality measures the extent to which a country acts as an intermediary in the trade network. It is calculated based on the number of times a country falls on the shortest path between other countries. High betweenness centrality indicates that a country is a major hub for trade, facilitating transactions between many other nations. This can highlight countries that play a vital role in the distribution of goods globally.</p><p><em>Visualization of vertex betweenness centrality on the global imports network:</em></p><pre><code class="language-wl">In[]:= Module[{g = globalImportRelationships}, 
   g = Graph[g, VertexCoordinates -&gt; Map[First[GeoGridPosition[#, &quot;WinkelTripel&quot;]] &amp;, VertexList[g]]]; 
   GeoBubbleChart[Thread[VertexList[g] -&gt; BetweennessCentrality[g]], 
    GeoProjection -&gt; &quot;WinkelTripel&quot;, 
    PlotLabel -&gt; Style[&quot;Global Trade Import Vertex Betweenness-Centrality&quot;, 14], 
    GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}] 
  ]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/1l8auoboznwi6.png" alt="" width="1304" height="829" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1l8auoboznwi6-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1l8auoboznwi6-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1l8auoboznwi6-md.png 768w"></figure><p><em>Visualization of vertex betweenness centrality on the global exports network:</em></p><pre><code class="language-wl">In[]:= Module[{g = globalExportRelationships}, 
   g = Graph[g, VertexCoordinates -&gt; Map[First[GeoGridPosition[#, &quot;WinkelTripel&quot;]] &amp;, VertexList[g]]]; 
   GeoBubbleChart[Thread[VertexList[g] -&gt; BetweennessCentrality[g]], 
    GeoProjection -&gt; &quot;WinkelTripel&quot;, 
    PlotLabel -&gt; Style[&quot;Global Trade Export Vertex Betweenness-Centrality&quot;, 14], 
    GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}] 
  ]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/0j6jsiinemtns.png" alt="" width="1301" height="827" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/0j6jsiinemtns-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0j6jsiinemtns-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0j6jsiinemtns-md.png 768w"></figure><p>Nations like the United States, China, and Germany show substantial centrality, reflecting their critical positions in both importing and exporting goods. These countries are central players in the international market, not just due to their economic size but also because they serve as major conduits for international trade.</p><p>Countries with high betweenness centrality play a significant role in the stability of global trade networks. Disruptions in these countries, be it political instability, natural disasters, or economic sanctions, could have ripple effects, impacting trade flows globally.</p><h3 id="weighted-international-trade-network-representations">Weighted international trade network representations</h3>
<p>While our previous unweighted network analysis provided insights into the structure of global trade relationships, it treated all connections equally. In reality, trade relationships vary significantly in their importance. Some countries depend heavily on specific trading partners, with a large percentage of their imports or exports flowing through them.</p><p>By incorporating the percentage data from our dataset (ImportPartnersFractions and ExportPartnersFractions), we can create weighted networks that better reflect the actual economic significance of each relationship. In these weighted networks, the thickness of each edge represents the percentage of a country’s total imports or exports that flows through that relationship. </p><p>*Construct the weighted global import partner graph: *</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/46/1us4mokwx5dfd.png" alt="" width="2660" height="259" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1us4mokwx5dfd-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1us4mokwx5dfd-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1us4mokwx5dfd-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/1gp61mwnbbhvs.png" alt="" width="360" height="405" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1gp61mwnbbhvs-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1gp61mwnbbhvs-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1gp61mwnbbhvs-md.png 768w"></figure><p>*Construct the weighted global export partner graph: *</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/46/12nuslpcvt9tk.png" alt="" width="2654" height="259" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/12nuslpcvt9tk-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/12nuslpcvt9tk-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/12nuslpcvt9tk-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/17a0eaya4u61j.png" alt="" width="360" height="300" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/17a0eaya4u61j-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/17a0eaya4u61j-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/17a0eaya4u61j-md.png 768w"></figure><p>Once again, let’s plot these networks geographically:</p><p><em>Visualise the weighted global import and export partner networks on a map:</em></p><pre><code class="language-wl">In[]:= Row[Rasterize[#, ImageSize -&gt; Large, RasterSize -&gt; 1500] &amp; /@ {
     GeoGraphValuePlot[globalWeightedImportRelationships, 
      GeoProjection -&gt; &quot;LambertAzimuthal&quot;, ImageSize -&gt; 500, ColorFunction -&gt; &quot;Aquamarine&quot;, 
      EdgeValueRange -&gt; {0, 1}, EdgeValueSizes -&gt; 1/100, PlotRangePadding -&gt; .1, VertexSize -&gt; 5, 
      PlotLegends -&gt; Automatic, MinPointSeparation -&gt; None, PlotLabel -&gt; Style[&quot;Global Weighted Major Import Partner Network&quot;, 15], 
      GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}], 
     GeoGraphValuePlot[globalWeightedExportRelationships, 
      GeoProjection -&gt; &quot;LambertAzimuthal&quot;, ImageSize -&gt; 500, ColorFunction -&gt; &quot;Aquamarine&quot;, 
      EdgeValueRange -&gt; {0, 1}, EdgeValueSizes -&gt; 1/100, PlotRangePadding -&gt; .1, VertexSize -&gt; 5, 
      PlotLegends -&gt; Automatic, MinPointSeparation -&gt; None, PlotLabel -&gt; Style[&quot;Global Weighted Major Export Partner Network&quot;, 15], 
      GeoBackground -&gt; {&quot;Coastlines&quot;, {&quot;Land&quot; -&gt; White}}] 
    }]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/GlobalWeightedMajorImportPartnerNetwork.png" alt="" width="1500" height="1339" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorImportPartnerNetwork-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorImportPartnerNetwork-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorImportPartnerNetwork-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/GlobalWeightedMajorExportPartnerNetwork.png" alt="" width="1500" height="1339" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorExportPartnerNetwork-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorExportPartnerNetwork-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/GlobalWeightedMajorExportPartnerNetwork-md.png 768w"></figure><p>These plots highlight strong regional trade patterns and commerce hubs centred at major economic powers. Thicker lines represent relationships where a higher percentage of a country’s imports or exports flow through that connection. </p><h3 id="comparison-of-import-and-export-relationship-weights">Comparison of import and export relationship weights</h3>
<p>By comparing the weights of common edges in our import and export networks, we can identify key patterns of dependency and influence in international trade. </p><p><em>Produce a scatter plot of import and export edge weights for edges common to both weighted networks:</em></p><pre><code class="language-wl">In[]:= Module[{
     importEdges = EdgeList[globalWeightedImportRelationships], 
     importWeights = AnnotationValue[globalWeightedImportRelationships, EdgeWeight], 
     exportEdges = EdgeList[globalWeightedExportRelationships], 
     exportWeights = AnnotationValue[globalWeightedExportRelationships, EdgeWeight], 
     threadEm = Function[{a, b}, Thread[a -&gt; b]], commonEdges}, 
    
    commonEdges = Intersection[importEdges, exportEdges]; 
    
    Labeled[Labeled[Show[
       Plot[x, {x, 0, 1}, PlotStyle -&gt; Directive[Dashed, LightGray]], 
       ListPlot[KeyValueMap[Callout[#2, #1] &amp;, Merge[{
          (*x axis values*) KeySort[FilterRules[threadEm[importEdges, importWeights], commonEdges]], 
          (*y axis values*) KeySort[FilterRules[threadEm[exportEdges, exportWeights], commonEdges]]}, 
          First[List[#]] &amp;]], PlotRange -&gt; Full], ImageSize -&gt; Large], Map[Text, {&quot;Import network edge weight (fraction of total imports to country A coming from country B)&quot;, &quot;Export network edge weight (fraction of total exports of country A going to country B)&quot;}], {Bottom, Left}, RotateLabel -&gt; True], 
     Text[Style[&quot;Scatterplot of Major Import and Export Relationship Weights in Global Commerce&quot;, 15]], Top] 
   ] // Rasterize[#, ImageSize -&gt; Large, RasterSize -&gt; 1500] &amp;
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/1x8fe3jjsmh5a.png" alt="" width="1230" height="871" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1x8fe3jjsmh5a-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1x8fe3jjsmh5a-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1x8fe3jjsmh5a-md.png 768w"></figure><p>In this scatter plot:</p><ol>
<li>Points above the diagonal line represent relationships where the export dependency (y-axis) is stronger than the import dependency (x-axis). For example, Puerto Rico depends on the United States as a market for a about 90% of its exports, whereas it imports a little under 60% of its goods from the US.</li>
<li>Points below the diagonal line represent relationships where the import dependency is stronger than the export dependency. For instance, the Falklands import over 70% of their imported goods from the UK, but the UK is a market for under 10% of the Falklands exports.</li>
<li>Clustered points near the origin indicate that most trading relationships involve relatively small percentages of total trade (&lt;20%), showing diversification in most countries’ trading patterns.</li>
</ol>
<p>The scatter plot highlights how smaller economies often have highly concentrated trade relationships with major economic powers, while most countries maintain diversified trading portfolios with their major partners. This pattern of asymmetric dependencies is particularly evident in relationships influenced by geographic proximity, historical colonial ties, and economic size disparities. It’s important to remember that these edges represent only the major commercial relationships as identified by the World Factbook, meaning they capture the most significant trade flows from each country’s perspective rather than all trade relationships globally.</p><p>By subtracting the import network weights from the export network weights, and plotting a histogram of the resulting data, we can estimate the distribution of commercial relationships from most import-dependent to most export-dependent:</p><pre><code class="language-wl">In[]:= With[{
     importEdges = EdgeList[globalWeightedImportRelationships], 
     importWeights = AnnotationValue[globalWeightedImportRelationships, EdgeWeight], 
     exportEdges = EdgeList[globalWeightedExportRelationships], 
     exportWeights = AnnotationValue[globalWeightedExportRelationships, EdgeWeight]}, 
    ReverseSort[Map[Subtract @@ Values[#] &amp;, GroupBy[FilterRules[Join[Thread[exportEdges -&gt; exportWeights], Thread[importEdges -&gt; importWeights]], Intersection[importEdges, exportEdges]], First]]] // Labeled[Histogram[#, PlotRange -&gt; Full, PlotLabel -&gt; Style[&quot;Distribution of Trade Dependency Asymmetries in Global Commerce&quot;, 14]], Text /@ {&quot;Export dependency minus import dependency&quot;, &quot;Frequency&quot;}, {Bottom, Left}, RotateLabel -&gt; True] &amp; 
   ] // Rasterize[#, ImageSize -&gt; Large, RasterSize -&gt; 1500] &amp;
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/1pi2xibkyrpkm.png" alt="" width="1194" height="816" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1pi2xibkyrpkm-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1pi2xibkyrpkm-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1pi2xibkyrpkm-md.png 768w"></figure><p>The x-axis measures the difference between import and export dependencies for each trading relationship. A value of zero on this axis represents a balanced trade relationship, in the sense that a country’s reliance on imports from another is equal to its reliance on exports to that same country. Negative values indicate a stronger import dependency, meaning a country imports more goods from another than it exports to them. Positive values suggest a stronger export dependency, where a country exports more to another than it imports.</p><p>We can also produce rankings of countries by the magnitude of their dependencies. Here are the top 10 largest trade asymmetries according to our data:</p><pre><code class="language-wl">In[]:= With[{
      importEdges = EdgeList[globalWeightedImportRelationships], 
      importWeights = AnnotationValue[globalWeightedImportRelationships, EdgeWeight], 
      exportEdges = EdgeList[globalWeightedExportRelationships], 
      exportWeights = AnnotationValue[globalWeightedExportRelationships, EdgeWeight]}, 
     Labeled[#1, Text[Style[#2, 14]], Top] &amp; @@@ Thread[{
        ReverseSort[Map[Subtract @@ Values[#] &amp;, GroupBy[FilterRules[Join[Thread[exportEdges -&gt; exportWeights], Thread[importEdges -&gt; importWeights]] 
             , Intersection[importEdges, exportEdges]], First]]] // Map[Dataset, {Take[#, 10], Take[#, -10]}] &amp;, 
        {&quot;Top 10 Relationships Where Countries Are Most Dependent on Partners as Export Markets&quot;, &quot;Top 10 Relationships Where Countries Are Most Dependent on Partners as Import Sources&quot;} 
       }] 
    ] // Reverse // Row[#, Spacer[10]] &amp;
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/Screenshot-2025-08-16-at-11.31.11.png" alt="" width="1666" height="744" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/Screenshot-2025-08-16-at-11.31.11-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/Screenshot-2025-08-16-at-11.31.11-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/Screenshot-2025-08-16-at-11.31.11-md.png 768w"></figure><p>Countries at the top of the import-dependent list (like Uruguay with Argentina) rely heavily on specific partners for their imports while exporting proportionally less to those same partners. Conversely, countries at the top of the export-dependent list (like Chad with the United States) are highly dependent on specific markets for their exports while importing proportionally less from those partners.</p><h3 id="global-export-communities-by-modularity">Global export communities by modularity</h3>
<p>The network visualizations we’ve examined so far don’t immediately show us how countries naturally cluster into trading groups or blocs. To identify these natural groupings, we can apply community detection algorithms to our weighted export network. Using modularity-based community detection on our weighted export network, we can identify clusters of countries that trade more with each other than with the rest of the world. </p><p><em>Visualise groups of countries whose mutual exports represent larger shares of total national exports than exports from other countries (white represents missing data):</em></p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/46/1whb0nt21kpwe.png" alt="" width="2758" height="462" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1whb0nt21kpwe-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1whb0nt21kpwe-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1whb0nt21kpwe-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/1a1ddw0auqv6f.png" alt="" width="2637" height="2009" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/1a1ddw0auqv6f-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/1a1ddw0auqv6f-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/1a1ddw0auqv6f-md.png 768w"></figure><p><em>Compare the plot above to this map of free trade areas worldwide form Wikipedia:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/46/0pk71zdgnpvxx.png" alt="" width="1386" height="639" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/46/responsive/0pk71zdgnpvxx-xs.png 300w ,https://phileasdg.github.io/media/posts/46/responsive/0pk71zdgnpvxx-sm.png 480w ,https://phileasdg.github.io/media/posts/46/responsive/0pk71zdgnpvxx-md.png 768w"></figure><p><em>(<strong><a href="https://en.wikipedia.org/wiki/Trade_bloc">Wikipedia: Trade bloc</a></strong>, Free trade areas worldwide, by user</em> <em><a href="https://commons.wikimedia.org/wiki/User:Emilfaro">Emilfaro</a>**)</em></p><p>The modularity-based community detection results show striking regional patterns that largely overlap with established trade blocs and agreements. North America, South America, Europe, Russia and parts of Central Asia, China and parts of Southeast Asia, and Australia/New Zealand each form distinct communities. These natural groupings often mirror formal trade agreements like NAFTA, MERCOSUR, the EU, ASEAN, and others, demonstrating how geographic proximity and policy decisions reinforce natural trading patterns.</p><h2 id="reflection-and-concluding-notes">Reflection and Concluding Notes</h2>
<p>The analysis here reveals how smaller economies often develop asymmetric trade relationships with larger ones, sometimes relying heavily on a single partner for either imports or exports without reciprocity. These dependencies create potential vulnerabilities but also reflect practical economic realities shaped by geography, historical connections, and resource distribution.</p><p>Perhaps most interesting is how the detected trade communities largely align with formal trade agreements while occasionally revealing unexpected connections. These natural groupings demonstrate that while policy decisions certainly influence trade patterns, underlying economic complementarity and geographic proximity remain important forces in shaping global commerce.</p><p>This network perspective on international trade provides a different lens through which to understand global economic relationships; one that emphasizes connections and interdependencies rather than just individual country statistics. As global trade continues to evolve amid changing geopolitical landscapes, these network representations offer valuable insights into the resilience and vulnerability of international commercial relationships.</p><h2 id="cite-this-work">Cite this work</h2>
<p><a href="https://community.wolfram.com/groups/-/m/t/3416904">Trading places: a network analysis of global commerce</a>
by <a href="https://community.wolfram.com/web/phileasdg">Phileas Dazeley-Gaist</a>
Wolfram Community, STAFF PICKS, March 14, 2025
<a href="https://community.wolfram.com/groups/-/m/t/3416904">https://community.wolfram.com/groups/-/m/t/3416904</a></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>DelphAI: Structured Communication with LLMs in a Simulated Delphi Process</title>
        <author>
            <name>Phileas Dazeley-Gaist</name>
        </author>
        <link href="https://phileasdg.github.io/delphai-structured-communication-with-llms-in-a-simulated-delphi-process/"/>
        <id>https://phileasdg.github.io/delphai-structured-communication-with-llms-in-a-simulated-delphi-process/</id>
        <media:content url="https://phileasdg.github.io/media/posts/45/Banner-image-Community-Post-LLM-Delphi-Method.png" medium="image" />
            <category term="Work at Wolfram"/>
            <category term="Wolfram Language"/>
            <category term="Modelling"/>
            <category term="Complex Systems"/>
            <category term="AI"/>

        <updated>2025-08-15T22:17:42-04:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://phileasdg.github.io/media/posts/45/Banner-image-Community-Post-LLM-Delphi-Method.png" alt="" />
                    Note: This post was originally a short technical article I shared on&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://phileasdg.github.io/media/posts/45/Banner-image-Community-Post-LLM-Delphi-Method.png" class="type:primaryImage" alt="" /></p>
                <p><strong>Note:</strong> This post was originally a short technical article I shared on the Wolfram Community forum. For an interactive experience with live code or to download this text alongside the source code, please visit the original post <a href="https://community.wolfram.com/groups/-/m/t/3393596">here</a>. </p><h2 id="introduction">Introduction</h2>
<h3 id="an-overview-of-the-delphi-method">An Overview of the Delphi Method</h3>
<p>The Delphi method is a structured communication technique originally designed as a forecasting technique, that relies on a panel of experts. It was developed by the RAND Corporation in the 1950s and 1960s. The method involves multiple rounds of questionnaires or writing prompts sent to a panel of experts. The anonymised responses are aggregated and shared with the group after each round. The experts are encouraged to revise their earlier answers in light of the replies of other members of the panel. With some luck, the answers will converge to consensus over the course of several rounds. The method is widely used for forecasting and decision-making in business and education. </p><p><em>Illustration of one round of the Delphi process:</em></p><pre><code class="language-wl">In[]:= Show[
   Graph[{0 -&gt; 1, 1 -&gt; 2, 1 -&gt; 3, 1 -&gt; 4, 2 -&gt; 5, 3 -&gt; 6, 4 -&gt; 7, 5 -&gt; 8, 6 -&gt; 8, 7 -&gt; 8, 8 -&gt; 9, 9 -&gt; 10}, 
    VertexShape -&gt; Thread[Range[0, 10] -&gt; Map[diskFrame[#, 250, 30] &amp;, {&quot;🕵&quot;, &quot;📑&quot;, &quot;👱🏼‍♀️&quot;, &quot;👩‍🎨&quot;, &quot;👷🏽‍♀️&quot;, &quot;📝&quot;, &quot;📝&quot;, &quot;📝&quot;, &quot;🕵&quot;, &quot;📑&quot;, &quot;\[Bullet]\[Bullet]\[Bullet]&quot;}]], 
    VertexSize -&gt; .8, GraphLayout -&gt; {&quot;LayeredDigraphEmbedding&quot;, &quot;Orientation&quot; -&gt; Left, &quot;RootVertex&quot; -&gt; 0}, 
    ImageSize -&gt; 700], 
   Graphics[{Line[{{-3.2, 4.8}, {-3.2, 5}, {2.6, 5}, {2.6, 4.8}}], Text[Style[&quot;A single Delphi process round&quot;, 14, TextAlignment -&gt; Left], {-2.12, 4.8}]}] 
  ]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/18afa53ilb1yy-2.png" alt="Illustration of one round of the Delphi process:" width="1328" height="642" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/18afa53ilb1yy-2-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/18afa53ilb1yy-2-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/18afa53ilb1yy-2-md.png 768w"></figure><h3 id="what-does-it-look-like-in-practice">What does it look like in practice?</h3>
<p>Here’s a step-by-step breakdown of the Delphi method. </p><ol>
<li>After gathering volunteers, the facilitator distributes a questionnaire or initial prompt to the participants.</li>
<li>The participants fill out the questionnaire/or prepare their contribution to the first round of the process, and turn in their work to the facilitator.</li>
<li>The facilitator anonymises and summarises the perspectives of the participants, making sure to represent each in a balanced and nonjudgmental way, highlighting areas of agreement and disagreement between them. The facilitator then produces and shares this information in a report to participants, initiating the next round of the process.</li>
<li>The process begins again: participants respond to the report by refilling the questionnaire/writing a new contribution taking account of the contents of the report, clarifying ambiguities and addressing disagreements.</li>
<li>Once a predefined stopping criterion is fulfilled (e.g. the desired number of rounds has been reached, or there is global consensus) the facilitator produces a final report which either becomes or is used to produce the proceedings of the Delphi process.</li>
</ol>
<p><em>Animation representing a three-round Delphi process:</em></p><pre><code class="language-wl">In[]:= ListAnimate[Join[Join @@ Table[Join[
       Table[delphiMethodPlot[distanceFromOrigin, True, False, &quot;Round &quot; &lt;&gt; ToString[i]], {distanceFromOrigin, Subdivide[0, .75, 30]}], 
       Table[delphiMethodPlot[.75, True, False, &quot;Round &quot; &lt;&gt; ToString[i]],15], Table[delphiMethodPlot[.75, False, False, &quot;Round &quot; &lt;&gt; ToString[i]], 15], 
       Table[delphiMethodPlot[distanceFromOrigin, False, False, &quot;Round &quot; &lt;&gt; ToString[i]], {distanceFromOrigin, Subdivide[.75, 0, 30]}], 
       Table[delphiMethodPlot[0, False, False, &quot;Round &quot; &lt;&gt; ToString[i]],15], Table[delphiMethodPlot[0, True, False, &quot;Round &quot; &lt;&gt; ToString[i]], 15]], {i, 3}], 
    Table[delphiMethodPlot[0, True, False, &quot;End: The facilitator produces a final report.&quot;], 60]], AnimationRate -&gt; 30]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0k6j4neosl4i7.png" alt="Snapshot from an animation representing the Delphi process" width="820" height="907" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0k6j4neosl4i7-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0k6j4neosl4i7-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0k6j4neosl4i7-md.png 768w"></figure><h3 id="why-simulate-a-delphi-process-with-llms">Why simulate a Delphi process with LLMS?</h3>
<h4 id="studying-llm-capabilities">Studying LLM Capabilities</h4>
<p>LLMs provide a unique laboratory for studying artificial intelligence capabilities in structured dialogue. We can systematically evaluate how well these models maintain consistent expertise and viewpoints across multiple rounds of interaction - a key test of their ability to maintain coherent personas. The controlled environment allows us to study how AI systems incorporate new information while maintaining logical reasoning threads, and observe how they handle disagreements and work toward consensus. Perhaps most importantly, what would take weeks or months with human experts can be simulated in minutes, enabling rapid experimentation with different approaches and parameters. </p><h4 id="benefits-for-studying-structured-communication">Benefits for Studying Structured Communication</h4>
<p>The digital nature and speed of LLM interactions offers unprecedented opportunities to study structured communication processes. Every exchange can be logged and analyzed computationally, revealing patterns in how consensus emerges and how different viewpoints influence each other. Researchers can precisely control and vary process parameters. This reproducibility and scalability simply isn’t possible with traditional human-based studies, making LLM simulations a powerful tool for understanding and possibly improving structured communication protocols. </p><h4 id="limitations-and-considerations">Limitations and Considerations</h4>
<p>While promising, this approach comes with important limitations that must be considered. LLMs lack the deep, embodied experience of human experts - their expertise is ultimately derived from training data rather than years of lived experience. Since all participants in a simulation draw from the same underlying model, there’s a risk of artificial consensus that doesn’t reflect the true diversity of expert opinions. Additionally, LLMs don’t have professional reputations or real-world consequences to consider when making judgments, potentially limiting the relevance of their decisions. Findings should be interpreted with appropriate awareness of these constraints.</p><h3 id="motivation-for-using-wolfram-language">Motivation for using Wolfram Language</h3>
<p>A few advantages of using Wolfram Language to implement an LLM Delphi process simulation are:</p><ul>
<li><p>The LLM connectivity functions in Wolfram Language are of exceptionally high quality. They are versatile and very well-documented.</p></li>
<li><p>There are many great LLM-related functions like <a href="https://reference.wolfram.com/language/ref/ChatObject">ChatObject</a>, <a href="https://reference.wolfram.com/language/ref/ChatEvaluate">ChatEvaluate</a>, <a href="https://reference.wolfram.com/language/ref/LLMSynthesize">LLMSynthesize</a>, <a href="https://reference.wolfram.com/language/ref/LLMPromptGenerator">LLMPromptGenerator</a>, <a href="https://reference.wolfram.com/language/ref/LLMFunction">LLMFunction</a>, <a href="https://reference.wolfram.com/language/ref/LLMTool">LLMTool</a>. </p></li>
<li><p>Being able to connect LLMs to the full Wolfram Language standard library of functions and symbols, the wolfram resource system, and wolfram knowledgebase.</p></li>
</ul>
<h2 id="llm-delphi-process-implementation"><em>LLM Delphi Process Implementation</em></h2>
<h3 id="defining-a-project-prompt-bank">Defining a project prompt bank</h3>
<p>Define a dataset of project prompts:</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/19u9mclxjw50y.png" alt="Definition of a dataset of project prompts" width="1195" height="719" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/19u9mclxjw50y-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/19u9mclxjw50y-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/19u9mclxjw50y-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/Screenshot-2025-08-15-at-22.39.36.png" alt="Prompt bank dataset preview (cut off)" width="1398" height="1058" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.39.36-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.39.36-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.39.36-md.png 768w"></figure><h3 id="participants-setup">Participants setup</h3>
<h4 id="defining-a-dataset-of-persona-details">Defining a dataset of persona details</h4>
<p><em>Generate 24 conflicting opinions:</em></p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/0um5kz93vlo6r.png" alt="Generate 24 conflicting opinions" width="796" height="85" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0um5kz93vlo6r-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0um5kz93vlo6r-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0um5kz93vlo6r-md.png 768w"></figure><p><em>Generate a dataset of participant details (name, persona prompt, a sample of preexisting perspectives):</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0ang0i5eq7168.png" alt="Generate a dataset of participant details" width="2530" height="323" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0ang0i5eq7168-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0ang0i5eq7168-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0ang0i5eq7168-md.png 768w"></figure><p><em>Let’s load a pre-generated dataset of participant parameters:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/05a87xett01ev.png" alt="Load a pre-generated dataset of participant parameters" width="567" height="78" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/05a87xett01ev-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/05a87xett01ev-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/05a87xett01ev-md.png 768w"></figure><table>
<thead>
<tr>
<th>Emoji</th>
<th>Name</th>
<th>Persona Prompt</th>
<th>Prior Perspectives</th>
</tr>
</thead>
<tbody><tr>
<td>🌱👩‍🌾</td>
<td>Horticulturist</td>
<td>You are a horticulturist specializing in plant selection and care. Your role is to provide expert advice on the types of plants and vegetables that would thrive in the local climate and soil conditions. Consider factors such as sunlight, water requirements, and pest resistance in your recommendations.</td>
<td>{The garden should feature a diverse range of exotic plants to make it visually appealing and unique., It should be on the outskirts of town, where it’s quieter and more peaceful for gardening without disturbances., The primary purpose of the garden is to grow food for the community, and any surplus should be donated to local food banks.}</td>
</tr>
<tr>
<td>🌳👨‍🎨</td>
<td>Landscape architect</td>
<td>You are a landscape architect with expertise in designing outdoor spaces. Your task is to offer insights into the optimal layout and design of the community garden. Consider elements such as garden aesthetics, accessibility, and efficient use of space in your suggestions.</td>
<td>{We should keep the garden small and manageable to maintain quality rather than quantity., Mandatory volunteer days feel forced; it should be up to individual gardeners to maintain their own plots., The garden should be expanded to include more plots in order to serve additional community members.}</td>
</tr>
<tr>
<td>🌍👫</td>
<td>Community organizer</td>
<td>You are a community organizer focused on engaging and mobilizing local residents. Your goal is to propose strategies for involving the community in the garden project, ensuring it meets their needs and encourages participation. Think about ways to organize events, workshops, and volunteer opportunities.</td>
<td>{We should have scheduled volunteer days every week to keep the garden maintained and foster community bonds., We should focus on native plants to promote local biodiversity and sustainability., Everyone should have equal say, and decisions should be made through community votes to promote democratic involvement.}</td>
</tr>
<tr>
<td>🔬👩‍🔬</td>
<td>Environmental scientist</td>
<td>You are an environmental scientist with a focus on sustainable practices. Your responsibility is to advise on environmentally friendly gardening techniques, such as composting, water conservation, and organic pest control. Provide guidance on minimizing the garden’s ecological footprint.</td>
<td>{We should focus on creating educational programs for local schools to teach kids about gardening and sustainability., The garden should be an exclusive space for members to harvest fruits and vegetables for their own households only., All gardening practices should be strictly organic; chemicals have no place in a community garden.}</td>
</tr>
</tbody></table>
<h4 id="initializing-participant-chat-objects">Initializing participant chat objects</h4>
<p><em>Initialise a participant chat object with the system prompt, participant persona prompt, and participant prior (preexisting) perspectives:</em></p><pre><code class="language-wl">In[]:= ClearAll[initialiseParticipantChat] 
  
 initialiseParticipantChat[participantData_] := ChatObject[StringTemplate[promptBank[&quot;Initial participant prompt template&quot;]][&lt;|
          (*Shared system prompt*) &quot;SystemPrompt&quot; -&gt; promptBank[&quot;Shared participant prompt&quot;], 
          (*Persona prompt:*) &quot;PersonaPrompt&quot; -&gt; participantData[&quot;Persona Prompt&quot;], 
          (*Prior perspectives:*) &quot;PriorPerspectives&quot; -&gt; (If[ListQ[#1], StringRiffle[Normal[#1], &quot;\n--------------\n&quot;], #1] &amp;@Normal[participantData[&quot;Prior Perspectives&quot;]]) 
          |&gt;]] /; MemberQ[{Association, Dataset}, Head[participantData]]
</code></pre>
<p><em>Initialise a participant chat object:</em></p><pre><code class="language-wl">In[]:= initialiseParticipantChat[participantParameterDataset[[1]]]
</code></pre>
<pre><code class="language-wl">Out[]= &quot;The garden should feature a diverse range of exotic plants to make it visually appealing and unique.--------------It should be on the outskirts of town, where it&#39;s quieter and more peaceful for gardening without disturbances.--------------The primary purpose of the garden is to grow food for the community, and any surplus should be donated to local food banks.&quot;
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/1ny77ybl4x6ee-2.png" alt="" width="237" height="86" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1ny77ybl4x6ee-2-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1ny77ybl4x6ee-2-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1ny77ybl4x6ee-2-md.png 768w"></figure><p><em>Initializing all participant chat objects at once:</em></p><pre><code class="language-wl">In[]:= ClearAll[participantChats]
 participantChats = Dataset[Association[Map[#Name -&gt; initialiseParticipantChat[#] &amp;, Normal[participantParameterDataset]]]]
</code></pre>
<table>
<thead>
<tr>
<th>Horticulturist</th>
<th>Landscape architect</th>
<th>Community organizer</th>
<th>Environmental scientist</th>
</tr>
</thead>
<tbody><tr>
<td>-ChatObject-</td>
<td>-ChatObject-</td>
<td>-ChatObject-</td>
<td>-ChatObject-</td>
</tr>
</tbody></table>
<h3 id="facilitator-setup">Facilitator setup</h3>
<h4 id="providing-instructions-from-the-facilitator-to-the-participants-and-getting-participant-contributions">Providing instructions from the facilitator to the participants, and getting participant contributions</h4>
<p><em>Construct facilitator instructions to participants:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0aykn2josyvjv.png" alt="" width="1739" height="119" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0aykn2josyvjv-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0aykn2josyvjv-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0aykn2josyvjv-md.png 768w"></figure><p><em>Construct the initial instructions to participants from the facilitator:</em></p><pre><code class="language-wl">In[]:= (*constructInstructionsFromFacilitator[]*)
</code></pre>
<p><em>Construct instructions from the facilitator, a list of materials:</em></p><pre><code class="language-wl">In[]:= (*constructInstructionsFromFacilitator[{&lt;|Step-&gt;1,Report-&gt;REPORT CONTENTS|&gt;}]*)
</code></pre>
<p><em>Request an initial (first round) contribution from one participant:</em></p><pre><code class="language-wl">In[]:= (*ChatEvaluate[
 initialiseParticipantChat[participantParameterDataset[[1]]],
 (*Initial (first round) participant contribution request:*)
 constructInstructionsFromFacilitator[]
 ]*)
</code></pre>
<p><em>Request initial (first round) participant contributions from all participants:</em></p><pre><code class="language-wl">In[]:= (*Map[ChatEvaluate[#,constructInstructionsFromFacilitator[]]&amp;,participantChats]*)
</code></pre>
<h4 id="providing-instructions-to-the-facilitator-and-getting-the-facilitator-to-produce-intermediate-reports">Providing instructions to the facilitator, and getting the facilitator to produce intermediate reports</h4>
<p><em>Initialize a facilitator chat object:</em></p><pre><code class="language-wl">In[]:= ClearAll[facilitatorChat]
 facilitatorChat = ChatObject[promptBank[&quot;Initial instructions to facilitator&quot;]]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/15vejcwe3gdmg.png" alt="Chat object" width="237" height="86" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/15vejcwe3gdmg-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/15vejcwe3gdmg-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/15vejcwe3gdmg-md.png 768w"></figure><p><em>Extract the latest participant responses:</em></p><pre><code class="language-wl">In[]:= ClearAll[latestParticipantResponses]
 latestParticipantResponses[participantChats_Dataset] := participantChats[All, Last[#[&quot;Messages&quot;]] &amp;][Select[#&quot;Role&quot; == &quot;Assistant&quot; &amp;], &quot;Content&quot;, Last, #&quot;Data&quot; &amp;]
</code></pre>
<p><em>Example:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0y00znl27qdxv-2.png" alt="" width="545" height="41" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0y00znl27qdxv-2-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0y00znl27qdxv-2-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0y00znl27qdxv-2-md.png 768w"></figure><p><em>Construct an instructions prompt for the facilitator to produce a report based on the latest round of participant contributions:</em></p><pre><code class="language-wl">In[]:= ClearAll[constructInstructionsToFacilitator]
 constructInstructionsToFacilitator[latestParticipantResponses_Dataset] := StringTemplate[
        promptBank[&quot;Facilitator materials template&quot;]][&lt;|&quot;LatestParticipantResponses&quot; -&gt; StringRiffle[KeyValueMap[
                   StringTemplate[&quot;Contributor: `1`\nContribution:\n`2`&quot;][##] &amp;,
                   Normal[latestParticipantResponses]], &quot;\n--------------\n\n&quot;]|&gt;]
</code></pre>
<p><em>Example:</em></p><p><em>Submit people’s latest round of contributions to the facilitator and ask the facilitator to produce a report:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/1a62mzg18g6x8.png" alt="" width="1378" height="41" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1a62mzg18g6x8-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1a62mzg18g6x8-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1a62mzg18g6x8-md.png 768w"></figure><h4 id="sending-facilitator-reports-to-participants">Sending facilitator reports to participants</h4>
<p><em>Get the latest response (report) from the facilitator:</em></p><pre><code class="language-wl">In[]:= ClearAll[latestFacilitatorResponse]
 latestFacilitatorResponse[facilitatorChat_ChatObject, defaultResponse_ : promptBank[&quot;Initial writing prompt&quot;]] := If[Length[#] == 1, 
         defaultResponse, Last[Last[Select[#, #Role == &quot;Assistant&quot; &amp;]][[&quot;Content&quot;]]][&quot;Data&quot;]] &amp;@facilitatorChat[&quot;Messages&quot;]
</code></pre>
<p><em>Example:</em></p><pre><code class="language-wl">In[]:= (*latestFacilitatorResponse[facilitatorChat]*)
</code></pre>
<p><em>Send all participants the report for the latest round, and prompt them to share their perspectives again:</em></p><pre><code class="language-wl">In[]:= (*Map[ChatEvaluate[#,constructInstructionsFromFacilitator[
 {&lt;|Round-&gt;1,Report-&gt;latestFacilitatorResponse[facilitatorChat]|&gt;}]]&amp;,participantChats]*)
</code></pre>
<p><em>Extract the new latest responses:</em></p><pre><code class="language-wl">In[]:= (*latestParticipantResponses[%]*)
</code></pre>
<h3 id="tying-it-all-together-simulating-the-delphi-process">Tying it all together: simulating the Delphi process</h3>
<p>A Delphi process round is made from the contributions of participants + the report produced by the facilitator.</p><p><em>Define a function to perform a single round of an automated Delphi process:</em></p><pre><code class="language-wl">In[]:= ClearAll[delphiProcessRound]
 delphiProcessRound[{round_Integer, participantChats_Dataset, facilitatorChat_ChatObject}] := {round + 1, #, ChatEvaluate[
          facilitatorChat, constructInstructionsToFacilitator[latestParticipantResponses[#](*,round+1*)]]} &amp;@Map[
            ChatEvaluate[#, constructInstructionsFromFacilitator[
                   {&lt;|&quot;Round&quot; -&gt; round, If[round == 0, &quot;Instructions&quot;, &quot;Report&quot;] -&gt; latestFacilitatorResponse[facilitatorChat]|&gt;}]] &amp;, 
            participantChats]
</code></pre>
<p>After the last round, the facilitator produces a final report.</p><p><em>Define a function to produce the final Delphi process report from the facilitator:</em></p><pre><code class="language-wl">In[]:= ClearAll[delphiProcessFinalReport]
 delphiProcessFinalReport[facilitatorChat_ChatObject] := ChatEvaluate[facilitatorChat, promptBank[&quot;Final report generation prompt&quot;]]
</code></pre>
<p><em>Run 1 round of a Delphi process:</em></p><pre><code class="language-wl">In[]:= (*delphiProcessRound[{0,participantChats,facilitatorChat}]*)
</code></pre>
<p><em>Run a 3 round Delphi process:</em></p><pre><code class="language-wl">In[]:= (*threeRoundDelphiProcessData=AbsoluteTiming[Nest[delphiProcessRound,{0,participantChats,facilitatorChat},3]];*)
</code></pre>
<p><em>Conclude the 3 round Delphi process with a final report:</em></p><pre><code class="language-wl">In[]:= (*latestFacilitatorResponse[delphiProcessFinalReport[Last[Last[threeRoundDelphiProcessData]]]]*)
</code></pre>
<p><em>In one go, perform a 3 round Delphi process, and generate the final report:</em></p><pre><code class="language-wl">In[]:= threeRoundDelphiProcessData = MapAt[delphiProcessFinalReport, Nest[delphiProcessRound, {0, participantChats, facilitatorChat}, 3],3];
</code></pre>
<pre><code class="language-wl">In[]:= Iconize[threeRoundDelphiProcessData]
</code></pre>
<figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/04f11y5b1vhzy.png" alt="Iconized data" width="88" height="41" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/04f11y5b1vhzy-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/04f11y5b1vhzy-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/04f11y5b1vhzy-md.png 768w"></figure><p>Let’s load a precomputed simulation result:</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/17ugn9x2lpitf.png" alt="Image description" width="1089" height="38" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/17ugn9x2lpitf-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/17ugn9x2lpitf-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/17ugn9x2lpitf-md.png 768w"></figure><h3 id="fetching-participant-contributionsfacilitator-reports-from-completed-simulations">Fetching participant contributions/facilitator reports from completed simulations</h3>
<h4 id="implementation-nthroundcontributions-nthroundcontributionspeechbubbles-nthroundreport-nthroundreportspeechbubble"><em>Implementation:</em> (nthRoundContributions, nthRoundContributionSpeechBubbles, nthRoundReport, nthRoundReportSpeechBubble)</h4>
<p><em>Define a function to retrieve the contributions of the participants at the nth Delphi process round:</em></p><pre><code class="language-wl">In[]:= ClearAll[nthRoundContributions]
 nthRoundContributions[participantChats_Dataset, n_Integer?Positive] :=participantChats[All, Select[#[&quot;Messages&quot;], #Role == &quot;Assistant&quot; &amp;][[n]][&quot;Content&quot;][[1]][&quot;Data&quot;] &amp;]
</code></pre>
<p><em>Retrieve the nth round participant contributions:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/Screenshot-2025-08-15-at-22.55.37.png" alt="" width="1706" height="572" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.55.37-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.55.37-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/Screenshot-2025-08-15-at-22.55.37-md.png 768w"></figure><ol>
<li><strong>Understanding Soil Composition and Local Climate</strong>: The notion that any plant can thrive with enough watering and fertilization overlooks the critical role of soil health and structure. Different plants have varying requirements for soil pH, drainage, and nutrient availability. For example, root vegetables like carrots and beets prefer sandy loam for proper growth, while leafy greens may do better in richer, loamy soils. It is essential to assess soil composition and amend it appropriately before deciding on plant varieties.</li>
<li><strong>Sustainable Plant Selection</strong>: Emphasizing diversity in our plant selection can encourage resilience against pests and diseases. Instead of exotic plants that may not adapt well to our local conditions, we should focus on selecting a mix of native and well-adapted species. Native plants often require less water and fertilizer and can support local biodiversity by attracting pollinators and beneficial insects. Some great examples include coneflowers and black-eyed Susans, which are visually appealing and attract bees and butterflies while requiring minimal maintenance.</li>
<li><strong>Balancing Aesthetics and Functionality</strong>: While I understand the desire for ornamental beauty in the garden, it’s important to recognize that aesthetics can coexist with productivity. Many flowering plants are not only attractive but also serve practical purposes. For example, marigolds can deter pests and even help with vegetable production. Incorporating edible ornamental plants, such as kale or swiss chard that have beautiful foliage, can enhance the garden’s visual appeal while contributing to food security.</li>
<li><strong>Educational Opportunities</strong>: Community gardens can and should serve as platforms for education about sustainable gardening practices and the importance of local ecosystems. This involves showcasing both ornamental plants and edible crops, thus providing visitors with a comprehensive understanding of gardening. Workshops on growing food, composting, and pest management can create a deeper connection amongst community members and foster a sense of shared responsibility in maintaining the garden.</li>
<li><strong>The Role of Community Involvement</strong>: To strengthen the sense of community, it’s essential to involve local residents in the decision-making process regarding plant choices. Engaging community members in selecting plants that reflect their preferences while being considerate of environmental conditions will promote a sense of ownership and pride in the garden. By co-creating the space, we can cultivate a richer community connection to our garden.</li>
</ol>
<p>Overall, my approach emphasizes the importance of informed plant selection that suits our local conditions and fosters both ecological health and community engagement. Let’s continue the conversation focusing on sustainable practices, integrating diverse plant types, and enhancing community involvement to create a resilient and beautiful space for everyone. | As a landscape architect with a focus on community gardens, I appreciate the rich tapestry of ideas presented regarding the design and functionality of these vital spaces. The key themes emerging from our discussions include aesthetics, biodiversity, sustainability, and community engagement. </p><p>First, I wholeheartedly support the pragmatic perspective advocating for the integration of edible landscaping. The blend of fruit trees, berry bushes, and perennial herbs with traditional vegetable plots not only enhances the garden’s visual appeal but also contributes to biodiversity and food accessibility, which are critical in urban settings. The aesthetic value of such a diverse garden can serve as a powerful tool for attracting community involvement, as people are often drawn to vibrant spaces where they can witness the results of their labor. </p><p>The consensual perspective adds an important layer by emphasizing sustainable design principles. Incorporating elements such as rain gardens and permeable pathways not only addresses stormwater management but also creates a more resilient ecosystem within the garden. This can significantly enhance the overall health of the garden while creating spaces that encourage local wildlife, thus bolstering pollinator populations which, in turn, improves vegetable and fruit production. </p><p>However, I understand the concern raised from the incoherent perspective that prioritizes functionality over aesthetics. While practicality is essential—especially with features like raised beds, composting areas, and secure tool storage—these elements need not be mutually exclusive with design. I propose a solution that intertwines functionality and aesthetics by deliberately positioning practical structures to create an alluring layout. For instance, raised beds can be designed with engaging shapes and materials that complement the natural surroundings, while composting areas can be concealed using native plant screens, maintaining a visually appealing environment.</p><p>Moreover, flexible zones for seasonal activities, as highlighted in the consensual perspective, offer a fantastic way to cater to community needs and desires. These adaptable spaces could allow for a range of activities including gardening workshops, children’s programs, or social gatherings, significantly enhancing community spirit and ownership of the garden. </p><p>That said, we must also consider the challenges of engaging a diverse community with varying levels of gardening experience and physical ability. Therefore, the design should prioritize accessibility. This can involve ensuring paths are wide enough for all users, incorporating raised beds at various heights, and providing seating that accommodates all community members.</p><p>In summary, the ideal community garden should be a harmonious blend of aesthetics, functionality, and sustainability. By leveraging the best aspects of the differing perspectives we’ve discussed, we can design a community garden that not only thrives ecologically and socially but also stands as a cherished space for all. I look forward to further discussions and collaborations that build upon these insights to create an inclusive and flourishing garden space. | As a community organizer focused on fostering meaningful engagement and participation in local initiatives, I appreciate the diverse perspectives shared regarding the establishment of our community garden project. There are several key themes that echo throughout these viewpoints, and I believe addressing them will enhance not just the garden’s design and implementation but also its overall success and sustainability.</p><p><strong>1. Inclusion and Accessibility:</strong>
The concern regarding potential exclusion, particularly for lower-income residents and those with mobility challenges, resonates deeply with me. It’s paramount that our planning phase prioritizes incorporating the voices and needs of the entire community. To achieve this, I suggest forming a Community Advisory Board that includes representation from marginalized groups. This board can be instrumental in advising on site selection, design features (such as raised beds for wheelchair access), and ensuring equitable access to resources.</p><p><strong>2. Sustained Involvement:</strong>
The idea of fostering ongoing local ownership through mentorship programs makes great sense. We could establish a tiered volunteer system, where experienced gardeners mentor novices not only in gardening skills but also in other areas, such as community organizing and sustainability practices. Additionally, implementing a regular schedule of volunteer days that specifically caters to varied schedules can encourage more residents to participate.</p><p><strong>3. Cultural Relevance and Diversity:</strong>
I wholeheartedly support the notion of integrating local cultural elements into the garden. In addition to individual sharing of gardening practices and culinary traditions, we can organize themed planting days or workshops that celebrate specific cultural events or festivals, enhancing the diversity of our plantings and attracting participants from various backgrounds. This could culminate in intercultural potlucks that honor and showcase the different connections our community has to food, growing practices, and identity.</p><p><strong>4. Potential Challenges:</strong>
While the proposed ideas hold great promise, potential challenges such as funding for maintaining infrastructure, ongoing volunteer engagement, and managing diverse opinions exist. To address funding, we can explore partnerships with local businesses and schools, applying for grants specifically aimed at urban agriculture and community development. We can also incentivize ongoing volunteer work through a points system where volunteers earn rewards, such as seeds, gardening tools, or local produce.</p><p>In conclusion, I believe that through intentional outreach, continuous engagement strategies, and inclusive programming, we can build a community garden that not only serves as a hub for gardening but also as a symbol of community resilience and collaboration. I look forward to our continued discussions and to exploring how we can collaboratively implement these strategies to address both the benefits and challenges presented. | As an environmental scientist focused on sustainable gardening practices, I appreciate the perspectives shared and believe they highlight critical themes for fostering a sustainable community garden. Here are my thoughts on the points raised, along with additional insights and recommendations.</p><p>Firstly, the emphasis on integrating native plant species is spot-on. Native plants are not only adapted to local environmental conditions, which reduces the need for extensive watering and chemical inputs, but they also play a crucial role in supporting local pollinators and wildlife. By creating a biodiverse ecosystem, we enhance resilience against pests and diseases, making the garden more sustainable in the long run. I would encourage community members to participate in workshops or educational sessions to learn about local flora, which can further deepen their connection to the environment and motivate stewardship. </p><p>However, we must also address the challenge many face regarding the misconceptions about synthetic fertilizers. While they may initially provide a quick fix for nutrient deficiencies, their prolonged use can degrade soil health and disrupt local ecosystems through nutrient runoff. It’s essential to shift the narrative towards looking at organic amendments, like compost or well-aged manure, as viable alternatives for enhancing soil fertility. Composting not only enriches the soil but also helps in reducing waste and fostering a closed-loop system within the garden. I recommend establishing a community composting program, where participants can contribute kitchen scraps and garden waste, thereby promoting shared responsibility for waste management and soil health.</p><p>Additionally, the idea of employing companion planting is invaluable. This approach fosters mutual benefits amongst plant species. For example, planting marigolds among vegetables can help deter pests, while legumes can naturally fix nitrogen in the soil, reducing the need for external fertilizers. Integrating such practices can create a harmonious ecosystem while educating the community about the interdependence of species.</p><p>Furthermore, I would urge the garden community to consider water conservation techniques such as rainwater harvesting and drip irrigation. These methods not only minimize water use but also prevent soil erosion and water wastage, making our gardens more resilient to droughts.</p><p>In conclusion, I believe that through a combination of native planting, organic amendment practices, companion planting, and water conservation, we can cultivate a community garden that is both productive and sustainable. Let us work collaboratively to create educational programs that empower community members to adopt these practices, while also addressing potential challenges to foster a robust and environmentally friendly gardening culture. I look forward to hearing how others might build upon or challenge these ideas in our subsequent discussions. |</p><p>Define a function to construct speech bubbles for the nth round contribution of a participant specification <em>participants</em> (which could be All, a single participant name, or a list of participant names):</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/090s6if3in8jv.png" alt="" width="1106" height="233" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-md.png 768w"></figure><p>*Example: *</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/1gaifup1y9wd1.png" alt="" width="1520" height="41" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1gaifup1y9wd1-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1gaifup1y9wd1-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1gaifup1y9wd1-md.png 768w"></figure><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/1h5ybo970k9qi.png" alt="" width="1226" height="855" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1h5ybo970k9qi-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1h5ybo970k9qi-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1h5ybo970k9qi-md.png 768w"></figure><p><em>Define a function to retrieve the facilitator reports at the nth Delphi process round:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0ljlk3quiqz29.png" alt="" width="2262" height="68" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0ljlk3quiqz29-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0ljlk3quiqz29-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0ljlk3quiqz29-md.png 768w"></figure><p><em>Retrieve the nth round facilitator report:</em></p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/1l0peedx4yo34.png" alt="" width="478" height="41" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1l0peedx4yo34-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1l0peedx4yo34-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1l0peedx4yo34-md.png 768w"></figure><p><em>Define a function to construct nth round facilitator report speech bubbles:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0lv37w7ofd568.png" alt="" width="1577" height="236" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0lv37w7ofd568-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0lv37w7ofd568-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0lv37w7ofd568-md.png 768w"></figure><p>*Example: *</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/1cm44wjglqejj.png" alt="" width="1194" height="41" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1cm44wjglqejj-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1cm44wjglqejj-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1cm44wjglqejj-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0m65zjrnlrk4h.png" alt="" width="1181" height="774" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0m65zjrnlrk4h-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0m65zjrnlrk4h-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0m65zjrnlrk4h-md.png 768w"></figure><h4 id="visualising-the-full-dialogue-from-a-simulated-delphi-process">Visualising the full dialogue from a simulated Delphi process:</h4>
<p><em>Visualise the sequence of communications between agents in the Delphi process:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/1v8y6wfhn3sfw.png" alt="" width="1801" height="349" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1v8y6wfhn3sfw-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1v8y6wfhn3sfw-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1v8y6wfhn3sfw-md.png 768w"></figure><p>(see the included visualisation at the end of this text)</p><h3 id="other-miscellaneous-visualisation-tools">Other miscellaneous visualisation tools</h3>
<h4 id="implementation-diskframe-delphimethodplot"><em>Implementation:</em> (diskFrame, delphiMethodPlot)</h4>
<p><em>Create disk frame around an expression:</em></p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/090s6if3in8jv-2.png" alt="" width="1106" height="233" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-2-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-2-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/090s6if3in8jv-2-md.png 768w"></figure><p><em>Create a Delphi process illustration:</em></p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/1vzaoomjz8zr0.png" alt="" width="2536" height="403" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1vzaoomjz8zr0-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1vzaoomjz8zr0-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1vzaoomjz8zr0-md.png 768w"></figure><p><em>Make an animation illustrating the process:</em></p><pre><code class="language-wl">In[]:= ListAnimate[Join[Join @@ Table[Join[
       Table[delphiMethodPlot[distanceFromOrigin, True, False, &quot;Round &quot; &lt;&gt; ToString[i]], {distanceFromOrigin, Subdivide[0, .75, 30]}], 
       Table[delphiMethodPlot[.75, True, False, &quot;Round &quot; &lt;&gt; ToString[i]],15], Table[delphiMethodPlot[.75, False, False, &quot;Round &quot; &lt;&gt; ToString[i]], 15], 
       Table[delphiMethodPlot[distanceFromOrigin, False, False, &quot;Round &quot; &lt;&gt; ToString[i]], {distanceFromOrigin, Subdivide[.75, 0, 30]}], 
       Table[delphiMethodPlot[0, False, False, &quot;Round &quot; &lt;&gt; ToString[i]],15], Table[delphiMethodPlot[0, True, False, &quot;Round &quot; &lt;&gt; ToString[i]], 15]], {i, 3}], 
    Table[delphiMethodPlot[0, True, False, &quot;End: The facilitator produces a final report.&quot;], 30]], AnimationRate -&gt; 30]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/1jrowcy9twoa8.png" alt="" width="820" height="907" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1jrowcy9twoa8-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1jrowcy9twoa8-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1jrowcy9twoa8-md.png 768w"></figure><h2 id="case-study-establishing-and-maintaining-a-community-garden">Case Study: Establishing and Maintaining a Community Garden</h2>
<h3 id="the-case-study-setting">The case study setting</h3>
<p>This case study simulates a Delphi process focused on developing a comprehensive plan for establishing and maintaining a community garden. </p><p>The simulation employs 4 LLM “expert” participants, each represented by their role and emoji identifier:</p><ol>
<li>Horticulturist (🌱👩‍🌾) - Plant selection and care specialist</li>
<li>Landscape Architect (🌳👨‍🎨) - Design and spatial planning expert</li>
<li>Community Organizer (🌍👫) - Community engagement and program coordination</li>
<li>Environmental Scientist (🔬👩‍🔬) - Environmental impact and sustainability advisor</li>
</ol>
<p>Plus a Facilitator (🕵️) who guides the process, summarizes findings, and produces reports. </p><h3 id="participant-system-prompts">Participant system prompts</h3>
<p>The LLM expert participants are given the following shared instructions: </p><p>Shared participant system prompt:</p><pre><code class="language-wl">In[]:= Framed[Text[Style[promptBank[&quot;Shared participant prompt&quot;], Italic]], RoundingRadius -&gt; 5]
</code></pre>
<figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/1hq1mwjuuylfb.png" alt="" width="2786" height="289" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1hq1mwjuuylfb-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1hq1mwjuuylfb-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1hq1mwjuuylfb-md.png 768w"></figure><p>In addition to these shared instructions, each participant gets their own persona prompt which describes the general , and some of the beliefs they should defend. For example:</p><p>Participant persona prompt example: The Horticulturist</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0l7d8px336ljg.png" alt="" width="1880" height="137" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0l7d8px336ljg-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0l7d8px336ljg-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0l7d8px336ljg-md.png 768w"></figure><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/1cozki4smkasv.png" alt="" width="2182" height="680" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1cozki4smkasv-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1cozki4smkasv-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1cozki4smkasv-md.png 768w"></figure><p>Participant beliefs are generated automatically using an LLM using the prompt:</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/1m8rvekmhvg8o.png" alt="" width="685" height="41" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1m8rvekmhvg8o-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1m8rvekmhvg8o-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1m8rvekmhvg8o-md.png 768w"></figure><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/0bgll1krzz5nh.png" alt="" width="1721" height="56" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0bgll1krzz5nh-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0bgll1krzz5nh-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0bgll1krzz5nh-md.png 768w"></figure><p>The resulting text is then converted into a list of first person statements using the prompt:</p><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/1adufvrvtmh3b.png" alt="" width="685" height="41" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/1adufvrvtmh3b-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/1adufvrvtmh3b-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/1adufvrvtmh3b-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0gwv7g2o5hcwh.png" alt="" width="1864" height="250" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0gwv7g2o5hcwh-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0gwv7g2o5hcwh-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0gwv7g2o5hcwh-md.png 768w"></figure><p>where $\text{$\grave{ }$1$\grave{ }$}$ stands for the conflicting opinions list generated at the last step. </p><p>The participants are then assigned three randomly sampled perspectives. The sampling is set up such that no two personas will share identical beliefs.</p><p>Here is the dataset of the participant perspectives used in this case-study: </p><pre><code class="language-wl">In[]:= participantParameterDataset[KeyDrop[&quot;Persona Prompt&quot;], &lt;|#, &quot;Prior Perspectives&quot; -&gt; Column[#&quot;Prior Perspectives&quot;]|&gt; &amp;]
</code></pre>
<table>
<thead>
<tr>
<th>Emoji</th>
<th>Name</th>
<th>Prior Perspectives</th>
</tr>
</thead>
<tbody><tr>
<td>🌱👩‍🌾</td>
<td>Horticulturist</td>
<td>{{The garden should feature a diverse range of exotic plants to make it visually appealing and unique.}, {It should be on the outskirts of town, where it’s quieter and more peaceful for gardening without disturbances.}, {The primary purpose of the garden is to grow food for the community, and any surplus should be donated to local food banks.}}</td>
</tr>
<tr>
<td>🌳👨‍🎨</td>
<td>Landscape architect</td>
<td>{{We should keep the garden small and manageable to maintain quality rather than quantity.}, {Mandatory volunteer days feel forced; it should be up to individual gardeners to maintain their own plots.}, {The garden should be expanded to include more plots in order to serve additional community members.}}</td>
</tr>
<tr>
<td>🌍👫</td>
<td>Community organizer</td>
<td>{{We should have scheduled volunteer days every week to keep the garden maintained and foster community bonds.}, {We should focus on native plants to promote local biodiversity and sustainability.}, {Everyone should have equal say, and decisions should be made through community votes to promote democratic involvement.}}</td>
</tr>
<tr>
<td>🔬👩‍🔬</td>
<td>Environmental scientist</td>
<td>{{We should focus on creating educational programs for local schools to teach kids about gardening and sustainability.}, {The garden should be an exclusive space for members to harvest fruits and vegetables for their own households only.}, {All gardening practices should be strictly organic; chemicals have no place in a community garden.}}</td>
</tr>
</tbody></table>
<p>When designing AI personas to represent different viewpoints in a multi-party dialogue, it’s important to carefully consider how to generate and manage disagreement while maintaining ethical safeguards. The approach used in this implementation is safe for several key reasons:</p><ol>
<li>The domain is constrained to community gardening, a relatively non-controversial topic</li>
<li>The perspective generation is focused on practical rather than ideological disagreements</li>
<li>The shared participant prompt emphasizes constructive collaboration</li>
<li>The facilitator role helps moderate and guide discussion toward consensus</li>
<li>The system is designed to surface and resolve differences through reasoned dialogue</li>
<li>The participant system prompt is completely transparent about the artificial nature of these perspectives. There’s no deception - the beliefs are explicitly described as aspects of a role the agent is playing.</li>
<li>While the AI personas may adopt different perspectives, they are still bound by the underlying model’s learned safety constraints. The base reinforcement learning training acts as a fundamental safety rail that prevents egregiously harmful outputs, regardless of the assigned persona.</li>
</ol>
<p>The experimental justification for assigning the participant AI agents heterogenous perspectives is to ensure that the participants will disagree on some issues, and to echo real-world group negotiation processes. LLMs tend to be very inoffensive by design and will rarely diverge from mainstream social, political, or cultural norms. When we don’t explicitly enforce heterogeneity of agent opinions, they tend to converge to unanimous agreement very quickly, obstructing meaningful study of group decision-making and consensus-building processes.</p><p>At the start of each round, the participants are sent instructions from the facilitator in the following form:</p><pre><code class="language-wl">In[]:= Framed[Text[Style[promptBank[&quot;Instructions from facilitator template&quot;], Italic]],RoundingRadius -&gt; 5]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0mls12ptpekcj.png" alt="" width="2478" height="563" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0mls12ptpekcj-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0mls12ptpekcj-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0mls12ptpekcj-md.png 768w"></figure><p>Each participant then responds to this prompt.</p><h3 id="the-facilitator-system-prompt">The facilitator system prompt</h3>
<p>The facilitator has the task of coordinating and directing the Delphi process. Unlike the expert participants who are given specific personas and perspectives, the facilitator is instructed to remain neutral and focus on process management. The facilitator is instructed using the following system prompt:</p><pre><code class="language-wl">In[]:= Framed[Text[Style[promptBank[&quot;Initial instructions to facilitator&quot;], Italic]], RoundingRadius -&gt; 5]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/035sfh91ajxpx.png" alt="" width="2452" height="250" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/035sfh91ajxpx-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/035sfh91ajxpx-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/035sfh91ajxpx-md.png 768w"></figure><p>At each round, when the participants have completed their contributions, the facilitator is sent the latest list of contributions in the following template:</p><pre><code class="language-wl">In[]:= Framed[Text[Style[promptBank[&quot;Facilitator materials template&quot;], Italic]], RoundingRadius -&gt; 5]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/06nt3vbqzfi37.png" alt="" width="2741" height="563" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/06nt3vbqzfi37-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/06nt3vbqzfi37-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/06nt3vbqzfi37-md.png 768w"></figure><p>The report the facilitator produces in response is sent out to the participants at the start of the next round. For the final round, the facilitator uses its latest report to produce a final report concluding the Delphi process.</p><h3 id="the-delphi-process">The Delphi process</h3>
<p>The simulated Delphi process of this case study consists of three rounds of structured communication between expert participants and a facilitator, culminating in a final report. A key feature of the implementation is the use of chat objects to provide each agent its own chat history and context throughout the process. </p><p>The core simulation can be executed with just three key components:</p><ol>
<li>A dataset mapping participant names to their chat obbjects (containing participant system prompts)</li>
<li>A facilitator ChatObject (containing the facilitator system prompt)</li>
<li>The number of rounds to perform.</li>
</ol>
<p>Here’s the code that runs the complete process: </p><pre><code class="language-wl">In[]:= threeRoundDelphiProcessData = MapAt[delphiProcessFinalReport, Nest[delphiProcessRound, {
      (*Initial step number:*) 0, 
      (*Dataset of participant chat objects:*) participantChats, 
      (*Facilitator chat object:*) facilitatorChat},(*Number of rounds:*)3], 3];
</code></pre>
<p>The result looks like this:</p><pre><code class="language-wl">In[]:= Dataset[AssociationThread[{&quot;Round Count&quot;, &quot;Participant Chats&quot;, &quot;Facilitator Chat&quot;}, threeRoundDelphiProcessData]]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/11da8zqwcppmx.png" alt="" width="1359" height="1023" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/11da8zqwcppmx-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/11da8zqwcppmx-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/11da8zqwcppmx-md.png 768w"></figure><p>The simulation results can be retrieved as plain text or speech bubbles. For more detail on this functionality, see the <em>Fetching participant contributions/facilitator reports from completed simulations</em> subsection of the <em>LLM Delphi Process Implementation</em> section of this article. </p><p>To make a speech bubble of the nth round response from a participant, we might write:</p><pre><code class="language-wl">In[]:= First[nthRoundContributionSpeechBubbles[threeRoundDelphiProcessData[[2]], 2, 
    &quot;Landscape architect&quot;, 
    &quot;SnippetForm&quot; -&gt; True, &quot;SnippetLength&quot; -&gt; 10]]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/13qyjo9rab6t5.png" alt="" width="1244" height="632" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/13qyjo9rab6t5-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/13qyjo9rab6t5-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/13qyjo9rab6t5-md.png 768w"></figure><p>Likewise, to make a speech bubble for the nth round report, we might say:</p><pre><code class="language-wl">In[]:= nthRoundReportSpeechBubble[Last[threeRoundDelphiProcessData], 1, 
   &quot;SnippetForm&quot; -&gt; True, &quot;SnippetLength&quot; -&gt; 10]
</code></pre>
<figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/0g9j5mu9p8p5g.png" alt="" width="1178" height="620" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/0g9j5mu9p8p5g-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/0g9j5mu9p8p5g-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/0g9j5mu9p8p5g-md.png 768w"></figure><h3 id="case-study-full-exchange-transcript"><em>Case-study full exchange transcript</em></h3>
<p>Visualise the full sequence of exchanges between agents in the case-study Delphi process simulation:</p><figure class="post__image"><img src="https://phileasdg.github.io/media/posts/45/010t8jgipvpxf.png" alt="" width="1801" height="349" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/010t8jgipvpxf-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/010t8jgipvpxf-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/010t8jgipvpxf-md.png 768w"></figure><figure class="post__image"><img loading="lazy" src="https://phileasdg.github.io/media/posts/45/fulltranscript.png" alt="Full transcript" width="902" height="13790" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/45/responsive/fulltranscript-xs.png 300w ,https://phileasdg.github.io/media/posts/45/responsive/fulltranscript-sm.png 480w ,https://phileasdg.github.io/media/posts/45/responsive/fulltranscript-md.png 768w"></figure><h3 id="qualitatively-speaking-how-did-the-llm-participants-and-facilitator-do">Qualitatively speaking, how did the LLM participants and facilitator do?</h3>
<p>I’m personally quite pleased with the results here. Using Anthropic’s Claude 3.5 Sonnet, the results feel remarkably natural and productive. Several aspects stand out:</p><ul>
<li>The facilitator maintained neutrality while effectively summarizing key points, successfully identified areas of agreement and conflict, kept discussions focused and constructive, and succeeded at in anonymising contributions while preserving their marrow.</li>
<li>The participants showed consistent role adherence while remaining flexible enough to engage with others’ ideas. They successfully balanced advocacy for their positions with willingness to find common ground, and brought forward new solutions and questions as discussions evolved. They also defended their distinct perspectives without becoming aggressive or rude.</li>
</ul>
<p>The simulation demonstrated that LLMs can effectively maintain consistent personas while engaging in meaningful negotiation and consensus-building. The quality of discourse suggests that this approach could be valuable for studying group decision-making processes and testing different facilitation strategies.</p><h2 id="what-next">What Next?</h2>
<p>This case study suggests the potential of using LLMs to study structured communication protocols. Wolfram proved to be an ideal environment for this work thanks to its powerful LLM functions, flexible syntax, and rich visualization capabilities.</p><p>Future work could explore several promising directions: </p><ul>
<li>Quantitative analysis of semantic convergence in LLM-based Delphi processes</li>
<li>Comparison of different LLM models in maintaining consistency across multiple rounds</li>
<li>Application to other structured communication protocols beyond the Delphi method</li>
<li>Development of tools for real-time monitoring and intervention in LLM-based group discussions</li>
</ul>
<p>The code and methodology presented here provide a foundation for researchers interested in using LLMs to study group decision-making and consensus-building processes.</p><h2 id="cite-this-work">Cite this work</h2>
<p><a href="https://community.wolfram.com/groups/-/m/t/3393596">DelphAI: Structured communication with LLMs in a simulated Delphi process</a>
by <a href="https://community.wolfram.com/web/phileasdg">Phileas Dazeley-Gaist</a>
Wolfram Community, STAFF PICKS, February 14, 2025
<a href="https://community.wolfram.com/groups/-/m/t/3393596">https://community.wolfram.com/groups/-/m/t/3393596</a></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Creative Generative Design with Mathematical Marbling</title>
        <author>
            <name>Phileas Dazeley-Gaist</name>
        </author>
        <link href="https://phileasdg.github.io/creative-generative-design-with-mathematical-marbling/"/>
        <id>https://phileasdg.github.io/creative-generative-design-with-mathematical-marbling/</id>
        <media:content url="https://phileasdg.github.io/media/posts/41/Mathematical-Marbling-Banner.png" medium="image" />
            <category term="Work at Wolfram"/>
            <category term="Wolfram Language"/>
            <category term="Programming"/>
            <category term="Modelling"/>
            <category term="Art"/>

        <updated>2024-10-24T15:15:01-04:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://phileasdg.github.io/media/posts/41/Mathematical-Marbling-Banner.png" alt="" />
                    Note: This post was originally a short technical article I shared on&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://phileasdg.github.io/media/posts/41/Mathematical-Marbling-Banner.png" class="type:primaryImage" alt="" /></p>
                <p class="msg msg--info"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forum. For an interactive experience with live code or to download this text alongside the source code, please visit the original post <a href="https://community.wolfram.com/groups/-/m/t/3258063">here</a>. </p>
<p class="msg--highlight msg ">See also: <a href="https://community.wolfram.com/groups/-/m/t/3271633">M<span class="cc6" data-native-text="true">athematical marbling animation</span></a>, for even more marbling magic.</p>
<h2>Paper Marbling and Mathematical Marbling</h2>
<h3>What is Paper Marbling?</h3>
<p>Ink marbling is the practice of dipping or dripping colorful inks or dyes onto a liquid surface, and swirling, displacing, cutting, dragging, and otherwise forming the ink into a design, often akin to patterns in marble. The earliest verified accounts of ink marbling date back to 12th century Japan, but the practice has a rich history throughout Asia, the Islamic World, and in Europe where it was extensively used to decorate book bindings. In Turkey, the practice is called “ebru” after the Persian word “ebrū”, which means “cloud-like”.</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-20.48.07.png" alt="" width="538" height="345" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.48.07-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.48.07-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.48.07-md.png 768w"></figure>
<p>I find ink marbling deeply enchanting. The imprecision of the medium results in organic-seeming, flowing shapes - never perfectly regular or completely random. By combining techniques, artists can create a wide variety of motifs and designs, from waves and spirals to scallop shells, flowers, and trees.</p>
<h3>Mathematical Marbling</h3>
<p><span class="cc1" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true">Mathematical marbling refers to the mathematical reproduction of the marbling process. Aubrey Jaffer has an excellent series of blog posts on the subject </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://people.csail.mit.edu/jaffer/Marbling/" target="_blank" data-testid="ButtonBoxView" rel="noopener" style="font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);"><span class="cc4" data-native-text="true">on his website</span></a><span class="cc1" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true">. He has also co-authored </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://ieeexplore.ieee.org/author/38513250100" target="_blank" data-testid="ButtonBoxView" rel="noopener" style="font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);"><span class="cc4" data-native-text="true">several papers</span></a><span class="cc1" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true"> on mathematical and computational methods for marbling, </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://ieeexplore.ieee.org/document/7478444" target="_blank" data-testid="ButtonBoxView" rel="noopener" style="font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);"><span class="cc4" data-native-text="true">including on marbling in 3D</span></a><span class="cc1" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true">. In this technical article, I will describe, reproduce, and demonstrate some mathematical marbling methods from his work.</span></p>
<p><span class="cc1" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true">In his blog post </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://people.csail.mit.edu/jaffer/Marbling/Mathematics" target="_blank" data-testid="ButtonBoxView" rel="noopener" style="font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);"><span class="cc4" data-native-text="true">The mathematics of marbling</span></a><span class="cc1" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true">, Jaffer outlines several marbling methods that don’t require fluid mechanics theory to perform. This article will explore vector graphics implementations of three of these methods in Wolfram Language, respectively, for dripping ink drops on a marbling canvas such that new drops displace and distort previous ones, for tracing lines through the ink using a pointed object (or tine), and for tracing circles through the ink using a pointed object. The lines and curves produced by displacing ink using a sharp tool like a toothpick are known as tine lines.</span></p>
<p><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">For each of these methods, I’ll split my exploration into a short description of the process, an implementation section containing my code, and an exploratory examples section demonstrating how you can use and combine these techniques to produce computational marbling art.</span></p>
<div id="cell-2060b4c3-02e0-c040-9f43-92dbf2116dcf" class="cell">
<div class="cell-wrapper">
<div class="cell-content">
<h2>Ink Drop Marbling</h2>
<h3>Dropping Ink in a Marbling Tank</h3>
<p>As we drip ink drops into the marbling tank, new drops will displace old ones such that given a point <em>P</em>, and a new paint drop of radius <em>r</em> centered at <em>C</em>, <em>P</em> will be displaced radially to the position:</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-20.53.05.png" alt="" width="234" height="84" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.53.05-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.53.05-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.53.05-md.png 768w"></figure>
<p>This transformations preserves the area of all neighbourhoods not containing <em>C</em> (though it is not guaranteed to preserve the area of individual polygons due to their finite detail). </p>
<p>Please visit <a href="https://people.csail.mit.edu/jaffer/Marbling/Dropping-Paint">Aubrey Jaffer's website</a> for a more in-depth explanation.</p>
<h2><em>Implementation:</em> inkDrop, marbleDisplace, and dripDrops</h2>
<p>To download the original code, please consult the original post <a href="https://community.wolfram.com/groups/-/m/t/3258063">here</a>.</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-20.54.54.png" alt="" width="1780" height="1586" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.54.54-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.54.54-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-20.54.54-md.png 768w"></figure>
<h3>Examples</h3>
<p>The <em>dripDrops</em> function takes as its arguments: </p>
<ol>
<li>A list of polygons, or an empty list defining the existing geometry on the canvas.</li>
<li>A list defining the sequence of new drop positions.</li>
<li>A list of drop sizes. </li>
</ol>
<p>It returns the transformed geometry after dripping. With this function defined, we can begin to make marbling designs. </p>
<h4>Basic examples</h4>
<p><em>Drop 5 randomly coloured drops with radius 1 in the same place:</em></p>
<figure class="post__image"><em><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.00.08.png" alt="" width="507" height="150" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.08-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.08-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.08-md.png 768w"></figure></em></p>
<p><em>Drop 12 randomly coloured drops with increasing radii in equally spaced intervals on a circle:</em></p>
<figure class="post__image"><em><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.00.43.png" alt="" width="455" height="132" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.43-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.43-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.00.43-md.png 768w"></figure></em></p>
<p><em>Drop 25 randomly coloured identically sized drops randomly dripped in a rectangular region of the marbling tank: </em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.01.26.png" alt="" width="584" height="368" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.01.26-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.01.26-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.01.26-md.png 768w"></figure>
<p>Note that in the displacement process, ink is pushed outside the ink-dropping region.</p>
<p><em>Drop 50 randomly coloured drops with random radii in a defined interval, in random positions in a disk:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.02.20.png" alt="" width="594" height="389" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.02.20-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.02.20-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.02.20-md.png 768w"></figure>
<h4>Layered designs</h4>
<p>We can create layered designs by partitioning an ordered list of drops such as one generated by <em>dripDrops</em> into groups, and plotting the groups in different colours:</p>
<p><em>Make a layered design by dropping ink, and interpreting a partition of the result as different colour layers:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.08.06.png" alt="" width="442" height="392" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.06-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.06-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.06-md.png 768w"></figure>
<p><em>We can design a setup to generate a layered marbling automatically given a list of the numbers of drops in each layer: </em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.08.37.png" alt="" width="465" height="500" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.37-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.37-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.08.37-md.png 768w"></figure>
<h4>Other ink drop shapes</h4>
<p>By specifying a different ink drop function to <em>dripDrops</em> with the "InkDropFunction" Option, you can use arbitrary geometry as ink drops:</p>
<p><em>Define a function to generate n-gons:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.09.25.png" alt="" width="536" height="94" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.25-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.25-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.25-md.png 768w"></figure>
<p><em>Use it as the ink drop function in a dripDrops call:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.09.51.png" alt="" width="488" height="353" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.51-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.51-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.09.51-md.png 768w"></figure>
<p>Note that while changing ink drop shapes results in different designs, the method by which points are displaced stays constant.</p>
<h4>Filling arbitrary shapes or text with ink drops</h4>
<p><span class="cc1" data-native-text="true">We might naively try to fill a shape by uniformly sampling points from the inside of the shape and dripping at these points. Unfortunately, this tends to be unsuccessful because ink drops push each other outside of the sampled region. One approach to mitigate this effect is to start with equally spaced points in the region, for example using the process described in </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://mathematica.stackexchange.com/a/141215/87521" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc4" data-native-text="true">this StackExchange answer by user kirma</span></a><span class="cc1" data-native-text="true"> for Monte Carlo estimation of Voronoi cell centroids.</span></p>
<p><em>Make an ink drop text marbling from roughly evenly spaced points in a text region:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.10.57.png" alt="" width="658" height="454" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.10.57-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.10.57-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.10.57-md.png 768w"></figure>
<p><em>Here's an ink drop marbling from roughly evenly spaced sampled points in France:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.11.36.png" alt="" width="1146" height="1140" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.11.36-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.11.36-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.11.36-md.png 768w"></figure>
<p>As you can see, there's still some bleeding outside of the regions of interest, but much less than there would be without sampling approximately equally spaced points from the target regions.</p>
<h4>Other interesting examples</h4>
<p><em>Displace arbitrary background geometry:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.12.33.png" alt="" width="621" height="446" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.33-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.33-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.33-md.png 768w"></figure>
<p><em>Make multiple full rotations along a circle, dropping ink in regular intervals:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.12.55.png" alt="" width="587" height="239" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.55-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.55-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.12.55-md.png 768w"></figure>
<p>Try these methods yourself. Play around with with different shapes and combine different techniques. </p>
<h2>Pin, Comb, and Other Tine Lines</h2>
<p>Marbling techniques often involve dragging pointed objects such as needles, pencils, or combs through ink. Displacements created this way are called tine lines.<br><br>In the following sections, I’ll implement methods to trace straight infinite tine lines, and tine circles.</p>
<h3>Tracing Infinite Lines Through the Ink</h3>
<p>Given <em>L</em>, a tine line with arbitrary slope, the vector mapping for a point <em>P</em> is:</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.15.41.png" alt="" width="168" height="50" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.15.41-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.15.41-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.15.41-md.png 768w"></figure>
<p>Where <em>d</em> is the minimum distance from the point <em>P</em> to the tine line, |<em>(P-B)•N</em>|, <em>N</em> is a unit vector perpendicular to the tine line <em>L</em>, <em>B</em> is a point on the tine line, and <em>M</em> is a unit vector along the tine line. The parameter <em>z</em> controls the maximum displacement of the tine line, and <em>c</em> controls the maximum sharpness of the bends as ink is dragged along the tine line in a laminar flow.</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.17.33.png" alt="" width="226" height="205" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.17.33-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.17.33-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.17.33-md.png 768w"></figure>
<p><em>(Illustration courtesy of Aubrey Jaffer)</em></p>
<p><span class="cc1" data-native-text="true">Please refer to Aubrey Jaffer’s website for a </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://people.csail.mit.edu/jaffer/Marbling/Mathematics" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc4" data-native-text="true">more in-depth explanation</span></a><span class="cc1" data-native-text="true">.</span></p>
<h3><em>Implementation: </em>tineLine and combLine</h3>
<p>To download the original code, please consult the original post <a href="https://community.wolfram.com/groups/-/m/t/3258063">here</a>.</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.36.47.png" alt="" width="572" height="566" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.36.47-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.36.47-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.36.47-md.png 768w"></figure>
<h3>Examples: tineLine and combLine</h3>
<h4>Distort polygons with a single tine line using tineLine</h4>
<p>The <em>tineLine</em> function distorts a polygon along an infinite tine line defined by a point <em>b</em> and unit vector <em>m</em>, alongside the tine parameters <em>z</em> and <em>c</em>. The function takes the following arguments:</p>
<ol>
<li>A polygon to distort.</li>
<li>An arbitrary point on the desired tine line.</li>
<li>A unit vector in the direction of the tine line.</li>
<li>The displacement magnitude parameter <em>z</em>.</li>
<li>The bend sharpness parameter <em>c</em>.</li>
</ol>
<p><em>Drag a tine line through a single ink drop:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.27.01.png" alt="" width="580" height="128" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.01-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.01-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.01-md.png 768w"></figure>
<p><em>Drag a tine line through 10 stacked drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.27.21.png" alt="" width="538" height="158" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.21-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.21-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.27.21-md.png 768w"></figure>
<h4>Distort polygons with an arbitrary number of tine lines using combLine</h4>
<p>The <em>combLine</em> function extends <em>tineLine</em>'s functionality to allow dragging multiple tines across polygons with a single function call. It takes the following arguments: </p>
<ol>
<li>A list of polygons, or empty list representing the canvas, or marbling tank. </li>
<li>A list of arbitrary points on the desired tine lines.</li>
<li>A list of unit vectors defining the line directions, or a single unit vector.</li>
<li>A list of <em>z</em> parameters, or a single <em>z</em> parameter value. </li>
<li>A list of <em>c</em> parameters, or a single <em>c</em> parameter value.</li>
</ol>
<p>The function returns the transformed geometry after applying the specified tine transformations. </p>
<p><em>Make computational latte art by pulling a tine in a line through a stack of ink drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.29.28.png" alt="" width="591" height="417" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.28-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.28-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.28-md.png 768w"></figure>
<p><em>Comb through a stack of ink drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.29.50.png" alt="" width="600" height="451" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.50-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.50-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.29.50-md.png 768w"></figure>
<p><em>Trace a sequence of parallel tine lines in alternating directions across a stack of ink </em><em>drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.30.16.png" alt="" width="632" height="475" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.16-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.16-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.16-md.png 768w"></figure>
<p><em>Draw tine lines counterclockwise around a point at the centre of a stack of ink drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.30.46.png" alt="" width="595" height="432" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.46-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.46-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.30.46-md.png 768w"></figure>
<p><em>Draw tine lines along the edges of regular polygons, counterclockwise over a stack of drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.31.09.png" alt="" width="586" height="335" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.09-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.09-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.09-md.png 768w"></figure>
<p>We can also use combLine to draw curved tines. The easiest approach to do this is to cheat somewhat first applying a nonlinear transformation to the canvas geometry, then applying tine lines, and finally reversing the initial nonlinear transformation. For example, we can use this technique to trace sinusoidal tine lines.</p>
<p><em>Sinusoidal tine lines:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.31.44.png" alt="" width="588" height="384" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.44-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.44-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.44-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.31.59.png" alt="" width="373" height="412" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.59-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.59-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.31.59-md.png 768w"></figure>
<h3>Tracing Circles Lines Through the Ink</h3>
<p>We can also marble by displacing ink along a circle of centre <em>C</em> and radius <em>r</em>. In this case, we can define the mapping from a point <em>P</em> as:</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.33.18.png" alt="" width="294" height="57" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.18-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.18-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.18-md.png 768w"></figure>
<p>Where <em>a</em> is the angle of the displacement arc,</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.33.57.png" alt="" width="74" height="44" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.57-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.57-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.33.57-md.png 768w"></figure>
<p><em>l</em> is the length of the displacement arc, <em>l=z•u^d</em>, and <em>d</em> is the distance from <em>P</em> to the closest point on the circle, <em>d=|(||P-C||-r)|</em>.</p>
<p>Just as is the case for tine lines, the parameters <em>z</em> and <em>c</em> control the maximum displacement of the tine, and the maximum sharpness of the bends along the tine circle, respectively.</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.34.58.png" alt="" width="227" height="228" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.34.58-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.34.58-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.34.58-md.png 768w"></figure>
<p><em>(Illustration courtesy of Aubrey Jaffer)</em></p>
<p><span class="cc1" data-native-text="true">Please read Aubrey Jaffer’s website for a </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://people.csail.mit.edu/jaffer/Marbling/Mathematics" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc4" data-native-text="true">more in-depth explanation</span></a><span class="cc1" data-native-text="true">.</span></p>
<h3><em>Implementation:</em> tineCircle and combCircle</h3>
<p>To download the original code, please consult the original post <a href="https://community.wolfram.com/groups/-/m/t/3258063">here</a>.</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.37.17.png" alt="" width="599" height="584" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.37.17-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.37.17-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.37.17-md.png 768w"></figure>
<h3>Examples</h3>
<h4>Distort polygons with a single tine line using tineCircle</h4>
<p>The <em>tineCircle</em> function distorts a polygon along a tine circle defined by the central point <em>b</em> and radius <em>r</em>, alongside the tine parameters <em>z</em> and <em>c</em>. The function takes the following arguments:</p>
<ol>
<li>A polygon to distort.</li>
<li>The centre of the desired tine circle.</li>
<li>The radius of the desired tine circle.</li>
<li>The displacement magnitude parameter <em>z</em>.</li>
<li>The bend sharpness parameter <em>c</em>.</li>
</ol>
<p><em>Drag a tine circle through a single ink drop:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.38.43.png" alt="" width="570" height="130" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.38.43-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.38.43-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.38.43-md.png 768w"></figure>
<p><em>Drag a tine circle through 10 stacked drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.39.01.png" alt="" width="594" height="175" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.39.01-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.39.01-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.39.01-md.png 768w"></figure>
<h4>Distort polygons with an arbitrary number of tine circles using combCircle</h4>
<p>The <em>combCircle</em> function extends <em>tineCircle</em>'s functionality to allow dragging multiple tines in circles through polygons with a single function call. It takes the following arguments: </p>
<ol>
<li>A list of polygons, or empty list representing the canvas, or marbling tank. </li>
<li>A list of centre points of the desired tine circles.</li>
<li>A list of radii of the desired tine circles, or a single radius value for all specified tine circles.</li>
<li>A list of<em> z</em> parameters, or a single <em>z</em> parameter value. </li>
<li>A list of <em>c</em> parameters, or a single <em>c</em> parameter value.</li>
</ol>
<p>The function returns the transformed geometry after applying the specified tine circle transformations. </p>
<p><em>Trace a tine circle through a stack of drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.41.55.png" alt="" width="465" height="400" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.41.55-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.41.55-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.41.55-md.png 768w"></figure>
<p><em>Comb tine circles through a stack of drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.42.15.png" alt="" width="562" height="363" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.15-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.15-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.15-md.png 768w"></figure>
<p><em>Trace tine circles in alternating directions through a stack of drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.42.39.png" alt="" width="615" height="424" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.39-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.39-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.42.39-md.png 768w"></figure>
<p>Using Module, it's easy to build up scenes by layering ink dripping and tine transformations.</p>
<p><em>Concentric tine circles in alternating direction through a grid of ink drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.43.06.png" alt="" width="572" height="662" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.06-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.06-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.06-md.png 768w"></figure>
<p><em>Trace tine circles centred on equally spaced points around a circle, alternating clockwise and counterclockwise directions through a stack of ink drops:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.43.31.png" alt="" width="600" height="457" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.31-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.31-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.31-md.png 768w"></figure>
<p><em>Trace tine circles through a stack of ink drops in alternating directions along the arms of a spiral:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.43.53.png" alt="" width="603" height="444" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.53-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.53-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.43.53-md.png 768w"></figure>
<h2>Sampling Evenly Distanced Points on Polygon Boundaries for Custom Canvas Design Geometry</h2>
<p>To achieve good results with manually prepared canvas geometry it's good to define polygons using roughly evenly separated points along their boundaries. High-detail polygons defined by a large number of evenly spaced points also deform more fluidly and naturally than low detail or varying detail polygons. To ensure polygons are optimally defined for marbling design it helps to be able to sample evenly spaced points from the boundaries of polygons. We can define a helper function for this.</p>
<p><em>Sample n equally spaced points on the boundary of a polygon:</em></p>
<ul>
<li>Based on Henrik Schumacher's answer on the Mathematica &amp; Wolfram Language StackExchange: <a href="https://mathematica.stackexchange.com/a/180931/87521">https://mathematica.stackexchange.com/a/180931/87521</a></li>
</ul>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.44.55.png" alt="" width="1300" height="548" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.44.55-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.44.55-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.44.55-md.png 768w"></figure>
<p><em>Example: Take a high-detail evenly spaced point sample from a low-detail star polygon:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.45.12.png" alt="" width="522" height="259" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.12-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.12-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.12-md.png 768w"></figure>
<p>Let's use this function to generate a striped background as the basis for the next marbling design:</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.45.36.png" alt="" width="1290" height="146" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.36-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.36-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.36-md.png 768w"></figure>
<p><em>Preview the striped background design:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.45.52.png" alt="" width="370" height="237" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.52-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.52-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.45.52-md.png 768w"></figure>
<h2>Simulating Real Marbling Design Techniques</h2>
<p>By combining the functions discussed in previous sections, we can generate an infinite variety of marbling patterns, and easily experiment with marbling ideas. We can also reproduce pattern-making techniques used in physical marbling designs.</p>
<h3>Peacock Feathers</h3>
<p><span class="cc1" data-native-text="true">The following pattern, sometimes called the </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://marbleart.us/Peacock-Bouquet.htm#:~:text=The%20real%20name%20for%20this,the%20comb%20and%20the%20rake." target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc4" data-native-text="true">peacock, bouquet</span></a><span class="cc1" data-native-text="true">, or scallop shells, is often found in end-paper designs:</span></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/bouquet-2.png" alt="" width="354" height="442" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/bouquet-2-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/bouquet-2-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/bouquet-2-md.png 768w"></figure>
<p class="align-center"><em>Marbled endpaper from Die Nachfolge Christi ed. Ludwig Donin (Vienna ca. 1875) - Wikimedia Commons</em></p>
<p><span class="cc1" data-native-text="true">Following </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://people.csail.mit.edu/jaffer/Marbling/Scallops" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc4" data-native-text="true">instructions from Aubrey Jaffer's website</span></a><span class="cc1" data-native-text="true">, we can reproduce this design by combining geometric sine transformations and tine combing, starting with the striped canvas defined previously. The result is very regular, and might benefit from additional displacement from 2D noise for a more natural effect, or from the addition of noise to the tine.</span></p>
<p><em>Create a perfect scallop array marbling:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.48.20.png" alt="" width="589" height="441" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.20-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.20-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.20-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.48.35.png" alt="" width="584" height="519" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.35-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.35-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.48.35-md.png 768w"></figure>
<h3>Combinations of Dripping and Combing</h3>
<p>By alternating dripping and combing sequences, we can produce designs resembling ebru marbling. For example, by dripping, combing up and down, then dripping again with different colours:</p>
<p><em>Create a computational ebru marbling:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.49.23.png" alt="" width="596" height="560" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.23-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.23-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.23-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.49.43.png" alt="" width="544" height="533" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.43-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.43-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.49.43-md.png 768w"></figure>
<h2>The Marble-Tron: An Interactive Marbling Canvas</h2>
<p>Download <a href="https://community.wolfram.com/groups/-/m/t/3258063">this notebook</a> and make your own marbling designs with the interactive canvas below. </p>
<h4>Usage:</h4>
<ul>
<li>To add a drop of ink to the canvas, click the "Ink" radio button, choose your drop settings using the <em>Drop scale</em> slider.</li>
<li>By default, the colour selection is random for each ink drop. Click the "Manual" radio button to show manual colour selection tools.</li>
<li>To trace a tine line through the ink, click the "Tine" radio button, choose your tine settings using the <em>Tine z</em> and <em>Tine c</em> sliders, then click and drag the mouse along the screen. An arrow will follow your mouse pointer, giving you a preview of the tine settings. Release the mouse to apply the tine line to the canvas.</li>
</ul>
<p><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Screen capture of the interactive marbling canvas interface:</span></p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/41/Screenshot-2024-12-16-at-21.24.33.png" alt="" width="485" height="658" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.24.33-xs.png 300w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.24.33-sm.png 480w ,https://phileasdg.github.io/media/posts/41/responsive/Screenshot-2024-12-16-at-21.24.33-md.png 768w"></figure>
</div>
<div class="cell-content">
<h2>Conclusion</h2>
<p>This exploration into mathematical marbling showcases the power and flexibility of Wolfram Language for generative art exploration, process design, and process implementation. By combining mathematical transformations, we can simulate traditional marbling techniques digitally, opening up endless possibilities for experimentation and creativity.</p>
<p>One advantage of the vector graphics marbling methods explored in this text is that a marbling process will always output a list of polygons, making it easy to pick and modify colour schemes without having to recompute the marbling from scratch. These polygons can also be magnified and exported without loss of detail for prints, or further manually or programmatically manipulated. </p>
<p>I encourage you to try out these techniques and create your own marbling designs! Happy marbling! </p>
<h2>Acknowledgements and Sources Cited</h2>
<h3>Special Thank You to Aubrey Jaffer</h3>
<p>This article would not exist without Aubrey Jaffer's mathematical marbling articles, his kind support, and advice at the 2024 Wolfram Summer School. Aubrey's work provided the foundation for this exploration, and his guidance has been invaluable. Thank you, Aubrey, for your dedication to the art and science of marbling, and for inspiring us to delve deeper into this fascinating subject, and thank you again for presenting your work at the 2024 Wolfram Summer School.</p>
<h3>Sources Cited</h3>
<div id="cell-9bddc041-7da9-af48-a5be-2e27d70ab293" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div class="native-layout native-layout-simple"><a href="https://commons.wikimedia.org/wiki/File:Battal_Ebru.jpg"><span class="cc1" data-native-text="true">Akcire.14. (2020). Battal Ebru.</span></a></div>
</div>
</div>
</div>
<div id="cell-3b10e018-ef9a-2041-8cd4-5d10d278c7d3" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div>
<div class="native-layout native-layout-simple"><a href="https://commons.wikimedia.org/wiki/File:Marbled_endpaper_from_Die_Nachfolge_Christi_ed._Ludwig_Donin_(Vienna_ca._1875)_1000ppi_(cropped).png"><span class="cc1" data-native-text="true">Aristeas, C. (1875). English: Marbled endpaper from a copy of Die Nachfolge Christi in vier Büchern von Thomas von Kempis.</span></a></div>
</div>
</div>
</div>
</div>
<div id="cell-b5342346-ec7c-cf43-a463-21b2248273ce" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div>
<div class="native-layout native-layout-simple"><a href="https://people.csail.mit.edu/jaffer/Marbling/Mathematics"><span class="cc1" data-native-text="true">Jaffer, A. (n.d.). The Mathematics of Marbling. Retrieved 26 August 2024</span></a></div>
</div>
</div>
</div>
</div>
<div id="cell-080ad89a-93f5-f04d-ac94-d936423e66e2" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div>
<div class="native-layout native-layout-simple"><a href="https://doi.org/10.1109/MCG.2011.51"><span class="cc1" data-native-text="true">Shufang Lu, Jaffer, A., Xiaogang Jin, Hanli Zhao, &amp; Xiaoyang Mao. (2012). Mathematical Marbling. IEEE Computer Graphics and Applications, 32(6), 26–35.</span></a></div>
</div>
</div>
</div>
</div>
<div id="cell-f91b2dd1-29c9-ac49-b8c9-92f290dfeb43" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div>
<div class="native-layout native-layout-simple"><a href="https://www.skillshare.com/es/blog/suminagashi-aprende-el-arte-del-marmoleado-de-papel-japones/"><span class="cc1" data-native-text="true">Turner, E. (2022, April 13). Suminagashi: Aprende el arte del marmoleado de papel japonés. Skillshare Blog.</span></a></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Earth&#x27;s Hottest Day Ever Recorded - July 22, 2024 - Analysed and Visualised Through Climate Data</title>
        <author>
            <name>Phileas Dazeley-Gaist</name>
        </author>
        <link href="https://phileasdg.github.io/earths-hottest-day-ever-recorded-july-22-2024-analyzed-and-visualised-through-climate-data/"/>
        <id>https://phileasdg.github.io/earths-hottest-day-ever-recorded-july-22-2024-analyzed-and-visualised-through-climate-data/</id>
        <media:content url="https://phileasdg.github.io/media/posts/37/Hottest-day-on-earth-Social-Media-2.png" medium="image" />
            <category term="Work at Wolfram"/>
            <category term="Wolfram Language"/>
            <category term="Geography &amp; GIS"/>
            <category term="Environmental Science"/>

        <updated>2024-07-28T03:17:34-04:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://phileasdg.github.io/media/posts/37/Hottest-day-on-earth-Social-Media-2.png" alt="" />
                    July 22, 2024 was the hottest day in recorded history, according to&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://phileasdg.github.io/media/posts/37/Hottest-day-on-earth-Social-Media-2.png" class="type:primaryImage" alt="" /></p>
                <p>July 22, 2024 was the hottest day in recorded history, according to provisional data from the European climate service.</p>
<p class="msg msg--info"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forum. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href="https://community.wolfram.com/groups/-/m/t/3234937">here</a>. </p>
<h2>Introduction</h2>
<p>On July 24 2024, <a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://apnews.com/article/hottest-day-ever-climate-change-weather-heat-extreme-global-warming-8e2b0b7fa0360ecb931ca333a832c694" target="_blank" data-testid="ButtonBoxView" rel="noopener" style="font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);"><span class="cc9" data-native-text="true">the Associated Press reported that July 22, 2024 broke the record for the hottest day ever recorded on earth</span></a><span class="cc7" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true">, according to provisional data from the European climate service, Copernicus.</span></p>
<div id="cell-1755bd5b-dc13-3440-bbb3-c2a8c2f106dd" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div>
<div class="native-layout native-layout-simple"><span class="cc7" data-native-text="true">In the article, Sibi Arasu and Seth Borenstein report that “Monday was 0.06 degrees Celsius (0.1 degree Fahrenheit) hotter than Sunday, which was .01 degrees Celsius hotter (0.2 degrees Fahrenheit) than the previous hottest day on record, July 6, 2023.”</span></div>
</div>
</div>
</div>
</div>
<div id="cell-48e7de22-8d3e-244e-a6a3-142436e30a7d" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div>
<div class="native-layout native-layout-simple"><span class="cc7" data-native-text="true">The data they cite are from the </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc9" data-native-text="true">ECMWF Reanalysis v5 (ERA5) dataset</span></a><span class="cc7" data-native-text="true">, which provides hourly spatial estimates of many of atmospheric, land and oceanic climate variables, including surface air temperature and sea surface temperature, daily, from 1940 to the present day.</span></div>
</div>
</div>
</div>
</div>
<div id="cell-8862fa9c-62ac-2b4b-b299-cb9d9452881e" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div class="native-layout native-layout-simple"><span class="cc7" data-native-text="true">While Copernicus provides free access to these data, the size of raw dataset files (which are large gridded data layer stacks stored in NetCDF format) makes many ad hoc analyses prohibitively expensive. However, and fortunately, Copernicus and the University of Maine’s Climate Change Institute both provide trackers for the average global temperature based on ERA5 data. These are:</span></div>
<div id="cell-c05329c8-883f-a443-8d6b-fc38e8ce5332" class="cell">
<ul>
<li class="cell-wrapper"><span class="cc7" data-native-text="true">Copernicus’ Climate Pulse: </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://pulse.climate.copernicus.eu/" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc9" data-native-text="true">https://pulse.climate.copernicus.eu/</span></a><span class="cc7" data-native-text="true"> (near real time, typically 2 days behind)</span></li>
<li class="native-layout native-layout-simple"><span class="cc7" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true">The University of Maine’s Climate Reanalyzer: </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://climatereanalyzer.org/clim/t2_daily/?dm_id=world" target="_blank" data-testid="ButtonBoxView" rel="noopener" style="font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);"><span class="cc9" data-native-text="true">https://climatereanalyzer.org/clim/t2_daily/?dm_id=world</span></a><span class="cc7" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true"> (a few more days delay)</span></li>
</ul>
</div>
<div id="cell-6a3b29c0-a328-8948-934c-6fce8fd3047b" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div class="native-layout native-layout-simple"><span class="cc7" data-native-text="true">How easy would it be to import and study these data in the Wolfram Language? Let’s find out.</span></div>
<h2>Getting Global Mean Surface Temperature Data</h2>
<h3>Importing and Preprocessing Data from Climate Pulse:</h3>
<p><span class="cc7" data-native-text="true">Climate Pulse conveniently provides a </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://sites.ecmwf.int/data/climatepulse/data/series/era5_daily_series_2t_global.csv" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc9" data-native-text="true">link</span></a><span class="cc7" data-native-text="true"> to download a table of global surface air temperature data from 1940 to the latest data available. Let’s import these data:</span></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.20.10.png" alt="" width="2014" height="180" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.10-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.10-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.10-md.png 768w"></figure>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.20.43.png" alt="" width="371" height="190" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.43-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.43-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.20.43-md.png 768w"></figure>
<p>Neat! The columns key (dropped from the .csv table during the import) defines the columns as: </p>
<p><code># Columns:</code><br><br><code>#  2t: Daily mean absolute temperature based on hourly values from 00 to 23 UTC</code><br><code>#  clim_91-20: Daily climatology for 1991-2020</code><br><code>#  ano_91-20: Daily anomaly relative to the 1991-2020 daily climatology</code><br><code>#  status: Preliminary or final</code><br><br><code># Units: deg. C</code><br><code># Last updated: 25 Jul 2024</code></p>
<p>To construct time series from these data, it'll help to convert the values from the date column into Wolfram Language date objects:</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.21.51.png" alt="" width="2204" height="76" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.21.51-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.21.51-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.21.51-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.22.06.png" alt="" width="371" height="186" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.06-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.06-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.06-md.png 768w"></figure>
<h3>Constructing and Plotting Time Series from the Data:</h3>
<p>Now that we have the data, we can get a time series of daily mean absolute temperatures like so:</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.22.57.png" alt="" width="1490" height="62" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.57-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.57-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.22.57-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.23.35.png" alt="" width="352" height="66" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.23.35-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.23.35-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.23.35-md.png 768w"></figure>
<p>Plotting it is as easy as: </p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.24.05.png" alt="" width="548" height="96" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.05-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.05-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.05-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.24.32.png" alt="" width="1458" height="982" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.32-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.32-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.24.32-md.png 768w"></figure>
<h3>Verifying the Claims Made by the AP &amp; Others:</h3>
<p>Based on these data, was the hottest day on record really last Monday? Let's confirm:</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.25.02.png" alt="" width="270" height="29" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.02-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.02-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.02-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.25.15.png" alt="" width="371" height="67" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.15-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.15-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.15-md.png 768w"></figure>
<p>What were the top 5 hottest recorded days since 1940?</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.25.45.png" alt="" width="276" height="26" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.45-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.45-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.25.45-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.26.05.png" alt="" width="373" height="155" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.05-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.05-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.05-md.png 768w"></figure>
<p>Note that the top four hottest days on record were this month.</p>
<h2>Reproducing the Famous Global Mean Surface Temperature Multi-Year Overlay Plot</h2>
<p>With the data we have collected, we can now reproduce the now famous year over year plot of global mean surface temperatures from Climate Pulse.</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.26.54.png" alt="" width="2610" height="1398" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.54-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.54-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.26.54-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.27.20.png" alt="" width="1266" height="1586" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.27.20-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.27.20-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.27.20-md.png 768w"></figure>
<h2>Getting These Data for Specific Time Ranges and Regions from Climate Reanalyzer</h2>
<p>It would be helpful to have a function that automates the process of importing these data for different available regions and time ranges. <br>This task is quite straightforward using data from Climate Reanalyzer.</p>
<p><em>Define a function to import time series from Climate Reanalyzer:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.28.05.png" alt="" width="1978" height="424" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.28.05-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.28.05-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.28.05-md.png 768w"></figure>
<p>The function supports importing data from six regions, specified with the area parameter: </p>
<ul>
<li>"World" ---&gt; The whole world, 90°S-90°N, 0-360°E</li>
<li>"NH" ---&gt; The northern hemisphere, 0-90°N, 0-360°E</li>
<li>"SH" ---&gt; The southern hemisphere, 0-90°S, 0-360°E</li>
<li>"Arctic" ---&gt; 66.5-90°N, 0-360°E</li>
<li>"Antarctic" ---&gt; 66.5-90°S, 0-360°E</li>
<li>"Tropics" ---&gt; 23.5°S-23.5°N, 0-360°E</li>
</ul>
<p>And takes an optional second argument specifying the start and end date for the requested data range in a list (from January 1st 1940 to seven days ago).</p>
<p>Consider the following examples:</p>
<p><em>Request and plot the time series of daily surface temperatures in the Arctic from 1990 to 2000:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.29.31.png" alt="" width="530" height="126" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.29.31-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.29.31-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.29.31-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.31.09.png" alt="" width="1180" height="786" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.09-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.09-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.09-md.png 768w"></figure>
<h2>Map Animations:</h2>
<p>Climate Pulse hosts recent raster maps of global surface temperatures. Here is the one corresponding to last Monday:</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.31.40.png" alt="" width="1348" height="784" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.40-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.40-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.31.40-md.png 768w"></figure>
<p>I'd like to take a moment to highlight my RemoteSensing paclet, which presently provides a WL interface to NASA's GIBS and AppEEARS APIs for remote sensing data retrieval. While my paclet does not yet support access to Copernicus ERA5 data (look out for future releases), GIBS and AppEEARS both provide access to similar data products, which we can import and work with directly in the Wolfram Language.</p>
<p>Please feel free to consult the paclet documentation here: <a href="https://resources.wolframcloud.com/PacletRepository/resources/PhileasDazeleyGaist/RemoteSensing/">https://resources.wolframcloud.com/PacletRepository/resources/PhileasDazeleyGaist/RemoteSensing/</a></p>
<p><em>To install the paclet, run the following code: </em></p>
<p><em><code>PacletInstall["PhileasDazeleyGaist/RemoteSensing"]</code></em></p>
<p><em>Load the paclet: </em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.32.55.png" alt="" width="347" height="29" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.32.55-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.32.55-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.32.55-md.png 768w"></figure>
<p><em>Using GIBSData, list global surface air temperature products:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.33.17.png" alt="" width="1520" height="44" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.17-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.17-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.17-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.33.30.png" alt="" width="2434" height="96" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.30-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.30-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.33.30-md.png 768w"></figure>
<p><em>Animate a map using one of these products:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Screenshot-2024-07-28-at-03.37.14.png" alt="" width="1732" height="212" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.37.14-xs.png 300w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.37.14-sm.png 480w ,https://phileasdg.github.io/media/posts/37/responsive/Screenshot-2024-07-28-at-03.37.14-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/37/Animation2.gif" alt="" width="1114" height="484"></figure>
<h2>Conclusion</h2>
<p>In this article, we've explored how one can readily access and analyse global climate data using the Wolfram Language. We've shown how one can pull daily global mean surface air temperature data from specific geographical ranges and plot the data over time, as well as how to import recent raster maps of global surface temperatures from Copernicus' Climate Pulse. We've also highlighted the RemoteSensing paclet, a powerful tool that can interface with NASA's GIBS and AppEEARS APIs for convenient remote sensing data retrieval. </p>
<p>With these functionalities, researchers in climate science and related fields are better equipped to analyse and interpret vast amounts of climate data right from within the Wolfram Language.</p>
<p> </p>
</div>
</div>
</div>
</div>
</div>
</div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>A Forest Fire Model in 1, 2, and 3 Dimensions</title>
        <author>
            <name>Phileas Dazeley-Gaist</name>
        </author>
        <link href="https://phileasdg.github.io/a-forest-fire-model-in-1-2-and-3-dimensions/"/>
        <id>https://phileasdg.github.io/a-forest-fire-model-in-1-2-and-3-dimensions/</id>
        <media:content url="https://phileasdg.github.io/media/posts/36/Animation1.gif" medium="image" />
            <category term="Work at Wolfram"/>
            <category term="Programming"/>
            <category term="Modelling"/>
            <category term="Environmental Science"/>
            <category term="Ecology"/>
            <category term="Complex Systems"/>
            <category term="Cellular Automata"/>
            <category term="Art"/>

        <updated>2024-05-03T17:38:15-04:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://phileasdg.github.io/media/posts/36/Animation1.gif" alt="" />
                    Note: This post was originally a short technical article I shared on&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://phileasdg.github.io/media/posts/36/Animation1.gif" class="type:primaryImage" alt="" /></p>
                <p class="msg msg--info"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forum. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href="https://community.wolfram.com/groups/-/m/t/3096615?p_p_auth=jA2YdLGR">here</a>. </p>
<h2>Introduction</h2>
<p>The forest fire model is one of the simplest computational models to display self-organised criticality. The model is a probabilistic cellular automaton with the following rules. At each computation/time step:</p>
<div id="cell-c6d531d9-bde4-e940-8566-2ff3288d6302" class="cell">
<div class="cell-wrapper">
<div class="cell-content">
<ul>
<li class="native-layout native-layout-simple"><span class="cc3" data-native-text="true">Trees on fire burn down, leaving wasteland.</span></li>
<li>Trees catch fire if they are adjacent to at least one tree already on fire.</li>
<li>Tree cells catch fire independently with probability <em>P(f)</em></li>
<li>Trees grow in wasteland cells with probability <em>P(t)</em></li>
</ul>
<p>We'll use the following values for the possible cell states:</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.32.53.png" alt="" width="397" height="165" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.32.53-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.32.53-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.32.53-md.png 768w"></figure>
<p>Here is a visualisation of the fire-spreading process in two-dimensions, with <em>P(t)</em> and <em>P(f)</em> set to 0:</p>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.35.46.png" alt="" width="619" height="119" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.35.46-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.35.46-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.35.46-md.png 768w"></figure>
<p>In the implementation that follows, the <code>forestFireStep</code> function computes simulation steps. <em>P(f)</em> is specified using the option <code>"NewFireProb"</code>, and <em>P(t)</em> with <code>"NewTreeProb"</code>. I have introduced the two additional (optional) terms <code>"MaxNewFires"</code> and <code>"MaxNewTrees"</code>, allowing the user to specify the maximum numbers of new fires and trees per step in addition to the probabilities of spontaneous ignition and new tree growth. This allows for more intuitive and varied system setups.</p>
<h2>Implementation: Forest Fire Functions</h2>
<p><em>Retrieve the positions of trees, actively burning fires, and wasteland:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.37.56.png" alt="" width="259" height="104" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.37.56-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.37.56-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.37.56-md.png 768w"></figure>
<p><em>Retrieve the positions of trees adjacent to actively burning fires in the landscape:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.38.21.png" alt="" width="673" height="115" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.21-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.21-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.21-md.png 768w"></figure>
<p><em>Compute a forest fire simulation step:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.38.46.png" alt="" width="1772" height="802" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.46-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.46-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.38.46-md.png 768w"></figure>
<h2>Performing Forest Fire Simulations</h2>
<p>Given an array defining the initial state of a landscape, the forestFireStep function returns the state of the landscape at the following time step. We'll see in a moment that it is flexible enough to be used to perform simulations in one, two, and three dimensions.</p>
<h3>Forest Fires on 2D Arrays</h3>
<p><em>Generate some forests:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.39.30.png" alt="" width="549" height="165" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.30-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.30-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.30-md.png 768w"></figure>
<p><em>Compute a single step of a forest fire simulation on a 2D array:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-08-at-16.39.54.png" alt="" width="553" height="286" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.54-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.54-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-08-at-16.39.54-md.png 768w"></figure>
<p>You can specify the probabilities that tree cell spontaneously will catch fire, or that a wasteland cell will grow a tree with the <code>"NewFireProb"</code> and <code>"NewTreeProb"</code> options. Likewise, you can specify the maximum number of new fires or trees per step by specifying the options <code>"MaxNewFires"</code> and <code>"MaxNewTrees"</code>.</p>
<p><em>Compute and animate 200 steps of a forest fire trajectory in a light forest with gaps and clearings:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-11.44.00.png" alt="" width="385" height="165" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.44.00-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.44.00-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.44.00-md.png 768w"></figure>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/ForestFireAnim1.gif" alt="" width="530" height="404"></figure>
<p><span class="cc3" data-native-text="true">By default, </span><code><span class="cc6" data-native-text="true">“MaxNewFires”</span></code><span class="cc3" data-native-text="true"> and </span><code><span class="cc6" data-native-text="true">“MaxNewTrees”</span></code><span class="cc3" data-native-text="true"> are set to </span><code><span class="cc4" data-native-text="true">∞</span></code><span class="cc3" data-native-text="true">. When this is the case, the occurrence of new fires or trees is determined entirely by the <span class="cc6" data-native-text="true"><code>“NewFireProb”</code></span></span> <span class="cc3" data-native-text="true">and </span><code><span class="cc6" data-native-text="true">“NewTreeProb”</span></code><span class="cc3" data-native-text="true"> options.</span></p>
<p><em>Compute and animate 200 steps of a forest fire trajectory on a partitioned landscape:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-11.46.43.png" alt="" width="370" height="121" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.46.43-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.46.43-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.46.43-md.png 768w"></figure>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/ForestFireAnim2.gif" alt="" width="529" height="402"></figure>
<p><em>Compute and animate 200 steps of a forest fire trajectory exhibiting self-organised criticality:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-11.50.24.png" alt="" width="390" height="221" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.50.24-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.50.24-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.50.24-md.png 768w"></figure>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/ForestFireAnim3.gif" alt="" width="529" height="403"></figure>
<p><em>Produce time-series and phase space plots for the trajectory above:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-05-20-at-13.17.34.png" alt="" width="1402" height="976" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-20-at-13.17.34-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-20-at-13.17.34-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-05-20-at-13.17.34-md.png 768w"></figure>
<h3>One-Dimensional Forest Fires</h3>
<p>We can apply the forest fire rules to one dimensional arrays as we would apply them in two dimensions. Rather than spreading to adjacent cells in two spatial dimensions, then, fires only spread along one.</p>
<div id="cell-3e894a24-cbce-354d-8f40-865531a2b60e" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div>
<div class="native-layout native-layout-simple"><span class="cc3" data-native-text="true">Following the convention for 1-dimensional cellular automata, we stack the arrays for subsequent time steps vertically and in sequence. In the resulting graphic, space is represented horizontally and time flows vertically from top to bottom.</span></div>
<div>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-11.54.01.png" alt="" width="530" height="292" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.54.01-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.54.01-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-11.54.01-md.png 768w"></figure>
<p>See some one dimensional trajectories in the animation below, or head to <a href="https://community.wolfram.com/groups/-/m/t/3096615">the original post </a>to see an interactive example:</p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-12.07.29.png" alt="" width="609" height="208" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-12.07.29-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-12.07.29-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-12.07.29-md.png 768w"></figure>
<figure class="post__image align-center"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/ForestFireAnim4-2.gif" alt="" width="434" height="499"></figure>
<h3>Forest Fires in 3D</h3>
<p>In three dimensions, we can also define forested landscapes with more complicated topographies, for example, by layering different cell types. </p>
<p>The following example is of a forested layer on top of a layer of soil. Both layers vary in thickness (check out <a href="https://community.wolfram.com/groups/-/m/t/3096615">the original post</a> for the interactive version).</p>
<p><em>Three-dimensional forest fire model trajectories through a dense hilly forest.</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-13.16.57.png" alt="" width="1378" height="616" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.16.57-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.16.57-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.16.57-md.png 768w"></figure>
<p>Depending on the forest initial configuration, it can be difficult to visualise all cell states at once. This is the case for forest fire trajectories through dense volumes of trees, for example:</p>
<p><em>Three-dimensional forest fire model trajectories through a cubic forest:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/36/Screenshot-2024-07-26-at-13.17.50.png" alt="" width="1378" height="852" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.17.50-xs.png 300w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.17.50-sm.png 480w ,https://phileasdg.github.io/media/posts/36/responsive/Screenshot-2024-07-26-at-13.17.50-md.png 768w"></figure>
<h3>Closing Note</h3>
<p>I hope you found these examples interesting and entertaining! The implementation discussed in this short text should in principle work for higher than 3-dimensional arrays but I have not tested it for such cases. If you do, please make sure to share your results in the comment section under this post. In fact, please feel free to share any interesting behaviours you find or modifications you make in the comments! I look forward to hearing your ideas and suggestions! </p>
<h3>Sources</h3>
<ul>
<li><a href="https://en.wikipedia.org/w/index.php?title=Forest-fire_model&amp;oldid=\%201170972820">'Forest-Fire Model'. In Wikipedia, 18 August 2023.</a></li>
<li><a href="https://mathematica.stackexchange.com/questions/39793/can-you-apply-the-cellular-automata-function-to-a-grid-containing-numbers/39863#39863">E, C. 'Answer to "Can You Apply the Cellular Automata Function to a Grid Containing Numbers?"' Mathematica Stack Exchange, 5 January 2014.</a></li>
<li><a href="https://www.sciencedirect.com/science/article/abs/pii/037596019090451S?via%3Dihub">Bak, Per, Kan Chen, and Chao Tang. 'A Forest-Fire Model and Some Thoughts on Turbulence'. Physics Letters A 147, no. 5 (16 July 1990): 297\[Dash]300.</a></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>A Dynamical Model of Immune-System Response to mRNA, Live Virus, and Inactivated Vaccines</title>
        <author>
            <name>Phileas Dazeley-Gaist</name>
        </author>
        <link href="https://phileasdg.github.io/a-dynamical-model-of-immune-system-response-to-mrna-live-virus-and-inactivated-vaccines-2/"/>
        <id>https://phileasdg.github.io/a-dynamical-model-of-immune-system-response-to-mrna-live-virus-and-inactivated-vaccines-2/</id>
        <media:content url="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.14.00.png" medium="image" />
            <category term="Work at Wolfram"/>
            <category term="Wolfram Language"/>
            <category term="Programming"/>
            <category term="Network Science"/>
            <category term="Modelling"/>
            <category term="Complex Systems"/>

        <updated>2024-05-02T09:44:47-04:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.14.00.png" alt="" />
                    Note: This post was originally a short technical article I shared on&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.14.00.png" class="type:primaryImage" alt="" /></p>
                <p class="msg msg--info"><strong>Note: </strong>This post was originally a short technical article I shared on the Wolfram Community forum. For an interactive experience with live demonstrations or to download this text and source code as a Wolfram Notebook, please visit the original post <a href="https://community.wolfram.com/groups/-/m/t/3055726">here</a>. </p>
<p class="msg msg--highlight "><span class="cc1" data-native-text="true"><strong>Source article:</strong> Zhaobin Xu, Jian Song, Hongmei Zhang, Zhenlin Wei, Dongqing Wei, Jacques Demongeot, A Mathematical Model Simulating the Adaptive Immune Response in Various Vaccines and Vaccination Strategies, medRxiv 2023.10.05.23296578. DOI: </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://doi.org/10.1101/2023.10.05.23296578" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc3" data-native-text="true">https://doi.org/10.1101/2023.10.05.23296578</span></a></p>
<h2>Introduction:</h2>
<p><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">The accomplishments of vaccination are numerous, leading to significant advances in human health. Yet new infectious diseases and evolving pathogens constantly challenge our understanding of vaccine efficacy and immunity. Mathematical modelling is a crucial lens through which we can reach a more comprehensive understanding of these complexities. By simulating the biological responses to vaccines, models can provide critical insights into disease progression, vaccine performance, and optimal strategies for developing vaccines.</span></p>
<div id="cell-fe47751b-0fbc-4ad3-bab0-ee4f1dd22fb8" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div>
<div class="native-layout native-layout-simple"><span class="cc6" data-native-text="true">In this short text, we’ll explore an approach to constructing one such model in the Wolfram Language. We will reproduce a compartmental dynamical model of adaptive immune responses to vaccine treatments described in a recent preprint from medRxiv.org: </span><span class="cc14" data-native-text="true">A Mathematical Model Simulating the Adaptive Immune Response in Various Vaccines and Vaccination Strategies</span> <a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://www.medrxiv.org/content/10.1101/2023.10.05.23296578v1" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc9" data-native-text="true">(Xu et al. 2023)</span></a><span class="cc6" data-native-text="true">. Compartmental models are a class of mathematical models which divide variables of interest into sections or “compartments”. Each compartment represents a specific state within the system being studied. The models track how entities, like cells or molecules, interact within and between these compartments over time.</span></div>
</div>
</div>
</div>
</div>
<div id="cell-95dd72c5-3543-4f12-a9d7-8486a64fa8f9" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div class="native-layout native-layout-simple"><span class="cc6" data-native-text="true">The stated goal of the paper is to construct a novel mathematical model to quantitatively research the activation of adaptive immune responses by vaccines. This model is used to simulate and compare the dynamics of antibody levels after administering different types of vaccines (inactivated, attenuated live virus, mRNA), thereby contributing to a better understanding of the mechanisms of various vaccines and vaccination strategies. Through the model, the authors aim to suggest strategies for vaccine design, while providing a comprehensive portrait of the inducible interactions between antibodies and antigens in the immune process.</span></div>
<h2>Setup</h2>
<h3>Dependencies</h3>
<p><span class="cc6" data-native-text="true">We will make use of the </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://resources.wolframcloud.com/PacletRepository/resources/RobertNachbar/CompartmentalModeling/" target="_blank" data-testid="ButtonBoxView" id="aui_3_4_0_1_433" rel="noopener"><span class="cc9" data-native-text="true">CompartmentalModelling</span></a><span class="cc6" data-native-text="true"> paclet. You can install and load the paclet like so:</span></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-09.49.26.png" alt="" width="560" height="178" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-09.49.26-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-09.49.26-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-09.49.26-md.png 768w"></figure>
<p><span class="cc6" data-native-text="true">You can find documentation for this paclet by following </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://resources.wolframcloud.com/PacletRepository/resources/RobertNachbar/CompartmentalModeling/" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc9" data-native-text="true">this link</span></a><span class="cc6" data-native-text="true">.</span></p>
<h3>Paper Tables</h3>
<p>You can find the definitions for the tables of reactions, reaction variables, and reaction parameters in the original version of this post on <a href="https://community.wolfram.com/groups/-/m/t/3055726">Wolfram Community</a>.</p>
<h2>Reactions, Parameters, and State Variables of the Model</h2>
<p>The authors of the paper helpfully provide three tables fully specifying the interactions between state variables (components) of the system, as well as model parameters and initial conditions. I have reproduced these tables below. Note that some parameter values and initial conditions depend on the selected vaccine treatment type. More precisely:</p>
</div>
<ul>
<li>The replication rate of viral antigens, described by parameter k_14 should be set to .3 in the case of a simulation of an attenuated live virus vaccine, and 0 otherwise.</li>
<li>The initial condition of the state variable x_2 (Antigen) should be set to 10^6 for simulation with an inactivated vaccine, 0 with an mRNA vaccine, and 1 for an attenuated live virus vaccine.</li>
<li>The initial condition of the state variable x_9 <span class="cc6" data-native-text="true"> (mRNA) should be set to 0 for simulation with an inactivated or attenuated live virus vaccine, and 10^6</span><span class="cc6" data-native-text="true"> for and mRNA vaccine.</span></li>
</ul>
<p><span class="cc6" data-native-text="true">For a more in depth explanation of these parameters and initial conditions, please refer to </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://www.medrxiv.org/content/10.1101/2023.10.05.23296578v1" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc9" data-native-text="true">the paper</span></a><span class="cc6" data-native-text="true">.</span></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.05.51.png" alt="" width="1266" height="1226" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.05.51-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.05.51-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.05.51-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.06.39.png" alt="" width="1330" height="1144" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.39-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.39-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.39-md.png 768w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.06.54.png" alt="" width="1330" height="578" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.54-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.54-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.06.54-md.png 768w"></figure>
<h2>Extracting Model Information</h2>
<p><span class="cc6" data-native-text="true">We can use tools from the </span><strong><span class="cc39" data-native-text="true">CompartmentalModelling</span></strong><span class="cc6" data-native-text="true"> paclet to extract useful information about the model. For instance, we can use </span><strong><span class="cc39" data-native-text="true">CompartmentalModelGraph</span></strong><span class="cc6" data-native-text="true"> from the CompartmentalModelling paclet to visualise the model’s structure:</span></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.10.06.png" alt="" width="1682" height="840" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.10.06-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.10.06-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.10.06-md.png 768w"></figure>
<p><span class="cc6" data-native-text="true">The </span><span class="cc39" data-native-text="true">CompartmentalModelling</span><span class="cc6" data-native-text="true"> paclet contains convenient functions to streamline the process of building models. For instance, we can use </span><strong><span class="cc39" data-native-text="true">KineticCompartmentalModel</span></strong><span class="cc6" data-native-text="true"> to generate differential equations for from a list of component transitions (the reactions).</span></p>
<p><em>Fetch the model data:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.16.18.png" alt="" width="476" height="929" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.16.18-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.16.18-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.16.18-md.png 768w"></figure>
<p>These data are very useful for quickly building and simulating compartmental models.</p>
<h2>Numerical Simulations</h2>
<h3>Preparing Model ODEs</h3>
<p><span class="cc8" data-native-text="true">Owing to details related to the original code implementation of the model, the authors provide a slightly modified system of ODEs describing the model. This system is reproduced below and numerically approximated using </span><span class="cc42" data-native-text="true">NDSolve</span><span class="cc8" data-native-text="true"> for different vaccine treatments:</span></p>
<p><em>Reproduce the ODEs from the paper:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.17.43.png" alt="" width="1308" height="484" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.17.43-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.17.43-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.17.43-md.png 768w"></figure>
<p>Let’s also get some replacement rules to easily convert between the variable names in plain English, and the symbols used in the paper for the model’s system of ODEs.</p>
<p><em>Plain English variables &lt;--&gt; ODE variables:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.18.28.png" alt="" width="588" height="57" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.18.28-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.18.28-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.18.28-md.png 768w"></figure>
<h3>Vaccine Treatment Simulations</h3>
<p>In the paper, the authors model three cases:</p>
<ol>
<li>Inactivated Vaccine Simulation</li>
<li>Attenuated Live Virus Vaccine</li>
<li>mRNA Vaccine</li>
</ol>
<p><span class="cc8" data-native-text="true">These cases are solved numerically in the three following sections. The inactivated vaccine and mRNA vaccines each take two injections, one at one at </span></p>
<div>
<div class="lines"><span class="pa ch cc17" data-token-box-id="c2832" data-token-text="t">t</span><span class="pa char cc10" data-token-box-id="c2833" data-token-text="=">=</span><span class="pa ch cc8" data-token-box-id="c2834" data-token-text="0">0</span><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">, the other at </span><span class="pa ch cc17" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2841" data-token-text="t">t</span><span class="pa char cc10" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2842" data-token-text="=">=</span><span class="pa ch cc8" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2843" data-token-text="50">50</span><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">. The attenuated live-virus vaccine takes a single dose at </span><span class="pa ch cc17" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2850" data-token-text="t">t</span><span class="pa char cc10" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2851" data-token-text="=">=</span><span class="pa ch cc8" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2852" data-token-text="0">0</span><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">. The injection dosage is of </span><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">6^</span><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">10</span><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);"> for all simulations.</span></div>
<h3>1. Inactivated Vaccine Simulation</h3>
<p>Model-specific parameters and initial conditions:</p>
<ul>
<li><span class="cc8" data-native-text="true">Replication rate of viral antigens: </span>k_<span class="pa char cc19" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2605" data-token-text="14">14</span><span class="pa char cc10" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2607" data-token-text="=">=</span><span class="pa ch cc8" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2608" data-token-text="0">0</span></li>
<li><span class="cc8" data-native-text="true">Antigen = </span>x_<span class="pa char cc19" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2627" data-token-text="2">2</span><span class="pa char cc10" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2629" data-token-text="[">[</span><span class="pa ch cc8" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2630" data-token-text="0">0</span><span class="pa char cc10" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2631" data-token-text="]">]</span><span class="cc8" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true"> = </span><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">10^6</span></li>
<li><span class="cc8" data-native-text="true">mRNA = </span>x_9[<span class="pa ch cc8" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2664" data-token-text="0">0</span><span class="pa char cc10" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2665" data-token-text="]">]</span><span class="cc8" data-native-text="true"> = 0</span></li>
</ul>
<p><em>Define model parameters corresponding to the inactivated vaccine setup:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.21.55.png" alt="" width="1484" height="186" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.21.55-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.21.55-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.21.55-md.png 768w"></figure>
<p><em>Define initial conditions of the system corresponding to the inactivated vaccine setup:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.22.21.png" alt="" width="1414" height="632" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.21-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.21-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.21-md.png 768w"></figure>
<p><em>Construct the system of equations for NDSolve, with parameter values and initial conditions:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.22.40.png" alt="" width="599" height="29" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.40-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.40-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.22.40-md.png 768w"></figure>
<p><em><span class="cc25" data-native-text="true">Solve numerically with NDSolve, from </span></em><span class="pa ch cc47" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2737" data-token-text="t">t</span><span class="pa char cc27" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2738" data-token-text="=">=</span><span class="pa ch cc25" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2739" data-token-text="0">0</span><em><span class="cc25" data-native-text="true"> to </span></em><span class="pa ch cc47" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2746" data-token-text="t">t</span><span class="pa char cc27" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2747" data-token-text="=">=</span><span class="pa ch cc25" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2748" data-token-text="100">100</span><em><span class="cc25" data-native-text="true">:</span></em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.23.23.png" alt="" width="485" height="29" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.23-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.23-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.23-md.png 768w"></figure>
<p><em>Plot the solution:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.23.50.png" alt="" width="1448" height="642" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.50-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.50-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.23.50-md.png 768w"></figure>
<h3>2. Attenuated Live Virus Vaccine</h3>
<p>Model-specific parameters and initial conditions:</p>
<ul>
<li><span class="cc8" data-native-text="true">Replication rate of viral antigens: </span>k_<span class="pa char cc19" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2605" data-token-text="14">14</span><span class="pa char cc10" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2607" data-token-text="=">=</span><span class="pa ch cc8" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2608" data-token-text="0">0.3</span></li>
<li><span class="cc8" data-native-text="true">Antigen = </span>x_<span class="pa char cc19" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2627" data-token-text="2">2</span><span class="pa char cc10" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2629" data-token-text="[">[</span><span class="pa ch cc8" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2630" data-token-text="0">0</span><span class="pa char cc10" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2631" data-token-text="]">]</span><span class="cc8" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-native-text="true"> = 1</span></li>
<li><span class="cc8" data-native-text="true">mRNA = </span>x_9[<span class="pa ch cc8" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2664" data-token-text="0">0</span><span class="pa char cc10" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2665" data-token-text="]">]</span><span class="cc8" data-native-text="true"> = 0</span></li>
</ul>
<p><em>Define model parameters corresponding to the inactivated vaccine setup:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.25.32.png" alt="" width="1484" height="194" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.32-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.32-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.32-md.png 768w"></figure>
<p><em>Define initial conditions of the system corresponding to the inactivated vaccine setup:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.25.49.png" alt="" width="1402" height="638" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.49-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.49-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.25.49-md.png 768w"></figure>
<p><em>Construct the system of equations for NDSolve, with parameter values and initial conditions:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.26.00.png" alt="" width="378" height="35" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.00-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.00-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.00-md.png 768w"></figure>
<p><em><span class="cc25" data-native-text="true">Solve numerically with NDSolve, from </span></em><span class="pa ch cc47" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2737" data-token-text="t">t</span><span class="pa char cc27" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2738" data-token-text="=">=</span><span class="pa ch cc25" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2739" data-token-text="0">0</span><em><span class="cc25" data-native-text="true"> to </span></em><span class="pa ch cc47" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2746" data-token-text="t">t</span><span class="pa char cc27" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2747" data-token-text="=">=</span><span class="pa ch cc25" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);" data-token-box-id="c2748" data-token-text="100">100</span><em><span class="cc25" data-native-text="true">:</span></em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.26.19.png" alt="" width="494" height="38" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.19-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.19-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.19-md.png 768w"></figure>
<p><em>Plot the solution:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.26.44.png" alt="" width="1478" height="646" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.44-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.44-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.26.44-md.png 768w"></figure>
<h3>3. mRNA Vaccine</h3>
<p>Model-specific parameters and initial conditions:<br><br>Replication rate of viral antigens: k_14=0<br>Antigen = x_2[0] = 0<br>mRNA = x_9[0] = 10^6</p>
<p><em>Define model parameters corresponding to the inactivated vaccine setup:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.30.46.png" alt="" width="1492" height="206" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.30.46-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.30.46-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.30.46-md.png 768w"></figure>
<p><em>Define initial conditions of the system corresponding to the inactivated vaccine setup:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.31.19.png" alt="" width="1398" height="646" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.19-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.19-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.19-md.png 768w"></figure>
<p><em>Construct the system of equations for NDSolve, with parameter values and initial conditions:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.31.32.png" alt="" width="649" height="37" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.32-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.32-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.32-md.png 768w"></figure>
<p><em>Solve numerically with NDSolve, from t=0 to t=100:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.31.48.png" alt="" width="519" height="37" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.48-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.48-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.31.48-md.png 768w"></figure>
<p><em>Plot the solution:</em></p>
<figure class="post__image"><img loading="lazy"  src="https://phileasdg.github.io/media/posts/35/Screenshot-2024-05-02-at-10.32.06.png" alt="" width="1460" height="646" sizes="(max-width: 48em) 100vw, 100vw" srcset="https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.32.06-xs.png 300w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.32.06-sm.png 480w ,https://phileasdg.github.io/media/posts/35/responsive/Screenshot-2024-05-02-at-10.32.06-md.png 768w"></figure>
<h2>Closing Notes</h2>
<div id="cell-54b896b0-0f0b-4cac-9367-cb44dc59b1b4" class="cell">
<div class="cell-wrapper">
<div class="cell-content">
<div>
<div> </div>
<div class="native-layout native-layout-simple"><span class="cc8" data-native-text="true">Through the exploration of this dynamical immune response model, we have seen how mathematical modelling in the Wolfram Language, can be used to derive insights into complex biological systems.</span></div>
</div>
</div>
</div>
</div>
<div id="cell-952802b4-cfde-45ea-bf61-c9cfcec97f25" class="cell">
<div class="cell-wrapper">
<div class="_3Dqn7hOe5vVS6Nh0S54gcV"> </div>
<div class="cell-content">
<div>
<div class="native-layout native-layout-simple"><span class="cc8" data-native-text="true">If you are interested in this work, and would like to learn more, please make sure to give the </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://www.medrxiv.org/content/10.1101/2023.10.05.23296578v1" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc11" data-native-text="true">source paper </span></a><span class="cc8" data-native-text="true">a read! I primarily intend this post to demonstrate how one might conduct this form of modelling in the Wolfram Language. I also highly encourage you to try Bob Nachbar’s </span><a class="GsEf0r4HiEK6fH_vutb_b EEKKPz0N2Ww3GdmB51Zgq" href="https://resources.wolframcloud.com/PacletRepository/resources/RobertNachbar/CompartmentalModeling/" target="_blank" data-testid="ButtonBoxView" rel="noopener"><span class="cc61" data-native-text="true">CompartmentalModelling</span></a><span class="cc8" data-native-text="true"> paclet. The </span><span class="cc42" data-native-text="true">CompartmentalModelling</span><span class="cc8" data-native-text="true"> paclet is not just for biologists, but could be a valuable tool for anyone dealing with interconnected systems that can be represented as compartments. </span></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
            ]]>
        </content>
    </entry>
</feed>
